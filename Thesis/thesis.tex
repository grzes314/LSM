\documentclass[a4paper,12pt, oneside]{book}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage[polish, english]{babel}
\usepackage[OT4]{fontenc}
\usepackage[left=2.5cm,right=2.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage[section]{placeins} % keeps floats in their places
\usepackage{graphicx}
\usepackage{color}
\usepackage{titlesec}
\usepackage{listings} % allows inclusion of code snippets
\usepackage[chapter]{algorithm} % allows to keep algorithms as floats
\usepackage{algpseudocode} % allows writing pseudocodes
\usepackage[font={small,sl}]{caption}
\usepackage{bbm}

\addto\captionsenglish{
  \renewcommand\chaptername{Part}}
\titleformat{\chapter}[display]
  {\normalfont\Large\filcenter\sffamily}
  {\titlerule[1pt]%
   \vspace{1pt}%
   \titlerule
   \vspace{1pc}%
   \LARGE\MakeUppercase{\chaptertitlename} \Roman{chapter}
  }
  {1pc}
  {\titlerule
  \vspace{1pc}%
  \Huge}

\setcounter{tocdepth}{1} %subsections won't appear in TOC

\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{coro}[thm]{Corollary}
\newtheorem{lemma}[thm]{Lemma}

\theoremstyle{definition}
\newtheorem{mydef}{Definition}[section]
\newtheorem{notation}[mydef]{Notation}
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}

% \newcounter{example}
% \newenvironment{example}
%   {\refstepcounter{example} \par\medskip\noindent \textbf{Example~\arabic{example}.}  }
%   {\begin{flushright}$\square$\end{flushright}}
  
\def\Var{{\rm Var}\,}
\def\E{{\mathbb{E}}\,}
\def\P{{\mathbb{P}}\,}
\def\Cov{{\hbox{Cov}}}
\def\Corr{{\hbox{Corr}}}
\def\Em{{\mathbb{E}^*}\,}
\def\Pm{{\mathbb{P}}^*\,}
\def\R{{\mathbb{R}}}
\def\conv{\xrightarrow[n \rightarrow \infty]{}}
\def\limn{\lim\limits_{n \rightarrow \infty} }
\def\Sa{\bar{S}}
\def\Xa{\bar{X}}
\def\xia{\bar{\xi}}
\def\CMC[#1]{\hat{Y}^{\hbox{\tiny CMC}}_{#1}}
\def\AV[#1]{\hat{Y}^{\hbox{\tiny AV}}_{#1}}
\def\CV[#1]{\hat{Y}^{\hbox{\tiny CV}}_{#1}}
\def\CMCa[#1, #2]{\hat{#1}^{\hbox{\tiny CMC}}_{#2}}
\def\AVa[#1, #2]{\hat{#1}^{\hbox{\tiny AV}}_{#2}}
\def\CVa[#1, #2]{\hat{#1}^{\hbox{\tiny CV}}_{#2}}

%opening
\title{Pricing American and Exotic Options using the Least Squares Monte Carlo Approach}
\author{Grzegorz Łoś}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[RO]{\small\bfseries\thepage}
%\fancyhead[LE,RO]{\small\bfseries\thepage} do odkomentowania w wersji dwustronnej
\fancyhead[LO]{\small\bfseries\nouppercase\rightmark}
%\fancyhead[RE]{\small\bfseries\nouppercase\leftmark} do odkomentowania w wersji dwustronnej

%\lhead{\nouppercase{\bfseries \leftmark}}
%\rhead{\nouppercase \rightmark}
\setlength{\headheight}{15pt}

\begin{document}
 
\thispagestyle{empty}
\begin{center}
\textbf{\large Uniwersytet Wrocławski\\
Wydział Matematyki i Informatyki\\
Instytut Matematyczny}\\
\textit{\large specjalność: zastosowania}\\
\vspace{4cm}
\textbf{\textit{\large Grzegorz Łoś}\\
\vspace{0.5cm}
{\Large Pricing American and Exotic Options using the Least Squares Monte Carlo Approach}}\\
\end{center}
\vspace{3cm}
{\hspace*{6.5cm}\large Praca magisterska\\
\hspace*{6.5cm}\large  napisana pod kierunkiem\\
\hspace*{6.5cm}\large  doktora Pawła Kawy }
\vfill
\begin{center}
{\large Wrocław 2013}\\
\end{center}

\newpage
\thispagestyle{empty}
\vspace*{10cm}
\noindent {\large Oświadczam, że pracę magisterską wykonałem samodzielnie\\ i~zgłaszam ją do oceny.\\[1.5cm]
Data:....................\hfill Podpis autora pracy:.........................\\[1.5cm]
Oświadczam, że praca jest gotowa do oceny przez recenzenta.\\[1.5cm]
Data:.................... \hfill Podpis opiekuna pracy:.........................}

\newpage

\tableofcontents

\newpage

\section*{\begin{center}\begin{normalsize} Abstract \end{normalsize}\end{center}}
\begin{quotation}
\noindent 
  The thesis presents a technique of option pricing known as Least Squares Monte Carlo or Longstaff-Schwartz model, due to it's discoverers Francis Longstaff and Eduardo Schwartz. In the first chapter some general facts from Stochastic Analysis, Monte Carlo theory and Black-Scholes model are reminded.
  Next chapters describe LSM algorithm, the implementation, examples of usage for valuation of exotic options.
\end{quotation}

\chapter{Preliminaries}
We expect from the reader some basic knowledge of stochastic processes and option pricing. Purpose of this section is to recall definitions and facts essential for this work and to establish notation.

\section{Elements of stochastic analysis}
\begin{mydef}
 Let $(\Omega, \mathcal{F}, \P)$ be a probability space, $(E, \mathcal{E})$ be a measureable space and $T$ be an arbitrary set. A \textbf{stochastic process} with values in a measurable space $E$, indexed by an arbitrary set $T$, is a family of random variables $X = (X_t)_{t \in T}$, where each $X_t$ is $E$-valued.
 
 For given $\omega \in \Omega$ a \textbf{trajectory} of process $X$ is a function $t \mapsto X_t(\omega)$, with domain $T$ and codomain $E$.
\end{mydef}

\begin{remark}
 Stochastic process may be viewed as a function $X: \Omega \rightarrow \mathbb{E}^T$. Then a trajectory is value of such function, i.e. for given $\omega,\ X(\omega)$ is a trajectory. In the other words, a stochastic process is a random function and a trajectory is it's concrete realization.
\end{remark}

\begin{remark}
 In our applications space $E$ will be equal $\R$ or $\R^n$. 
\end{remark}

\begin{mydef}
 A \textbf{Brownian motion} (or a \textbf{Wiener process}) is a stochastic process $(W_t)_{t \geq 0}$ defined by following conditions:
 \begin{itemize}
  \item $W_0 = 0$ a.s.,
  \item for any $t,\ W_t \sim \mathcal{N}(0,t)$,
  \item increments of $W$ are independent (i.e. for any $t_0 \leq t_1 \leq \ldots \leq t_n$ random variable $W_{t_0}, W_{t_1} - W_{t_0},\ \ldots, W_{t_n} - W_{t_{n-1}}$ are independent,
  \item increments of $W$ are stationary (i.e. for every $0 \leq s < t,\ W_t-W_s$ is equal in distribution to $W_{t-s})$,
  \item trajectories of $W$ are continous a.s.
 \end{itemize}
\end{mydef}
\noindent In this paper $W$ will always denote Brownian motion.

\begin{mydef}
 \textbf{Filtration} $(\mathcal{F}_t)_{t=0}^T$ on probability space $(\Omega, \mathcal{F}, {P})$ is an increasing family of $\sigma$-algebras contained in $\mathcal{F}$, i.e. for all $s<t,\ \mathcal{F}_s \subseteq \mathcal{F}_t \subseteq \mathcal{F}$.
\end{mydef}
\noindent Sometimes $\mathcal{F}_t$ is interpreted as a set of all events observable up to time $t$.

\begin{mydef}
 Process $X=(X_t)_{t=0}^T$ is called $\mathcal{F}_t$-\textbf{adoptable} if and only if for all $t~\in~[0,T],\ X_t$ is $\mathcal{F}_t$-measurable.
\end{mydef}
\noindent Minimal filtration to which $X$ is adoptable if of course filtration generated by $X$, defined as $\mathcal{F}_t^X = \sigma(X_s:\ s \leq t)$.

\begin{mydef}
 A \textbf{stopping time} with respect to filtration $(\mathcal{F}_t)_{t=0}^T$ is a random variable $\tau:\ \Omega \rightarrow [0,T]\cup\{\infty\}$, such that $\{\tau \leq t\} \in \mathcal{F}_t$ for all $t \in [0,T]$.
\end{mydef}
If $X$ is a process corresponding to some risky game, then a stopping time may be seen as a strategy which tells us whether we should withdraw at time $t$, basing only on the information accessible at time $t$.
\begin{example}
 A typical example of a stopping time is first $t$, when $X_t$ reaches a fixed barrier, i.e.
 \[\tau = \inf\{t\in[0,T]: X_t \geq b\}\]
\end{example}
\noindent Stopping times play important role in financial mathematics. Often we are interested in finding an optimal strategy for exercising an option. Such strategy is a stopping time.

\begin{mydef}
 We call a stochastic process $M=(M_t)_{t=0}^T$ a \textbf{martingale} with respect to filtration $(\mathcal{F}_t)_{t=0}^T$ if and only if it satisfies following conditions:
 \begin{itemize}
  \item for all $t \in [0,T],\ M_t$ is $\mathcal{F}_t$-measurable,
  \item $\E|M_t| < \infty$,
  \item for all $0 \leq s < t \leq T, \E[M_t|\mathcal{F}_s] = M_s$  a.s.
 \end{itemize}
\end{mydef}

\begin{example}
 Brownian motion $W$ is a martingale. Indeed, we have
 \begin{equation*}
  \E[W_t|\mathcal{F}_s] = \E[W_t-W_s|\mathcal{F}_s] + \E[W_s|\mathcal{F}_s] = \E[W_t-W_s] + W_s = W_s.
 \end{equation*}
 for all $t > s$.
\end{example}
\begin{example}
 \label{ex:angleWt}
 Process $(W_t^2-t)_t$ is a martingale. As previously, for any $t > s$
 \begin{equation*}
  \begin{split}
       & \E[W_t^2-t|\mathcal{F}_s] = \E[(W_t-W_s)^2 + 2W_tW_s - W_s^2|\mathcal{F}_s] -t =\\ 
    =\ & \E[(W_t-W_s)^2|\mathcal{F}_s] + \E[2W_tW_s|\mathcal{F}_s] - \E[W_s^2|\mathcal{F}_s] -t = \\
    =\ & \E[(W_t-W_s)^2] + 2W_s\E[W_t|\mathcal{F}_s] - W_s^2 -t = \\
    =\ & \E[(W_t-W_s)^2] + 2W_s^2 - W_s^2 -t = W_s^2 - s.
  \end{split}
 \end{equation*}
\end{example}

The breakthrough allowing financial mathematics to devolop was discovery of It\^{o} integral, named after Japanese mathematician Kiyoshi It\^{o}. We will not discuss constructon of such integral, what is done for example in \cite{latala}.
Instead we will provide some intuition about its meaning. It\^{o} integral of $X=(X)_{t=0}^T$ with respect to Wiener process $W=(W)_{t=0}^T$ is a stochastic process
\[ \left( \int_0^{t} X_s dW_s \right)_{t = 0}^T, \]
where
\begin{equation}
 \label{eq:ito_integral}
  \int_0^{t} X_s dW_s = \lim_{n \rightarrow \infty} \sum\limits_{i=0}^n X_{t_{i-1}} (W_{t_i} - W_{t_{i-1}}).
\end{equation}
As we can see the above definition is similar to the Stieltjes integral definition, which is defined for $g$ of bounded variation on finite intervals and continous $f$, as
\[  \int_0^{t} f(s) dg(s) = \lim_{n \rightarrow \infty} \sum\limits_{i=0}^n f(t_{i-1}) (g(t_i) - g(t_{i-1})). \]
However, on almost all trajectories $W$ has unbounded variation on finite intervals. In order to give sense to equation (\ref{eq:ito_integral}), the limit has to be taken in $L_2$.

\begin{remark} Note that
\begin{itemize}
 \item to integrate $\int\limits_0^t X_s ds$ we need only ``standard'' Riemann theory. The integrand is random, hence $\int\limits_0^t X_s ds$ is a function $\omega \mapsto \int\limits_0^t X_s(\omega) ds$ and the last term is a Riemann integral.
 \item $\int\limits_0^t X_s dW_s$ denotes stochastic integral, thus its calculation requires It\^{o} theory.
\end{itemize}
\end{remark}


\begin{mydef}
\label{def:SDE}
 Let $\mu, \sigma \in C^1,\ \xi$ be $\mathcal{F}_s$-measurable random variable. We say that process $X=(X_t)_{t=0}^T$ solves a \textbf{stochastic differential equation (SDE)}
 \begin{equation*}
 \begin{split}
   dX_t &= \mu(X_t)dt + \sigma(X_t) dW_t,\\
   X_0 &= \xi  
 \end{split}  
 \end{equation*}
 if and only if
 \[X_t = \xi + \int\limits_0^t \mu(X_s)ds + \int\limits_0^t\sigma(X_s) dW_s\]
for all $t \in [0,T)$.
\end{mydef}
\begin{remark}
 Sometimes indices are omitted and SDE is written in the form
\end{remark}
\[ dX = \mu(X)dt + \sigma(X) dW. \]

Next definition presents one of the most important type of processes, used to model asset movements in markets.
\begin{mydef}
 A stochastic process $S$ given by SDE
 \begin{equation}
  dS_t = \mu S_t dt + \sigma S_t dW_t, 
  \label{eq:gbm}
 \end{equation}
where $\mu,\sigma \in \R$ is called a \textbf{geometic Brownian motion}.
\end{mydef}

Now we can formulate a version of It\^{o}'s lemma, which is widely used in financial mathematics.
\begin{thm}[It\^{o}'s lemma]
 \label{thm:ito}
  Let $S$ be a geometic Brownian motion as in (\ref{eq:gbm}), $F:\ \R^2 \rightarrow \R,\ F \in C^2$. Then 
  \begin{equation*}
   F(S_t, t) = F(S_0, 0) + \int\limits_0^t \frac{\partial F}{\partial S}(S_r,r)dS_r + \int\limits_0^t \frac{\partial F}{\partial t}(S_r,r)dr + \frac{1}{2}\sigma^2 S_t^2 \int\limits_0^t \frac{\partial^2 F}{\partial S^2}(S_r,r)dr
  \end{equation*}
  or equivalently in SDE form
  \begin{equation}
   \label{eq:ito}
   dF(S_t, t) = \frac{\partial F}{\partial S}(S_t,t)dS_t + \frac{\partial F}{\partial t}(S_t,t)dt + \frac{1}{2}\sigma^2 S_t^2 \frac{\partial^2 F}{\partial S^2}(S_t,t)dt   .
  \end{equation}  
\end{thm}
{\Large \color{red} Wskazac pozycje z dowodem}

\noindent In the books on the stochastic processes It\^{o}'s lemma is proven in much greater generality. However, for our purposes, as in many other literature on financial mathematics, formulated theorem will be sufficient.
Equation (\ref{eq:ito}) is also called an It\^{o}'s formula.

It\^{o}'s lemma is a very powerfull tool, indispensable in Black-Scholes theory. We will show how it can be used to solve equation (\ref{eq:gbm}).
\begin{lemma}
\label{lemma:solution_dynamics}
 Let $S$ be a geometric Brownian motion, as in (\ref{eq:gbm}).
 Solution of its SDE is given by
 \begin{equation}
  \label{eq:gmb_sol}
  S_t = S_0 \exp\left\{ (\mu - \frac{1}{2}\sigma^2)t + \sigma W_t \right\}.
 \end{equation}
\end{lemma}
\begin{proof}
We will apply Theorem \ref{thm:ito} (It\^{o}'s formula) with $F(S,t) = \ln(S)$. We have
 \begin{equation*}
  \begin{split}
   dF &= \frac{\partial F}{\partial S}dS + \frac{\partial F}{\partial t}dt + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2}dt \\
   &= \frac{\partial F}{\partial S}(\mu S dt + \sigma S dW) + \frac{\partial F}{\partial t}dt + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2}dt \\    
   &= \frac{1}{S}(\mu S dt + \sigma S dW) + 0dt - \frac{1}{2}\sigma^2 S^2 \frac{1}{S^2}dt \\   
   &= (\mu - \frac{1}{2}\sigma^2) dt + \sigma dW
  \end{split}.
 \end{equation*}
 From Definition \ref{def:SDE}
 \begin{equation*}
  \begin{split}
  F(S_t,t) &= F_0 + \int\limits_0^t (\mu - \frac{1}{2}\sigma^2) ds + \int\limits_0^t \sigma dW_s\\
  &= F_0 + (\mu - \frac{1}{2}\sigma^2)t + \int\limits_0^t \sigma W_t. 
  \end{split}.
 \end{equation*}
 By substituting $S_0 = e^{F_0}$, we get
 \[ S = S_0 \exp\left\{ (\mu - \frac{1}{2}\sigma^2)t + \sigma W_t \right\}. \] 
\end{proof}

Significance in the financial mathematics of the last theorem in this section derives from the fact, that it allows us to move from real measure $\P$ to equivalent martingale measure $\Pm$.
\begin{thm}[\bfseries Girsanov theorem]
 \label{thm:girsanov}
 Let $\bar{W}$ be a $d$-dimensional standard Wiener process on probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t)_{t=0}^T, \P)$ and let $\varphi$ be any $d$-dimensional adapted column vector process.
 Choose a fixed $T$ and define the process $L$ on $[0,T]$ by
 \[ L_t = \exp\left\{ \int\limits_0^t \varphi_s \cdot d\bar{W}_s - \frac{1}{2}\int\limits_0^t ||\varphi_s||^2ds. \right\} \]
 Assume that 
 \[ \E^P[L_T] = 1, \]
 and define the new probability measure $\mathbb{Q}$ on $\mathcal{F}_T$ by
 \[ \frac{d\mathbb{Q}}{d\P} = L_T,\ \ \hbox{ on } \mathcal{F}_T. \]
 Then $W$ given by
 \[W_t = \bar{W}_t - \int\limits_0^t \varphi_s ds\]
 is a standard Wiener process under $\mathbb{Q}$.
\end{thm}
\begin{remark}
 Symbol $\cdot$ in definition of $L$ is the inner product of two vectors. 
\end{remark}
The proof of Girsanov theorem reader may find for example in \cite{bjork} (Theorem 11.3).

\section{Elements of Monte Carlo theory}
Monte Carlo methods are a class of algorithms designed for estimation of unknown values by simulation.
They do not refer to any particular algorithm, they are rather a general ``recipe'' for procedures, which obtain results by simulation.

\subsection{Crude Monte Carlo}
Suppose we want to estimate an unknown value $I$, which can be written as expected value of some random variable, i.e.
\begin{equation}
 \label{eq:EY}
 I = \E Y. 
\end{equation}
The idea of Monte Carlo technique is to replicate $Y$ many times, and as an estimation of $I$ take an average. So
\[ I \approx \frac{1}{n} \sum\limits_{i=1}^n Y_i, \]
where $n$ is a big natural number and $Y_i$ are independent, with the same distribution as~$Y$.

This procedure is justified by the strong law of large numbers. Let 
\begin{equation}
 \label{eq:CMC}
 \CMC[n] = \frac{1}{n}\sum\limits_{i=1}^n Y_i.
\end{equation}
Of course $\E\CMC[n] = \E Y = I$, so $\CMC[n]$ is unbiased. Moreover, from the law of large numbers $\CMC[n] \conv I$ a.s., what explains why Monte Carlo method works. 

Value $\CMC[n]$ is called \textbf{crude Monte Carlo} estimator. Simple calculation gives its variance
\begin{equation}
 \label{eq:VarCMC}
 \Var(\CMC[n]) = \frac{1}{n}\Var(Y).
\end{equation}
In this paragraph we will simply write $\hat{Y}_n$ instead of $\CMC[n]$.

Here appears a natural question, how big should be the number $n$ to obatain the satisfying accuracy of the estimator?
To find an answer we have to specify the question a little more: for chosen numbers $b$ and $\alpha$, how big should be $n$, so we could tell, that an error of the estimation, with probability $1-\alpha$, is not greater than $b$?

Let $\sigma = \sqrt{\Var{Y}}$, $z_{1-\alpha/2} = \Phi^{-1}(1-\alpha/2)$, where $\Phi$ is cumulative distribution function of normal distribution.
Strong convergence of $\hat{Y}_n$ implies also weak convergence, what means that
\[ \P(|\hat{Y}_n - I| > b) \conv 0 \hbox{\ \ a.s.,} \]
for any $b > 0$. 
Hence we write
\begin{align*}
 \P(-b \leq \hat{Y}_n - I \leq b) &= 1 - \alpha\\
 \P(-b \leq \frac{\sum\limits_{i=1}^n Y_i - nI}{n}  \leq b) &= 1 - \alpha\\
 \P(-\frac{b\sqrt{n}}{\sigma} \leq \frac{\sum\limits_{i=1}^n Y_i - nI}{\sqrt{n}\sigma}  \leq \frac{b\sqrt{n}}{\sigma}) &= 1 - \alpha
\end{align*}
From Central Limit Theorem we have
\[ \limn \P(-z_{1-\alpha/2} \leq \frac{\sum\limits_{i=1}^n Y_i - nI}{\sqrt{n}\sigma}  \leq z_{1-\alpha/2}) = 1 - \alpha, \]
hence for large $n$ we have
\[z_{1-\alpha/2} \approx \frac{b\sqrt{n}}{\sigma}.\]
In a typical situation we do not know variation of $Y$ (we don't even know the expected value, yet we are using Monte Carlo method to find it!), so above formula has rather theoretical meaning.
However, there is a version of CLT which uses unbiased estimator
\[ \hat{\sigma} = \frac{1}{n-1}\sum\limits_{i=1}^n (Y_i - \hat{Y}_n)^2 \]
instead of $\sigma$, what allows to replace $\sigma$ by $\hat{\sigma}$ in above approximation. We have proven following 
\begin{thm}
 Dependency between number of simulations $n$, error $b$ and confidence level $\alpha$ is given by following formulas
 \begin{equation}
   \label{eq:error}
   b = \frac{\hat{\sigma} z_{1-\alpha/2}}{\sqrt{n}}
 \end{equation}
 \begin{equation}
   \label{eq:sim}
   n = \frac{\hat{\sigma}^2 z_{1-\alpha/2}^2}{b^2}.
 \end{equation}
\end{thm}
\noindent Equation (\ref{eq:error}) tells us how big is an error of estimation when we performed $n$ simulation. Equation (\ref{eq:sim}) inverses situation, it allows us to plan the number of simulations necessary to obtain requested accuracy.

Unfortunatly equation (\ref{eq:error}) tells us that convergence of the Monte Carlo method is slow. To improve accuracy by one more digit, one have to perform 100 times more simulations. The only way to decrease the number of necessary simulations is to choose $Y$ with smallest possible variance. In next sections two methods of variance reduction are discussed.

The confidence level $\alpha$, which appears in (\ref{eq:error}) in quantile function, is not essential when comparing two estimators. Hence we introduce 
\begin{mydef}
 Value
 \begin{equation}
  \label{eq:stderr}
  \frac{\hat{\sigma}}{\sqrt{n}}
 \end{equation}
is called \textbf{standard error} (abbreviated \textbf{s.e.}).
\end{mydef}
Suppose that in some fixed time we can take $n$ samples from distribution of $Y$, and $m$ samples from distribution of $Z$, where $EY = EZ = I$. In order to settle which estimator is better, $\hat{Y}_n$ or $\hat{Z}_m$, it is sufficient to compare their standard errors, that is $\dfrac{\hat{\sigma}_Y}{\sqrt{n}}$ and $\dfrac{\hat{\sigma}_Z}{\sqrt{m}}$.

\subsection{Antithetic variates}
Let's consider again $I$ and $Y$ as in (\ref{eq:EY}). Equation (\ref{eq:sim}) shows that the number of simulations required to obtain given accuracy is proportional to variance of $Y$. It explains the necessity of choosing $Y$ wisely. If we can find $Y'$ which has smaller variance than $Y$, then we can significantly decrease the number of needed simulations.
We will describe two techniques of variance reduction: this paragraph introduces antithetic variates method, and the following presents control variates method.

In \textbf{antithetic variates method} every sample is a pair of values, each from the same distribution as $Y$. Every of $n$ sample pairs is independent from each other, however random variables in a pair should be correlated. In the other words we consider pairs $(Y_{2i-1}, Y_{2i})$, $i=1,2,...,n$,
where each $(Y_{2i-1}, Y_{2i})$ is independent from $(Y_{2j-1}, Y_{2j})$, if $i \neq j$, and for some $\varrho$, $\Corr(Y_{2i-1}, Y_{2i}) = \varrho$. Let
\begin{equation*}
 \tilde{Y}_i = \frac{Y_{2i-1} + Y_{2i}}{2},\ \ \ i = 1,2,...,n.
\end{equation*}
It is clear that $(\tilde{Y}_i)_{i=1}^n$ are i.i.d., and their variance satisifies
\begin{equation*}
 \begin{split}
 \Var(\tilde{Y}_i) &= \dfrac{1}{4} \Var( Y_{2i-1} + Y_{2i} ) = \dfrac{1}{4} (\Var(Y_{2i-1}) + \Var(Y_{2i}) + 2\Cov(Y_{2i-1}, Y_{2i})) \\
 %&= \dfrac{1}{4} (\Var(Y_{2i-1}) + \Var(Y_{2i}) + 2\Corr(Y_{2i-1}, Y_{2i})\sqrt{\Var(Y_{2i-1})\Var(Y_{2i})})
 &= \dfrac{1}{4} (2\Var(Y) + 2\Var(Y)\varrho) \\
 &= \dfrac{\Var(Y)}{2} (1 + \varrho).
 \end{split}
\end{equation*}
We define \textbf{antithetic variates estimator} as
\begin{equation*}
 \AV[n] = \frac{1}{n}\sum\limits_{i=1}^n \tilde{Y}_i.
\end{equation*}
We calculate its variance
\begin{equation}
 \label{eq:VarAV}
 \begin{split}
 \Var(\AV[n]) &= \frac{1}{n^2} \Var(\sum\limits_{i=1}^n \tilde{Y}_i) \\
   &= \frac{1}{n} \Var(\tilde{Y}_i) = \dfrac{\Var(Y)}{2n} (1 + \varrho).
 \end{split}
\end{equation}
From (\ref{eq:VarCMC}) we see that variance of the crude Monte Carlo estimator, which performs the same number of draws, equals $\frac{1}{2n}\Var(Y)$. Hence, if correlation of random variables in a pair is negative, then we reduce variance. In consequence the number of simulations necessary to keep an error smaller than $b$, at the confidence level $\alpha$ is also smaller.

\subsection{Control variates}
The \textbf{control variates method} also involves drawing pairs of values, however in opposite to antithetic variates method, elements in pair do not come from the same distribution and expected value of the second distribution must be known. More precisely, we consider pairs $(Y_i, X_i)$, $i=1,2,...,n$, where each $(Y_i, X_i)$ is independent from $(Y_j, X_j)$,
if $i \neq j$, $\E X$ is known and $\Cov(Y_i, X_i) > 0$. Let $\hat{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$. \textbf{Control variates estimator} is defined as
\begin{equation}
 \label{eq:CV}
 \CV[n] = \CMC[n] + c(\hat{X}_n - \E X)
\end{equation}
for some $c$. In order to reduce variance $c$ must be chosen properly. We have
\begin{equation*}
 \begin{split}
 \Var( \CV[n] ) &= \Var( \CMC[n] + c\hat{X}_n ) = \frac{1}{n^2} \Var \left( \sum\limits_{i=1}^n( Y_i + c X_i) \right) \\
                &= \frac{1}{n}\Var(Y + c X) = \frac{1}{n}( \Var(Y) + 2c\Cov(Y,X) + c^2 \Var(X)).
 \end{split}
\end{equation*}
The last expression is a simple quadratic equation with respect to $c$, hence it is easy to determine for which argument it reaches its minimum value:
\[ c = -\frac{\Cov(Y,X)}{\Var(X)}. \]
Let $\varrho = \Corr(Y,X)$. By substituting $c$ to the last equation we get
\begin{equation}
 \begin{split}
 \Var( \CV[n] ) &=  \frac{1}{n} \left( \Var(Y) - 2\frac{\Cov(Y,X)^2}{\Var(X)} + \frac{\Cov(Y,X)^2}{\Var(X)^2} \Var(X) \right) \\
 &= \frac{1}{n} \left( \Var(Y) - \frac{\Cov(Y,X)^2}{\Var(X)}  \right) \\
 &= \frac{\Var(Y)}{n} \left( 1 - \varrho^2  \right) \label{eq:VarCV}
 \end{split}
\end{equation}
Crude Monte Carlo estimator, which takes the same number of random variables (i.e. 2 times the number of pairs in control variates method) has the variance equal to $\frac{\Var(Y)}{2n}$. Thus if $1 - \varrho^2 < \frac{1}{2}$ we reduce the variance.

In practice, however, we do not know values $\Var(X)$ (we only assumed we know expectation of $X$) and $\Cov(Y,X)$. Hence in the simulations we have to use 
\begin{equation}
 \label{eq:CVc}
 c = -\frac{\sigma_{XY}^2}{\sigma_{X}^2},
\end{equation}
where
\begin{equation*}
 \begin{split}
  \sigma_{XY}^2 &= \frac{1}{n-1} \sum\limits_{i=1}^{n} (X_i - \hat{X}_n)(Y_i - \CMC[n]),\\
  \sigma_{X}^2 &= \frac{1}{n-1} \sum\limits_{i=1}^{n} (X_i - \hat{X}_n)^2.
 \end{split}
\end{equation*}

\begin{example}
To compare presented Monte Carlo methods let us calculate value of $I = \int_0^1 e^x dx$ by simulation. Of course exact value equals $e - 1 \approx 1.71828183$. Let $g(x) = e^x$ and $U \sim \mathcal{U}(0,1)$. Then 
\[ I = \E[g(U)], \]
 hence we can use derived theory with $Y = g(U)$. We consider following estimators:
 \begin{equation*}
  \begin{split}
   \CMC[2n] &= \frac{1}{2n} \sum\limits_{i=1}^{2n} g(U_i), \\
   \AV[n] &= \frac{1}{n} \sum\limits_{i=1}^{n} \frac{g(U_i) + g(1-U_i)}{2}, \\ 
   \CV[n] &= \frac{1}{n} \sum\limits_{i=1}^{n} \left( g(U_i) + c(U_i - \frac{1}{2}) \right),
  \end{split}
 \end{equation*}
where $c$ is as in (\ref{eq:CVc}) with $Y = g(U)$ and $X = U$. Note that we are taking twice as much simulations in crude Monte Carlo method, since it does not use pairs of random variables. The results of comparision of all presented methods are gathered in Table \ref{tab:MCcompare} and Figures \ref{fig:boxMC}, \ref{fig:convergenceMC}.

\begin{table}[h]
\centering
 \caption{Results of calculating $\int_0^1 e^x dx$ by simulation.}
 \label{tab:MCcompare}
\begin{tabular} {||c | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMC[2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AV[n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CV[n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
100    & 1.69825 & 0.03504 & 1.71717 & 0.00648 & 1.71962 & 0.00638 \\ \hline 
1000   & 1.72458 & 0.01094 & 1.72171 & 0.00205 & 1.72032 & 0.00203 \\ \hline 
10000  & 1.72116 & 0.00349 & 1.71805 & 0.00062 & 1.71918 & 0.00063 \\ \hline 
100000 & 1.71665 & 0.00110 & 1.71802 & 0.00020 & 1.71844 & 0.00020 \\ \hline 
1000000& 1.71796 & 0.00035 & 1.71831 & 0.00006 & 1.71829 & 0.00006 \\ \hline 
\end{tabular}  
\end{table}

\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.4]{images/Preliminaries/boxMonteCarlo.pdf}
\caption{For each method 10000 simulations were run 100 times. Hence each method gave 100 estimations of $\int_0^1 e^x dx$. Small points indicate obtained values. As usually in box plots, the lower and upper edges of the boxes are first and third quartiles.  }
\label{fig:boxMC}
\end{figure}

\begin{figure}
\centering
 \includegraphics[scale=0.4]{images/Preliminaries/convergenceMC.pdf}
\caption{Comparision of speed of convergence. }
\label{fig:convergenceMC}
\end{figure}

We see that in this case antithetic and control variates methods gave approximatly equal results, while crude Monte Carlo is far behind them. When performing one million simulations (in case of CMC two millions) standard error turned out 50 times smaller in AV and CV than in CMC. It means that results from the first two methods are more than one digit more accurate.

Box plot from figure \ref{fig:boxMC} shows that variance of the crude Monte Carlo estimator is greater than in two other methods. In practice it means, that if we run simulations with AV estimator or CV estimator, then every time we would obtain more or less equal result. For CMC discrepancy between the results would be much bigger.
Figure \ref{fig:convergenceMC} explains that fact -- speed of convergence of CMC is definitely lower than two other methods.

In order to realize why AV and CV methods result with so similar accuracy, look at (\ref{eq:VarAV}) and (\ref{eq:VarCV}). In AV method variance is reduced by a coefficient
\[ \frac{1 + \Corr(e^U, e^{1-U})}{2} \approx \frac{1 - 0.968}{2} = 0.0162, \]
while in CV method variance is reduced by a coefficient
\[ 1 - \Corr(e^U, U)^2 \approx 1 - 0.992^2 = 0.0163. \]
Such similarity of the results is pure coincidence.

At the end note that this is very tendentious example, which shows that variance reduction may be very usefull. Actually, in many applications it may be difficult to find pairs of highly correlated random variables necessary to use AV or CV methods.
\end{example}


\subsection{Simulation}
Now, when we know how Monte Carlo methods work, we need to describe how to get random values.
\paragraph{Independent standard normal random variables.} Most computational enviroments and programming languages have built-in generator of values from uniform distribution. We will show how to obtain (pseudo)random variables with ubiquitous normal distribution.

The most popular way is to use \textbf{Box-Muller algorithm}, which uses two independent variates with uniform distribution on $(0,1)$, and ``produces'' two independent variates with standard normal distribution.
\begin{algorithm}[!ht]
 \begin{algorithmic}[1]
  \Function{BoxMuller}{}
    \State Generate independent random variables $U_1, U_2 \sim \mathcal{U}(0,1)$,
    \State $N_1 \gets \sqrt{-2\log(U_1)} \cos(2\pi U_2)$,
    \State $N_2 \gets \sqrt{-2\log(U_1)} \sin(2\pi U_2)$,
    \State \Return ($N_1$, $N_2$).
  \EndFunction
 \end{algorithmic}
 \caption{Box-Muller method.}
 \label{alg:box-muller}
\end{algorithm}

This method returns values of two independent random variables coming from standard normal distribution. When we need more than two samples, then of course we repeat that algorithm as many time as necessary.

In \cite{london} we can find a remark that necessity of calculating sine and cosine may slow the above algorithm down. Another algorithm, \textbf{polar rejection}, is proposed.
\begin{algorithm}[!ht]
 \begin{algorithmic}[1]
  \Function{PolarRejection}{}
    \State Generate independent random variables $U_1, U_2 \sim \mathcal{U}(0,1)$,
    \State $V_1 \gets 2U_1-1$,
    \State $V_2 \gets 2U_2-1$,
    \State $W \gets V_1^2 + V_2^2$,
    \State if $W > 1$ return to step 2.,
    \State $N_1 \gets \sqrt{\frac{-2\log(W)}{W}} V_1$,
    \State $N_2 \gets \sqrt{\frac{-2\log(W)}{W}} V_2$,
    \State \Return ($N_1$, $N_2$).
  \EndFunction
 \end{algorithmic}
 \caption{Polar rejection method.}
 \label{alg:polarRejection}
\end{algorithm}

However, conducted experiment does not show any significat diffrence in efficiency of both presented methods. Code for the test is presented on Listing \ref{lst:rnorm}.
\lstset{  basicstyle=\scriptsize }
\lstinputlisting[language=Java, caption=Java program for comparision of normal random values generators, label=lst:rnorm]{listings/rnormTest.java}
For both algorithms program takes ten millions pairs of values and prints following \hbox{output}\footnote{Test was performed on a notebook with processor Intel® Core™2 Duo CPU P8400 @ 2.26GHz x 2 }: \bigskip \\
\texttt{Box-Muller: 3.321 s.\\
Polar rejection: 3.292 s.} \bigskip\\
what brings us to conclusion that the efficiency of both algorithms is comparable and not worth bothering.

\paragraph{Independet nonstandard normal random variables.} Sampling from an arbitrary normal distribution $\mathcal{N}(\mu, \sigma^2)$ is now straightforward. From the elementary probability theory comes following method.
\begin{enumerate}
 \item Genarate $N \sim \mathcal{N}(0,1)$ using one of previously shown methods.
 \item Return $\mu + \sigma N$.
\end{enumerate}

\paragraph{Correlated normal random values.} Above methods allow us to generate independent random variables. In the real world, however, we notice dependencies between observed phenomenons. For example movements of the prices of the market assets are usually correlated. When the market is in a boom cycle, then all the prices are increasing; inversly, if the recession comes, all of the prices are falling.
In order to model such values we must be able to generate correlated random variables.

\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.4]{images/Preliminaries/normalCorrelated.pdf}
\caption{Graphical illustration of dependency between normal correlated random variables. In the upper left corner $\varrho = -0.8$, upper right: $\varrho = -0.4$, lower left: $\varrho = 0$ (independent variables), lower right: $\varrho = 0.4$.}
\end{figure}

Let's begin with two standard normal random variables with correlation $\varrho$. We want to obtain $Z_1, Z_2 \sim \mathcal{N}(0,1)$ such that $\Corr(Z_1, Z_2) = \varrho$.  For now we only can generate independent $Z_1$ and $Z_2$, i.e. $\Corr(Z_1, Z_2) = 0$. On the other hand $\Cov(Z_1, Z_1) = 1$. Here rises the idea that there exists $Z_3$, such that $\Corr(Z_1, Z_3) = \varrho$, of the form $Z_3 = a Z_1 + b Z_2$.
It should come from standard normal distribution, thus
\[ 1 = \Var(Z_3) = \Var( a Z_1) +  \Var(b Z_2) = a^2 + b^2 \]
Moreover
\[ \varrho = \Corr(Z_1, Z_3) = \Cov(Z_1, Z_3) = a\Cov(Z_1, Z_1) + b\Cov(Z_1, Z_2) = a \]
Hence
\[ a = \varrho,\ \ \ \ b = \sqrt{1 - \varrho^2}. \]
We have proven following
\begin{prop}
 If $Z_1$ and $Z_2$ are independent random variables with the same distribution $\mathcal{N}(0,1)$, then for any $\varrho \in [-1,1]$ random variable
 \[ Z_3 = \varrho Z_1 + \sqrt{1 - \varrho^2} Z_2 \]
 has distribution $\mathcal{N}(0,1)$ and $\Corr(Z_1, Z_3) = \varrho$.
\end{prop}
The derivation of above fact was intuitive, but we need a more general version.


\begin{thm}
 If $N_1$ and $N_2$ are independent random variables with the same distribution $\mathcal{N}(0,1)$, then for any
 $\Sigma = \left( \begin{array}{cc}
                      \sigma_1^2 & \sigma_{12}^2 \\
                      \sigma_{12}^2 & \sigma_2^2
                   \end{array} \right)$
 random vector $ Z = \mu + LN$, where
  $L = \left( \begin{array}{cc}
                      \sigma_1 & 0 \\
                      \frac{\sigma_{12}^2}{\sigma_1} & \sqrt{\sigma_2^2 - \frac{\sigma_{12}^4}{\sigma_1^2}}
                   \end{array} \right)$,
 has distribution $\mathcal{N}(\mu,\sigma)$. Moreover $\Sigma = LL^T$.
\end{thm}
\begin{proof}
Let's focus on the case $\mu_1 = \mu_2 = 0$, since the mean may be added at the end. We have $N \sim \mathcal{N}(\bf{0}, \mathbb{I})$. By making an assigment $Z_1 = \sigma_1 N_1$, $Z_1$ has desired variance. As previously, we look for $Z_2$ of the form $Z_2 = a N_1 + b N_2$. We want the variance of $Z_2$ to equal $\sigma_2^2$, so
\[ \sigma_2^2 = \Var(Z_2) = \Var( a N_1) +  \Var(b N_2) = a^2 + b^2 \]
Moreover
\[ \sigma_{12}^2 = \Cov(Z_1, Z_2) = \sigma_1 a\Cov(N_1, N_1) + \sigma_1 b\Cov(N_1, N_2) = a\sigma_1 \]
Hence
\[ a = \frac{\sigma_{12}^2}{\sigma_1},\ \ \ \ b = \sqrt{\sigma_2^2 - \frac{\sigma_{12}^4}{\sigma_1^2}}. \] 
Equation $\Sigma = LL^T$ may be proven by simple matrix multiplication.
\end{proof}

It turns out that above theorem can be generalized for higher dimensions. That explains following algorithm for generating values from multivariate normal distribution with given mean vector $\mu$ and positive-definite covariation matrix $\Sigma$. 
\begin{enumerate}
 \item Use Cholesky decomposition to obtain matrix $L$ such that $\Sigma = LL^T$,
 \item Using previously shown method generate vector $N$ of independent random variables with standard normal distribution.
 \item Return $\mu + LN$.
\end{enumerate}


\chapter{Basics of option pricing}
The main field of interest of the financial mathematics is pricing so-called contingent claims, which are assets whose payoff depends on the stock prices. In case of the European options there exists a straightforward forumula, derived by Black and Scholes in 1973, which gives price of the option. Antother way of pricing is using Monte Carlo simulations.
Although the simulations are time-consuming and for that reason less effective than Black-Scholes formula, they are widely used because of the possibility to adjust them to diffrent contingent claims. 

\section{Elements of arbitrage theory}

\subsection{Notation}
Throughout this thesis we assume we are given a probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t)_{t=0}^T, \P)$. Since it is observed by investors, $\P$ is sometimes called a \textbf{real measure}, in opposite to artificial \textbf{risk-neutral measure}, which will be later on. Elements of $\Omega$ are called \textbf{market scenarios}.
Furthermore $\sigma$-algebra $\mathcal{F}_t$ may be seen as set of all events observable up to time $t$.

We consider a market with $d+1$ assets, where each asset $S^{(i)} = (S^{(i)}_t)_{t=0}^T$ is modelled as a $\R_+$-valued stochastic process adapted to $(\mathcal{F}_t)_{t=0}^T$. The $0$\textsuperscript{th} asset is the money stored in a locally riskless bank account and is given by 
\[S^{(0)}_t = \exp\left\{ \int\limits_0^t r(t)dt \right\},\]
where $r(t)$ is a short term riskless interest rate at time $t$. In general $r(t)$ may also be a stochastic process, however often we will assume $r(t) \equiv r$ and then $S^{(0)}$ may also be regarded as a bond, paying $e^{rT}$ at time $T$. By $S$ we will denote a $d$-dimensional vector of prices of the risky assets, i.e.
\begin{equation*}
 S_t = (S^{(1)}_t, S^{(2)}_t, \ldots, S^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}
We also introduce notation $\Sa$ for a $(d+1)$-dimensional vector of prices of all assets, that is
\begin{equation*}
 \Sa_t = (S^{(0)}_t, S_t) = (S^{(0)}_t, S^{(1)}_t, \ldots, S^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}

For convenience we also consider discounted time processes
\[ X^{(i)}_t = \frac{S^{(i)}_t}{S^{(0)}_t}. \]
It allows us to compare asset prices quoted at diffrent times. In similar manner as previously we will use notation $X, \Xa$ for vectors of the discounted prices,
\begin{equation*}
 X_t = (X^{(1)}_t, X^{(2)}_t, \ldots, X^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}
\begin{equation*}
 \Xa_t = (X^{(0)}_t, X^{(1)}_t, \ldots, X^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}

Next definition gives us a notation to describe the content of \textbf{portfolio}.
\begin{mydef}
A \textbf{dynamic trading strategy} is any $\mathcal{F}_t$-adapted,  $\R^{d+1}$-valued process $\xia = (\xia_t)_{t=0}^T = (\xi^{(0)}_t, \xi_t)_{t=0}^T = (\xi^{(0)}_t, \xi^{(1)}_t, \ldots, \xi^{(d)}_t)_{t=0}^T$.
\end{mydef}
Each $\xi^{(i)}_t$ has an interpretation of the quantity of shares of the $i$\textsuperscript{th} asset held in portfolio at time $t$ (it may be negative, then it corresponds to the short sale). Thus, the notion of the portfolio and the dynamic trading strategy may be equated. The value of the portfolio at time $t$ equals
\[\xia_t \cdot \Sa_t = \sum\limits_{i=0}^d \xi^{(i)}_t S^{(i)}_t,\]
where $\cdot$ is the inner product of two vectors.

Assume that investor's portfolio is worth 101\$ today and a year ago it was worth 100\$. Did the investor really make a profit? If riskless interest rate equals 5\%, then investor would gain more if he put all his capital into bank account. This example shows the necessity of discounting to compare portfolios whose values are quoted at diffrent times.
\begin{mydef}
 The \textbf{discounted value process} $V^{\xi} = (V^{\xi}_t)_{t=0}^T$ associated with a trading strategy $\xia$ is given by 
 \begin{equation*}
  V^{\xi}_t = \xia_t \cdot \Xa_t.
 \end{equation*}
\end{mydef}

\subsection{Arbitrage opportunities}
The value $V^{\xi}_0$ is the initial investment into the portfolio. Following definition introduces portfolios which do not receive cash flows from the ``outside world'' after initialization. They are rearranged in such a way that purchases of new assets must be covered by selling some other assets, so value of the portfolio before and after rearranging stays the same.
\begin{mydef}
 A dynamic trading strategy is called \textbf{self-financing} if and only if for every $0 \leq t \leq T$
 \[ \sum\limits_{i=0}^d d\xi^{(i)}_t (S^{(i)}_t + dS^{(i)}_t) = 0. \]
\end{mydef}
This definition, although being very simple, looks completely incomprehensible at first sight. To convey some intuition let's think that $dt$ is a very small, even infinitesimal, time period. Vector $\xia_t$ describes content of the portfolio at the beginning of the period. After time $dt$ change of the stock prices equals $dS_t$. The portfolio needs a rearrangment -- $d\xia_t$ means changes of quantities of the held assets.
Thus $\xia_t \cdot (\Sa_t + d\Sa_t)$ is the total cost of the rearrangment. From the definition it equals 0, what explains the name \textit{self-financing}.

From now on we will consider only those market models that are efficient in the sense that they are arbitrage-free.
\begin{mydef}
 An \textbf{arbitrage opportunity} is a self-financing portfolio $\xia$, such that
 \begin{align*}
  V^{\xi}_0 &= 0\\
  \P(V^{\xi}_T \geq 0) &= 1\\
  \P(V^{\xi}_T > 0 ) &> 0
 \end{align*}
 The market is \textbf{arbitrage-free} if it does not allow for arbitrage opportunities.
\end{mydef}
What does arbitrage opportunity mean in practice? Assume an investor entering the market without any money. He builds his portfolio by short sale of some assets and purchase of other assets for received money. Arbitrage opportunity is a situation when the investor at time $T$ can cover his short positions by sale of assets held long, and with positive probability he has some remaining cash.
In the other words, he can make money without exposure to any downside risk. 

Now we are moving to an important concept of martingule measure.
\begin{mydef}
 A probability measure $\Pm$ is a \textbf{martingale measure} if and only if the discounted price process $X$ is a $\Pm$-martingale, i.e. for all  $0 \leq s \leq t \leq T$
 \begin{equation}
  \label{eq:X-martingale}
  \Em[X_t] < \infty \hbox{\ \ and\ \ } \Em[X_t | \mathcal{F}_s] = X_s
 \end{equation}
\end{mydef}

\begin{remark}
 Condition (\ref{eq:X-martingale}) is written for a vector $X$, hence for every $1 \leq i \leq d$
  \begin{equation*}
  \Em[X^{(i)}_t] < \infty \hbox{\ \ and\ \ } \Em[X^{(i)}_t | \mathcal{F}_s] = X^{(i)}_s
 \end{equation*}
\end{remark}

Let us recall that two measures $\P$ and $\Pm$ defined on $\sigma$-algebra $\mathcal{F}$ are equivalent if and only if $\forall A \in \mathcal{F}.\ \P(A)=0 \Leftrightarrow \Pm(A)=0$. Next theorem, known as \textbf{first fundamental theorem of asset pricing}, shows importance of martingale measures.
\begin{thm}[\bfseries First FTAP]
 \label{thm:fftap}
 The following to statements are \emph{essentialy} equivalent:
 \begin{enumerate}
  \item The market model is arbitrage free.
  \item There exists martingale measure $\Pm$ equivalent to $\P$.
 \end{enumerate}
\end{thm}
Unfortunatly, due to an appearence of a word ``essentialy'', this is rather a ``meta-theorem''. It can be given a sharp, mathematical sense -- see for example Theorems 10.9 and 10.10 in \cite{bjork}. In the discrete case, however, theorem holds without the word ``essentialy'', as it is proven in \cite{follmer} (Theorem 5.17). This case is sufficient for us, since trajectories can be simulated only in a finite number of points.

\section{European contingent claims}
We start this section with definition of a mentioned contingent claim.
\begin{mydef}
 \label{def:cc_eu}
 \textbf{European contingent claim} is a non-negative random variable $C$ on $(\Omega, \mathcal{F}_T, \P)$. \textbf{Derivative} of underlying assets $S^{(0)}, S^{(1)}, \ldots, S^{(d)}$ is a contingent claim which is measurable with respect to $\sigma$-algebra generated by price processes.
\end{mydef}
European contingent claims may be seen as assets yielding a random payoff at \textbf{exercise date} $T$ (also called \textbf{maturity}). Of course the seller of such contingent claim can't take a random amount of money from the buyer. What should be then the price at time $0$? The answer to this question is definitely nontrivial. However, for some simple derivatives, e.g. European options, there exists a straightforward formula for the price.

\begin{mydef}
 An \textbf{European call option} on asset $S^{(i)}$ with exercise date $T$ and \textbf{strike price} $K$ gives it's owner the right, but not the obligation, to \underline{buy} that asset at time $T$ for a fixed price $K$.
 
 An \textbf{European put option} on asset $S^{(i)}$ with exercise date $T$ and \textbf{strike price} $K$ gives it's owner the right, but not the obligation, to \underline{sell} that asset at time $T$ for a fixed price $K$.
\end{mydef}
From the definition
\begin{equation}
 \label{eq:ecall}
 C\textsuperscript{call} = (S^{(i)}_T - K)_+
\end{equation}
\begin{equation}
 \label{eq:eput}
 C\textsuperscript{put} = (K - S^{(i)}_T )_+
\end{equation}
where $(x)_+ = \max(0,x)$.

A popular modification of above \textbf{vanilla options} are \textbf{barrier options}. Their payoff depends not only on the stock price at maturity, but also on historical prices. Barrier options are divided into \textit{knock-in} options, which may be ``turned on'', and \textit{knock-out} options, which may be ``turned off'' in case of reaching some \textbf{barrier}. Let us write down two example definitions
\begin{mydef}
Payoff of \textbf{up-and-in call} option on asset $S^{(i)}$ with exercise date $T$, strike price $K$ and barrier $\bar{B}$, is
\[ C^{\hbox{\scriptsize call}}_{\hbox{\scriptsize u\&i}} = 
\begin{cases}
 (S^{(i)}_T - K)_+    & \hbox{if } \sup\limits_{0 \leq t \leq T} S^{(i)}_t \geq \bar{B}\\
 0                    & \hbox{otherwise.}
\end{cases}
\]
\end{mydef}
Payoff of knock-out option is zeroed when barrier is reached.
\begin{mydef}
Payoff of \textbf{down-and-out put} option on asset $S^{(i)}$ with exercise date $T$, strike price $K$ and barrier $\underline{B}$, is
\[ C^{\hbox{\scriptsize put}}_{\hbox{\scriptsize d\&o}} = 
\begin{cases}
 (K - S^{(i)}_T)_+    & \hbox{if } \inf\limits_{0 \leq t \leq T} S^{(i)}_t \leq \underline{B}\\
 0                    & \hbox{otherwise.}
\end{cases}
\]
\end{mydef}
We have eight types of barrier options, as every one is call or put, up or down, in or out. They are all defined in similar manner. The best way to get a grip on barrier options is possibly through a graphical example. Figure \ref{fig:barrier} discusses payoff from an up-and-out call option in three diffrent scenarios. 
\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.3]{images/BasicsOfOptionPricing/barrier.pdf}
\caption{We consider up-and-out call option with strike 110, barrier 140, expiring at time 1. In the red scenario option is in-the-money at the maturity, however in the past barrier was crossed, thus payoff is 0. In the blue scenario stock price ends about the level of 115, barrier wasn't reached, hence payoff equals 5. In case of green scenario payoff is 0, as it would be for vanilla option, because we ended out-of-the-money. }
\label{fig:barrier}
\end{figure}

\section{Black-Scholes model}
In this section we recall famous Black-Scholes model, leading to a straightforward formula for the price of the European options. Here we are considering a market with only one stock $S$ and a bond $B$. The assumptions of that model are following.

\noindent \textbf{The underlying stock price follows a lognormal model.} Moreover drift $\mu$ and volatility $\sigma$ are constant in time. Thus, SDE for option price is described by equation
\begin{equation}
 \label{eq:stockDynamics}
 dS_t = \mu S_t dt + \sigma S_t dW_t. 
\end{equation}

\noindent \textbf{There exists constant risk-free interest rate $r$.} In the other words, dynamics of $B$ is given by 
\[ dB_t = rB_t dt. \]
Investors may both, borrow and lend, any amount of cash at rate $r$.

\noindent \textbf{It is possible to buy and sell any amount of stock.} It means that investors can even trade fractional numbers of stock, and short sell unbounded quantity of shares.

\noindent \textbf{All transactions do not incur any additional costs.}

\noindent \textbf{The market does not admit arbitrage opportunities.}

Suppose we are constructing a portfolio consisting of short position in one option and long position in $\Delta$ shares. 
Let $\Pi$ be the process of value of portfolio ($\Pi_t$ is value at time $t$), and $V$ be the process of price of the option ($V_t$ is price at time $t$). We have to make one more assumption. 

For some smooth function $V$ \textbf{the price process has the form:}
\[ V_t = V(S_t, t). \]
Note that symbol $V$ has an ambigous meaning -- in above formula left $V$ is price process and the right one is smooth function. However, as in many other literature, we do not bring in additional notation, since it does not lead to misunderstanding.

Many authors forget to mention this last assumption, altough it is very important. Without it we could not use It\^{o}'s lemma.

Equation of portfolio is given by
\begin{equation}
 \label{eq:portfolio}
  \Pi = \Delta S - V 
\end{equation}
We may ask how much the portfolio will change in a short period of time. We have
\[ d\Pi = \Delta dS - dV  \]
Note that we do not have to differentiate $\Delta$, because it does not change in an infinitesimal increment of time. To handle $dV$ we will use It\^{o}s lemma. Thus
\[ d\Pi = \Delta dS - \frac{\partial V}{\partial S}dS - \frac{\partial V}{\partial t}dt - \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 V}{\partial S^2}dt  \]
Risk in increment of portfolio is carriered by changes of stock price. By choosing
\begin{equation}
 \label{eq:delta}
 \Delta = \frac{\partial V}{\partial S}
\end{equation}
we get rid off uncertainity. Now we have
\begin{equation}
  \label{eq:portfolio_inc}
 d\Pi = -(\frac{\partial V}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 V}{\partial S^2})dt.
\end{equation}
Increment of $\Pi$ does not depend on any risky asset, hence no-arbitrage assumption induces
\[ d\Pi = r\Pi dt. \]
After substituting (\ref{eq:portfolio}), (\ref{eq:delta}) and (\ref{eq:portfolio_inc}) into above equation, we obtain
\[ -(\frac{\partial V}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 V}{\partial S^2})dt = r(\frac{\partial V}{\partial S} S - V)dt, \]
which after simple calculation gives
\begin{equation}
 \label{eq:BSeq}
 \frac{\partial V}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 V}{\partial S^2} + r\frac{\partial V}{\partial S} S - rV = 0.
\end{equation}
(\ref{eq:BSeq}) is known as \textbf{Black-Scholes equation}. Note that so far we did not say anything about the final condition of (\ref{eq:BSeq}), i.e. about the payoff off the option, thus this is a general equation. For European options it has straightforward solution.

\begin{align*}
V_t\textsuperscript{call} &= \Phi[d_1(t)]S_t  - \Phi[d_2(t)]K e^{-r(T-t)},\\
V_t\textsuperscript{put} &= -\Phi[-d_1(t)]S_t + \Phi[-d_2(t)]K e^{-r(T-t)},
\end{align*}
where
\begin{align*}
d_1(t) &= \frac{\ln\left(\frac{S_t}{K}\right)+\left(r+\frac{\sigma^{2}}{2}\right)(T-t)}{\sigma\sqrt{T-t}}\\
d_2(t) &= \frac{\ln\left(\frac{S_t}{K}\right)+\left(r-\frac{\sigma^{2}}{2}\right)(T-t)}{\sigma\sqrt{T-t}} = d_{1}(t)-\sigma\sqrt{T-t},\\
\Phi & \hbox{ is distibution function of standard normal distribution. } 
\end{align*}

{\Large \color{red} Wskazac pozycje z dowodem}
It is called \textbf{Black-Scholes formula}.

\section{Risk-neutral pricing}
\label{sec:risk-neutral}
Black-Scholes formula allows us to price only European vanilla options. In this section we present a general method of pricing European contingent claims. 
\begin{mydef}
 The discounted value of the contingent claim $C$ is given by
 \begin{equation*}
  H = \frac{C}{S^{(0)}_T}.
 \end{equation*}
 Random variable $H$ is called a \textbf{discounted claim}.
\end{mydef}

Values $C$ and $H$ correspond to the payoff of an instrument. We need notation to talk about its price also before maturity.
\begin{notation}
 The (discounted) \textbf{price process} is denoted by $V_t$. 
\end{notation}
\begin{remark}
 In section \textit{Black-Scholes model} value $V_t$ denoted price of the option at time $t$ (no discounting). From now on $V_t$ is price of the contingent claim at time $t$ discounted to time~$0$.
\end{remark}

Next theorem is the key to defining prices of contingent claims. But first we define a class of claims for which pricing is pretty straightforward. 
\begin{mydef}
 A contingent claim is called \textbf{attainable} if there exists a self-financing trading strategy $\xia$ whose portfolio coincides with $C$ at maturity, i.e.
 \[ C = \xia \cdot \Sa_T. \]
 The trading strategy $\xia$ is then called the \textbf{replicating strategy} for $C$.
\end{mydef}

\begin{thm}
 For every attainable discounted claim $H$ and for every equivalent martingale measure $\Pm$
 \[ \Em [H] < \infty. \]
 Moreover, for every replicating strategy $\xia$ its value process satisfies
 \begin{equation}
  V^\xi_t = \Em[H | \mathcal{F}_t] \hbox{ P-a.s., } 0 \leq t \leq T .
 \end{equation}
\end{thm}
Proof of this theorem reader may find in \cite{follmer}.

Since there is no $\xia$ in term $\Em[H | \mathcal{F}_t]$, so value $V^\xi_t$ does not depend on choice of $\xia$. Note also that
\begin{equation*}
 \Em[H | \mathcal{F}_t]  = \Em[\xia \cdot \Xa_T | \mathcal{F}_t]  = \xia \cdot \Xa_t
\end{equation*}
Thus, value $\Em[H | \mathcal{F}_t]$ does not depend on choice of $\Pm$. 
Since attainable discounted claim $H$ and its replicating strategy $\xia$ have the same payoff at time $T$, thus no-arbitrage assumption induces
\[ V_t = V^\xi_t,\ \ 0 \leq t \leq T. \]
Thus in particular it implies
\begin{coro}
\label{coro:price_mth}
Let $H$ be a discounted contingent claim and $V$ be its price process. Then
\begin{equation}
 \label{eq:price_mtg}
 V_0 = \Em[H].
\end{equation}
\end{coro}
\noindent This equation tells us that \textbf{value of the option is an expactaion of its payoff} (under the risk-neutral measure).

The above theorem suggests how price processes should look in general.
\begin{mydef}
 The (discounted) price process of the discounted claim $H$ is given by
 \begin{equation*}
  V_t \gets \Em[H | \mathcal{F}_t].
 \end{equation*}
 Such $V$ is a $\Pm$-martingale.
\end{mydef}
For general claims process $V$ depends on choice of an equivalent martingale measure. However, it may be proven that the market model consisting of the discounted assets $(X^{(0)}, X^{(1)},\ldots,X^{(d)}, V)$ is arbitrage-free, regardless of the choice of $\Pm$. In that sense every possible price process $V$ is equally good.

\subsection{Change of the measure}
We have discussed how equivalent martingale measures can be used for option pricing, but so far we did not tell how to find them. For this purpose Girsanov theorem is very usefull.

\begin{prop}
\label{prop:measure_change}
 Suppose that all risky assets on the market follow the geometric Brownian motion, that is for $i=1,2,\ldots,d$
 \begin{equation}
  \label{eq:dynamics_real}
  dS^{(i)} = \mu_i S^{(i)} dt + \sigma_i S^{(i)} d\bar{W}^{(i)},
 \end{equation}
 where each $\bar{W}^{(i)}$ is a Brownian motion under measure $\P$ and $corr(\bar{W}^{(i)}, \bar{W}^{(j)}) = \rho_{ij}$. For every vector $(\nu_1, \nu_2, \ldots, \nu_d)$ there exists equivalent probability measure $\mathbb{Q}$, such that the equation (\ref{eq:dynamics_real}) may be rewritten in the form
  \begin{equation}
  dS^{(i)} = \nu_i S^{(i)} dt + \sigma_i S^{(i)} dW^{(i)},
 \end{equation}
 where each $W^{(i)}$ is a Brownian motion under equivalent measure $Q$ and\\ $corr^Q(W^{(i)}, W^{(j)}) = \rho_{ij}$.
\end{prop}

\begin{proof}
 Let $\Sigma = (\rho_{ij})_{i,j=1}^d$ be a correlation matrix. Cholesky's algorithm allows us to decompose $\Sigma$ to the form
 \[ \Sigma = LL^T. \]
 Hence, $\bar{W}$ may be written in the form
 \[ \bar{W} = L \bar{V}, \]
 where $\bar{V}$ is a standard $d$-dimensional Wiener process under measure $\P$. Let us apply Theorem \ref{thm:girsanov} (Girsanov theorem) with $\varphi = (\theta_1, \theta_2, \ldots, \theta_d)'$, where all $\theta_i$ are constant. It implies that
 \[ V_t = \bar{V}_t - t\theta_i \]
 is $d$-dimensional standard Wiener process under measure $\mathbb{Q}$. Thus
 \begin{equation*}
  \begin{split}
   dS^{(i)} &= \mu_i S^{(i)} dt + \sigma_i S^{(i)} d\bar{W}^{(i)} \\
            &= \mu_i S^{(i)} dt + \sigma_i S^{(i)} d\left(\sum\limits_{k=1}^d l_{ik} \bar{V}^{(k)}\right) \\
            &= \mu_i S^{(i)} dt + \sigma_i S^{(i)} \left(\sum\limits_{k=1}^d l_{ik}\theta_i dt + l_{ik}d V^{(k)}\right) \\    
            &= \left(\mu_i + \sigma_i \theta_i \sum\limits_{k=1}^d l_{ik} \right) S^{(i)} dt + \sigma_i S^{(i)} d\left(\sum\limits_{k=1}^d l_{ik} V^{(k)}\right) \\    
  \end{split}
 \end{equation*}
 By substituting
 \begin{align*}
  \theta_i &\gets (\nu_i - \mu_i)/(\sigma_i \sum\limits_{k=1}^d l_{ik})\\
  W &\gets LV
 \end{align*}
 we get the thesis.
\end{proof}

Above propostion allows us to describe vector of price processes in terms of some equivalent measures, however we need a very particular measure -- the martingale measure.

\begin{coro}
\label{coro:rn-dynamics}
 In real measure $\P$ the risky assets follow a geometric Brownian motion, as in equation (\ref{eq:dynamics_real}). Under equivalent martingale measure $\Pm$ the dynamics has the form
 \begin{equation}
  \label{eq:dynamics_neutral}
  dS^{(i)} = r S^{(i)} dt + \sigma_i S^{(i)} dW^{(i)}.
 \end{equation}
\end{coro}
\begin{proof}
 Proposition \ref{prop:measure_change} states that there exist equivalent measure $\Pm$ under which price processes are described by equation (\ref{eq:dynamics_neutral}). We will show that it is martingale measure.
 From (\ref{eq:gmb_sol})
 \[ X_t = e^{-rt} S_t = S_0 e^{ \frac{1}{2}\sigma^2 t + \sigma W_t }. \]
 Let $0 \leq s \leq t \leq T$. We have
 \begin{equation*}
  \begin{split}
   \Em[X_t | \mathcal{F}_s] &= \Em[ S_0 e^{ \frac{1}{2}\sigma^2 t + \sigma W_t } | \mathcal{F}_s] \\
       &= S_0 e^{\frac{1}{2}\sigma^2 t} \Em[ e^{  \sigma W_s} e^{ \sigma (W_t - W_s) } | \mathcal{F}_s] \\
       &= S_0 e^{\frac{1}{2}\sigma^2 t + \sigma W_s} \Em[ e^{ \sigma (W_t - W_s) }] \\
       &= S_0 e^{\frac{1}{2}\sigma^2 t + \sigma W_s}  e^{ -\frac{1}{2}\sigma^2(t-s) } \\
       &= S_0 e^{\frac{1}{2}\sigma^2 s + \sigma W_s}.
  \end{split}
 \end{equation*}
Hence $\Pm$ is an equivalent martingale measure.
\end{proof}


\chapter[{Pricing European options with Monte Carlo method}]{Pricing European options using \\Monte Carlo method}
The Black-Scholes theory gives us compact formula for pricing european vanilla options. Such options gained popularity and are traded in many world markets. However, over the counter (ab. OTC) investors may trade much more complicated instrumets, whose value can not be derived analitically. Thus, other methods must be used.
The most popular are finite diffrence, binomial trees and Monte Carlo. In this thesis only the last one is presented.

\section{Pricing vanilla options}
\label{sec:pricing_vanilla}

In order to use the Monte Carlo method in option pricing, we need to involve the theory presented in the section \ref{sec:risk-neutral}. First we will focus on the case, when the only instruments traded in the market are $B = S^{(0)}$ -- a riskless bank account, and a risky asset $S = S^{(1)}$.

From Corollary \ref{coro:price_mth} we have
\begin{equation}
 \label{eq:price_for_MC}
 V_0 = \Em[H].% = \Em[\frac{C}{S^{(0)}_T}] = e^{-rT} \Em[C].
\end{equation}
By comparision with (\ref{eq:EY}), we see that equation (\ref{eq:price_for_MC}) is exactly what we need for simulations. To calculate options price we have to replicate its payoff many times and take an average. Note, however, that expectaion is taken under the risk-neutral measure. Hence, also the asset price must be generated under the risk-neutral measure. Corollary \ref{coro:rn-dynamics} describes its dynamics:
\[ dS = rSdt + \sigma S dW. \]
Lemma \ref{lemma:solution_dynamics} gives the solution to above SDE:
\begin{equation}
 \label{eq:vanilla_St}
 S_t = S_0 \exp\left\{ (r - \frac{1}{2}\sigma^2)t + \sigma W_t \right\}.
\end{equation}
In case of vanilla options only the value at the end of the trajectory is important, i.e. at maturity time $T$. Thus, we need
\begin{equation}
\label{eq:vanilla_ST}
 S_T = S_0 \exp\left\{ (r - \frac{1}{2}\sigma^2)T + \sigma W_T \right\},
\end{equation}
where, from properties of the Wiener process, $W_T \sim \mathcal{N}(0,T)$. Value of $S_T$ depends on $W_T$, hence it is justified to write $S_T = S_T(W_T)$.

Let $H = g(S_T)$ and $E$ be the strike price. For instance, if $H$ is a call option $g(x) = (x - E)_+$, and if $H$ is a put $g(x) = (E - x)_+$, but in fact $H$ might be any claim whose payoff depends only on $S_T$. Equation (\ref{eq:vanilla_ST}) tells us how to generate the asset price; by applying function $g$ we generate the payoff.
Since $S_T$ is also a function of some $Z \sim \mathcal{N}(0,T)$, thus actually $H = g(S_T(Z)) =: f(Z)$, for $f = g \circ S_T$. By $Z_i, i = 1,2,...$, we will denote replications of $Z$.
The crude Monte Carlo estimator has the form:
\begin{equation}
 \label{eq:vanilla_CMC}
 \CMCa[H, 2n] = \frac{1}{2n}\sum\limits_{i=1}^{2n} f(Z_i).
\end{equation}
We will also use antithetic variates, where an antithetic variable to $f(Z_i)$ will be  $f(-Z_i)$. 
\begin{equation}
 \label{eq:vanilla_AV}
 \AVa[H, n] = \frac{1}{n}\sum\limits_{i=1}^{n} \frac{f(Z_i) + f(-Z_i)}{2}.
\end{equation}
To use the control variates method, recall that $S_0 = \Em[S_T]$. It implies that we can take $S_T$ as a control variate, hence
\begin{equation}
 \label{eq:vanilla_CV}
 \CVa[H, n] = \frac{1}{n}\sum\limits_{i=1}^{n} \left( f(Z_i) + c (S_T(Z_i) - S_0) \right),
\end{equation}
where $c$ is a value calculated as in equation (\ref{eq:CVc}).

To get a grip on using above estimators in practice, we present how exactly looks pricing call options using the control variates method. It is shown in Algorithm \ref{alg:priceCallCV}. Argument of the algorithm is \texttt{n} -- number of simulations. 
\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{PriceCallCV}{$n$, $S_0$, $\sigma$, $r$, $T$, $E$ }
    \State  $S,H,Y \gets $ arrays with indices from 1 to $n$.
    \For{$i = 1$ {\bf to} $n$} 
      \State $Z \gets$ generate standard normal
      \State $S[i] \gets S_0 \cdot \exp\{ (r - \frac{1}{2}\sigma^2 ) \cdot T + \sigma \cdot Z \}$
      \State $H[i] \gets \max(S - E, 0) \cdot \exp\{-rT\}$
    \EndFor
    \State $c \gets -\Cov(H,S)/\Var(S)$
    \For{$i = 1$ {\bf to} $n$} 
      \State $Y[i] \gets  H[i] + c\cdot \bigl(S[i] - S_0\cdot \exp\{rT\} \bigr)$
    \EndFor    
    \State $price \gets mean(Y)$
    \State $var \gets var(Z)$
    \State $se \gets \sqrt{var / n}$
    \State \Return $(price, var, se)$
  \EndFunction
 \end{algorithmic}
 \caption{Valuation of a call option using CV method.}
 \label{alg:priceCallCV}
\end{algorithm}
Values calculated in lines 12-14 are price of the option, variance and standard error of the estimation.

Implementation of an option pricer based on estimators (\ref{eq:vanilla_CMC})-(\ref{eq:vanilla_CV}) allows us to compare these methods. In sections \ref{sec:pricing_vanilla} and \ref{sec:pricing_complicated} we will always assume following parameters:
\begin{equation}
\label{eq:marketParams}
\begin{split}
 S &= 100 \\
 \sigma &= 0.20 \\
 r &= 0.05 \\
 T &= 1 \hbox{\ \ \ (options expire after one year)}
\end{split}
\end{equation}
First consider a call option with strike 90. The Black-Scholes value of the option is 16.70. Results of the Monte Carlo pricing are shown in Table \ref{tab:vanilla1} and Figure \ref{fig:vanilla1}.

\begin{table}
\centering
 \caption{Results of pricing call@90. Black-Scholes price is 16.70.}
 \label{tab:vanilla1}
\begin{tabular} {||r | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 17.09 & 0.393 & 16.67 & 0.185 & 16.74 & 0.127 \\ \hline 
10000  & 16.98 & 0.123 & 16.66 & 0.061 & 16.67 & 0.041 \\ \hline 
100000 & 16.71 & 0.039 & 16.67 & 0.019 & 16.70 & 0.013 \\ \hline 
\end{tabular}  
\end{table}
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxCall90.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergenceCall90.pdf}
\caption{Accuracy of pricing call@90. Box plot on the left was created by running estimation 100 times for each method, each estimation used 10000 replicated pairs. Chart on the right shows speed of convargence, i.e. how the estimation changes as the number of performed replications increases. The horizontal line is the options value calculated form Black-Scholes formula. }
\label{fig:vanilla1}
\end{figure}

It is clear, that in this case CV method proved itself the best. It is caused by the fact, that in many simulations option expires in the money. In consequence the payoff is highly correlated with the asset price at the end of the path. Let us consider now a call with higher strike, 130, whose Black-Scholes price equals 1.64. Look at the Table \ref{tab:vanilla2} and Figure \ref{fig:vanilla2}. 

\begin{table}
\centering
 \caption{Results of pricing call@130. Black-Scholes price is 1.64.}
 \label{tab:vanilla2}
\begin{tabular} {||r | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 1.67 & 0.135 & 1.56 & 0.126 & 1.67 & 0.147 \\ \hline 
10000  & 1.61 & 0.043 & 1.60 & 0.041 & 1.60 & 0.046 \\ \hline 
100000 & 1.63 & 0.014 & 1.64 & 0.013 & 1.64 & 0.015 \\ \hline 
\end{tabular}  
\end{table}
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxCall130.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergenceCall130.pdf}
\caption{Accuracy of pricing call@130. Plots were created in the similar manner as on the Figure \ref{fig:vanilla1}.}
\label{fig:vanilla2}
\end{figure}
This time the asset price usually ended above the options strike, what means that in most simulations payoff was 0. Thus, correlation between payoff and assets final price is low, and in consequence CV did not bring a significant improvement.
\begin{remark}
 Box plot from Figure \ref{fig:vanilla2} shows that CMC estimator has smaller dispersion than AV and CV. That is because we compare $\CMCa[H, 2n]$ (index is $2n$) with $\AVa[H, n]$ and $\CVa[H, n]$. We do so, because then the number of used random variables is the same in each estimator.
 However, generating an antithetic variate or a control variate is often instantaneous. Hence calculating $\CMCa[H, 2n]$ may be much slower. If in time $t$ we can compute  $\CMCa[H, a]$, $\AVa[H, b]$ and $\CVa[H, c]$, then $\CMCa[H, a]$ will always\footnote{Of course we assume that antithetic variate is really antithetic, i.e. it is negatively correlated with the base variate, and control variate is not independent from the base variate.} have greater variance than $\AVa[H, b]$ and $\CVa[H, c]$.
\end{remark}

\section{Pricing path-depenent instruments}
\label{sec:pricing_complicated}

To price vanilla options it was sufficient to generate the asset price only at the maturity. However, there are contingent claims whose payoff depends on the entire history, for example barrier options or Asian options. Of course, we can not generate the entire trajectory, since it has continuum points. Thus, values of the asset must be generated in a finite number $K$ of points. By taking $K$ large enough, a continous model is approximated sufficiently.

It follows from equation (\ref{eq:vanilla_St}) that
\begin{equation}
 \label{eq:priceChange}
 S_{t + {\Delta} t} = S_t \exp\left\{ (r - \frac{1}{2}\sigma^2)\Delta t + \sigma \sqrt{\Delta t} Z \right\},
\end{equation}
where $Z$ is standard normal. Above formula allows us to generate prices of the asset in specified points step by step.

Figure \ref{fig:trajectories} shows a thousand of trajectories simulated accordingly to equation (\ref{eq:priceChange}). Note that the mean of the asset price at the final time is slightly above $S_0 = 100$. It corresponds to the fact that $\Em [S_T] = e^{rT}S_0$, which for parameters of the simulations equals $100\cdot e^{0.05} \approx 105.13$.

\begin{figure}[ht]
\centering
 \includegraphics[scale=0.4]{images/PricingEuropean/trajectories50.pdf}
\caption{A thousand of simulated trajectories of the asset price, under paratemeters ${T=1},\ {\sigma=0.2}$, ${r=0.5},\ {S_0=100}$. Each path was generated in $K=50$ points. The darker is the area the greater is the concentration of trajectories.}
\label{fig:trajectories}
\end{figure}

In theory, value of the discounted claim now has the form $H = g(S)$, for some $g$, i.e. $H$ is a function of the whole process $S$. As mentioned before, in order to make $H$ computable, we are forced to treat $H$ as a function of $S$ in limited number of points, that is $H = g\bigl(S_0, S_{\Delta t}, ..., S_T\bigr),\ T = K\cdot\Delta t$.
Path replications will be denoted by $S_i\ (i=1,2,...$), i.e. value $S_{i,t}$ means what was the asset price at time $t$, on $i$-th simulated path. The CMC estimator is analogous to (\ref{eq:vanilla_CMC})
\begin{equation*}
 \CMCa[H, n] = \frac{1}{n}\sum\limits_{i=1}^n g\bigl(S_{i,0}, S_{i,\Delta t}, ..., S_{i,T}\bigr)
\end{equation*}
For example for Asian call option
\begin{equation*}
 \CMCa[H, n] = \frac{1}{n}\sum\limits_{i=1}^n \left( \frac{1}{K} \sum\limits_{j=1}^K S_{i,j \Delta t} - E \right)_+
\end{equation*}
and for a put option with down-and-out barrier $B$
\begin{equation*}
 \CMCa[H, n] = \frac{1}{n}\sum\limits_{i=1}^n \left( (E - S_{i,T})_+ \cdot \prod\limits_{j=0}^K \mathbbm{1}\bigl(S_{i,j \Delta t} \geq B\bigr) \right).
\end{equation*}
Adjusting above estimators to use control variates does not bring any difficulties. The asset price at the end of the path may still be the control variate, however, better suited is the payoff from the analogous vanilla option (at least for barrier and Asian options). For instance for Asian put option
\begin{equation*}
 \CVa[H, n] = \CMCa[H, n] + \frac{c}{n} \sum\limits_{i=1}^n \Bigl( (E - S_{i,T})_+ - \Em (E - S_T)_+ \Bigr),
\end{equation*}
where $c$ is calculated as in (\ref{eq:CVc}) and value $\Em (E - S_T)_+$ is known from Black-Scholes formula.

In previous section while using AV method, we generated negatively correlated variables representing the asset price at the expiry of the option. Since now payoff depends on the whole process, thus we have to generate the antithetic trajectories. Algorithm \ref{alg:single-tr} describes how to do it. Figure \ref{fig:trajectoriesAnti} gives an idea how antithetic paths look like.
We omit exact formulas for $\AVa[H, n]$, because they are becoming lengthy and overly complicated. Analysing an example application of AV method should be sufficient to understand how it works in general. To this end, we present procedure of pricing Asian call options (Algorithm \ref{fig:trajectoriesAnti}).

\begin{figure}
\centering
 \includegraphics[scale=0.8]{images/PricingEuropean/trajectoriesAnti.pdf}
\caption{Pair of antithetic trajectories generated by an implementation of Algorithm \ref{alg:single-tr}.}
\label{fig:trajectoriesAnti}
\end{figure}
\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{Trajectory}{$S_0$, $\sigma$, $r$, $T$, $K$}
  \State pos, neg $\gets$ arrays with indices from $0$ to $K$
  \State pos[0] $\gets$ neg[0] $\gets S_0$
  \State $dt \gets T/K$
  \For{$i=1$ {\bf to} $K$}
    \State $Z \gets$ generate standard normal
    \State pos[$i$] $\gets$ pos[$i-1$] $\cdot \exp\left\{ (r - \frac{1}{2}\sigma^2) dt + \sigma \sqrt{dt} Z \right\}$
    \State neg[$i$] $\gets$ neg[$i-1$] $\cdot \exp\left\{ (r - \frac{1}{2}\sigma^2) dt - \sigma \sqrt{dt} Z \right\}$
  \EndFor
  \State \Return (pos, neg)
  \EndFunction
 \end{algorithmic}
 \caption{Generating antithetic trajectories.}
 \label{alg:single-tr}
\end{algorithm}
 
\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{priceAsianCallAV}{$n$, $S_0$, $\sigma$, $r$, $T$, $E$, $K$}
    \State  $sum \gets sum\_sq \gets 0$
    \For{$i=1$ {\bf to} $n$}
      \State (pos,neg) $\gets$ \Call{Trajectory}{$S_0$, $\sigma$, $r$, $T$, $K$}
      \State $H_{pos} \gets \max($mean(pos)$- E, 0) \cdot \exp\{-rT\}$
      \State $H_{neg} \gets \max($mean(neg)$- E, 0) \cdot \exp\{-rT\}$
      \State $H \gets \frac{1}{2} \cdot (H_{pos} + H_{neg})$
      \State $sum \gets sum + H$
      \State $ sum\_sq \gets sum\_sq + H^2$
    \EndFor
    \State $var \gets (sum\_sq - sum \cdot sum/n) / (n-1)$
    \State $se \gets \sqrt{var / n}$
    \State $price \gets sum / n$
    \State \Return $(price, var, se)$
  \EndFunction
 \end{algorithmic}
 \caption{Pricing Asian call options}
 \label{alg:priceAsianAV}
\end{algorithm}

In a similar manner we can value any path-dependent options. For instance we present results of pricing some barrier options. In this section we still set market parameters as in (\ref{eq:marketParams}), moreover we take
\[ K = 50, \]
it may be regarded as checking once a week if barrier was hit.

Suppose $S$ is an exchange rate between some currencies. Consider an exporter whose production becomes unprofitable when exchange rate becomes too low. He would like to be hedged for pesimistic scenarios, thus he is interested in purchasing put options with strike 100, whose price from the Black-Scholes formula is 5.57.
In order to save some capital he prefers cheaper barrier options rather than vanilla options. He may think the following: ``If the exchange rate at some point will be very high, then it is very likely that my option will expire worthless. It means that I will not need an option when the rate is high.''. Thus he may decide to buy put options with strike 100 and with up-and-out barrier 115.
Monte Carlo methods allow us to price such an instrument, and the results are gathered in Table \ref{tab:barrier1} and Figure \ref{fig:barrier1}. On the other hand, the exporter may think: ``I can stand if the rate is not too bad. However, if the situation gets really ugly, I would like to sell part of my production for good money.''. Hence, he may be interested in put options with strike 100 and with down-and-in barrier 70.
Table \ref{tab:barrier2} and Figure \ref{fig:barrier2} present results of pricing such instrument with Monte Carlo methods.

\begin{table}
\centering
 \caption{Results of pricing put@100 with up-and-out barrier 115. Black-Scholes price of the option without barrier equals 5.57.}
 \label{tab:barrier1}
\begin{tabular} {||r | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 5.10 & 0.189 & 5.13 & 0.150 & 5.20 & 0.072 \\ \hline 
10000  & 5.14 & 0.060 & 5.15 & 0.049 & 5.15 & 0.023 \\ \hline 
100000 & 5.20 & 0.019 & 5.17 & 0.015 & 5.18 & 0.007 \\ \hline 
\end{tabular}  
\end{table}
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxPut100UaO115.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergencePut100UaO115.pdf}
\caption{Accuracy of pricing put@100 with up-and-in barrier 115. Plots were created in the similar manner as on the Figure \ref{fig:vanilla1}.}
\label{fig:barrier1}
\end{figure}

\begin{table}
\centering
 \caption{Results of pricing put@100 with down-and-in barrier 70. Black-Scholes price of the option without barrier equals 5.57.}
 \label{tab:barrier2}
\begin{tabular} {|r |c |c |c |c |c |c |}  
 \hline 
  n & CMC.est & CMC.se & AV.est & AV.se & CV.est & CV.se \\ \hline \hline 
1000   & 1.33 & 0.138 & 1.38 & 0.135 & 1.37 & 0.152 \\ \hline 
10000  & 1.29 & 0.043 & 1.31 & 0.043 & 1.31 & 0.049 \\ \hline 
100000 & 1.38 & 0.014 & 1.36 & 0.014 & 1.36 & 0.016 \\ \hline 
\end{tabular}
\end{table}  
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxPut100DaI70.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergencePut100DaI70.pdf}
\caption{Accuracy of pricing put@100 with down-and-in barrier 70. Plots were created in the similar manner as on the Figure \ref{fig:vanilla1}.}
\label{fig:barrier2}
\end{figure}

As previously, CV seems to be the best method when payoffs from vanilla option and barrier options are highly correlated. It is the case when pricing put@100 with up-and-out barrier 115. Option expires in the money when asset prices are low, while reaching the barrier happens when prices are high.
Hence in most cases if option ended in the money, then the barrier was not hit, and if the barrier was hit, then option would expire worthless anyway. Thus payoff of barrier and vanilla options are highly correleated.

In the case of put@100 with down-and-in barrier 70, barrier is set very low; hitting it happens seldom, thus often option expires worthless even if analogous vanilla option ends in the money. In consequence correlation between payoffs of the barrier and the vanilla option becomes low, and in this case AV method gives slightly better accuracy. 

At the end of this section, it is worth to mention, that there exist analitical formulas for prices of European barrier options, see \cite{wilmott}, chapter 23.

\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/chart3dCallUaO.png}
\caption{Value of an European option call option with up-and-out barrier as a function of strike and barrier values.}
\label{fig:barrier3d}
\end{figure}

\section{Pricing multiasset instruments}

\chapter{Least Squares Monte Carlo}
\section{The idea of LSM}
%\paragraph{Problems with Monte Carlo method for american options.}
\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.5]{images/LSMIdea/LSMidea1.pdf}
\caption{To co chcemy}
\end{figure}
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/LSMIdea/LSMidea2.pdf}
\caption{To co mozemy}
\end{figure}

\begin{thebibliography}{99}
\addcontentsline{toc}{section}{\bfseries References}

\bibitem{bjork}
T. Bj\"{o}rk, \emph{Arbitrage Theory in Continuous Time}, Oxford University Press,  New York, 3rd edition, 2009

\bibitem{follmer}
H. F\"{o}llmer, A. Schied, \emph{Stochastic finance. An introduction in discrete time}, Walter de Gruyter, Berlin, 2nd edition, 2004

\bibitem{latala}
R. Latała, \emph{Wstęp do Analizy Stochastycznej}, Warszawa, 2011

\bibitem{london}
J. London, \emph{Modeling derivatives in C++}, John Wiley \& Sons, Hoboken, 2005

\bibitem{l-sch}
F. Longstaff, E. Schwartz, \emph{Valuing American Options by Simulation: A Simple Least Swuares Approach}, The Review of Financial Studies, Vol.14, No.1, pp.113-147, 2001

\bibitem{wilmott}
P. Wilmott, \emph{On quantitative finance}, John Wiley \& Sons, Chichester, 2nd edition, 2006

\end{thebibliography}


\end{document}
