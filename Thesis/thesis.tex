\documentclass[a4paper,11pt, twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsthm, amssymb}
\usepackage[polish, english]{babel}
\usepackage[OT4]{fontenc}
\usepackage[left=2.5cm,right=2.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage[section]{placeins} % keeps floats in their places
\usepackage{graphicx}
\usepackage{color}
\usepackage{titlesec}
\usepackage{listings} % allows inclusion of code snippets
\usepackage[chapter]{algorithm} % allows to keep algorithms as floats
\usepackage{algpseudocode} % allows writing pseudocodes
\usepackage[font={small,sl}]{caption}
\usepackage{bbm}
\usepackage{subfig} % placing floats side by side
\usepackage{rotating}

% pretty display of a chapter/part
\addto\captionsenglish{
  \renewcommand\chaptername{Part}}
\titleformat{\chapter}[display]
  {\normalfont\Large\filcenter\sffamily}
  {\titlerule[1pt]%
   \vspace{1pt}%
   \titlerule
   \vspace{1pc}%
   \LARGE\MakeUppercase{\chaptertitlename} \Roman{chapter}
  }
  {1pc}
  {\titlerule
  \vspace{1pc}%
  \Huge}


\newtheorem{thm}{Theorem}[chapter]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{coro}[thm]{Corollary}
\newtheorem{lemma}[thm]{Lemma}

\theoremstyle{definition}
\newtheorem{mydef}{Definition}[chapter]
\newtheorem{notation}[mydef]{Notation}
\newtheorem{example}{Example}[chapter]

\theoremstyle{remark}
\newtheorem{remark}{Remark}[chapter]

% \newcounter{example}
% \newenvironment{example}
%   {\refstepcounter{example} \par\medskip\noindent \textbf{Example~\arabic{example}.}  }
%   {\begin{flushright}$\square$\end{flushright}}
  
\def\Var{{\rm Var}}
\def\E{{\mathbb{E}}}
\def\P{{\mathbb{P}}\,}
\def\Q{{\mathbb{Q}}\,}
\def\Cov{{\hbox{Cov}}}
\def\Corr{{\hbox{Corr}}}
\def\Em{{\mathbb{E}^*}\,}
\def\Pm{{\mathbb{P}}^*\,}
\def\R{{\mathbb{R}}}
\def\conv{\xrightarrow[n \rightarrow \infty]{}}
\def\limn{\lim\limits_{n \rightarrow \infty} }
\def\Sa{\bar{S}}
\def\Xa{\bar{X}}
\def\xia{\bar{\xi}}
\def\CMC[#1]{\hat{Y}^{\hbox{\tiny CMC}}_{#1}}
\def\AV[#1]{\hat{Y}^{\hbox{\tiny AV}}_{#1}}
\def\CV[#1]{\hat{Y}^{\hbox{\tiny CV}}_{#1}}
\def\CMCa[#1, #2]{\hat{#1}^{\hbox{\tiny CMC}}_{#2}}
\def\AVa[#1, #2]{\hat{#1}^{\hbox{\tiny AV}}_{#2}}
\def\CVa[#1, #2]{\hat{#1}^{\hbox{\tiny CV}}_{#2}}
\def\bpipe{{\bigl|\bigr.}}
\def\Bpipe{{\Bigl|\Bigr.}}
\DeclareMathOperator*{\esssup}{ess\,sup}

\definecolor{comment}{RGB}{96,96,192}


%opening
\title{Pricing Exotic Options using Monte Carlo methods}
\author{Grzegorz Łoś}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[RO]{\small\bfseries\thepage}
\fancyhead[LE,RO]{\small\bfseries\thepage} %do odkomentowania w wersji dwustronnej
\fancyhead[LO]{\small\bfseries\nouppercase\rightmark}
\fancyhead[RE]{\small\bfseries\nouppercase\leftmark} %do odkomentowania w wersji dwustronnej

%\lhead{\nouppercase{\bfseries \leftmark}}
%\rhead{\nouppercase \rightmark}
\setlength{\headheight}{15pt}

\begin{document}
 
\thispagestyle{empty}
\begin{center}
\textbf{\large Uniwersytet Wrocławski\\
Wydział Matematyki i Informatyki\\
Instytut Matematyczny}\\
\vspace{4cm}
\textbf{\textit{\large Grzegorz Łoś}\\
\vspace{0.5cm}
{\Large Pricing Exotic Options using Monte Carlo methods}}\\
\end{center}
\vspace{3cm}
{\hspace*{6.5cm}\large Praca magisterska\\
\hspace*{6.5cm}\large  napisana pod kierunkiem\\
\hspace*{6.5cm}\large  doktora Pawła Kawy }
\vfill
\begin{center}
{\large Wrocław 2013}\\
\end{center}

\newpage
\thispagestyle{empty}
\vspace*{10cm}
\noindent {\large Oświadczam, że pracę magisterską wykonałem samodzielnie\\ i~zgłaszam ją do oceny.\\[1.5cm]
Data:....................\hfill Podpis autora pracy:.........................\\[1.5cm]
Oświadczam, że praca jest gotowa do oceny przez recenzenta.\\[1.5cm]
Data:.................... \hfill Podpis opiekuna pracy:.........................}

\newpage

\tableofcontents

\newpage


\chapter*{Abstract}

%\section*{\begin{center}\begin{normalsize} Abstract \end{normalsize}\end{center}}
\begin{quotation}
\noindent
  This thesis presents techniques of option pricing based on Monte Carlo simulations. Mathematical theories underlying the presented methods are recalled, however, the thesis is practical in nature, hence it not always gets deep into mathematical details.
  Instead, it provides many algorithms in the form of concise pseudocode, which outline how to use the theory in practice. The utility of depicted methods is affirmed by implementations in R and Java programming languages. This paper is filled with illustrations of the results obtained by the created application.
  
  The first part of the thesis gathers a group of definitions and facts from the probability theory which are essential for the thesis, like It\^{o}'s lemma Girsanov theorem, a general description of Monte Carlo methtods.
  In the second part, Reader may find an introduction to option pricing. It contains description of the market model, Black-Scholes paradigm, definition of the martingale measure. It also provides a detailed explanation how to calibrate parameters of the Black-Scholes model from the real-world market's history.
  In the next part, the Monte Carlo pricing procedure for European options is described. It starts with simple vanilla options, and gradually moves to more complicated exotic instruments, whose exercise may depend on multiple assets or on the whole history of the market scenario. 
  The fourth part introduces American contracts and collects several facts necessary to value instruments with American-style exercise. A technique known as Least Squares Monte Carlo or Longstaff-Schwartz method, which may be used to price American options, is described.
  The next part depicts an architecture of a financial Java library, which was created as a part of the thesis and bases on the presented algorithms.
  In the last part, illustrations of several pricing results are collected.
\end{quotation}

\chapter{Preliminaries}
Despite the fact that noone really believes that movements of asset prices are truly random, markets' stochastic models are commonly used, due to very satisfactory results. 

\section{Elements of stochastic analysis}
We expect from the reader some basic knowledge of the probability theory and stochastic processes. Purpose of this section is to recall definitions and facts essential for this work and to establish notation.

\begin{mydef}
 Let $(\Omega, \mathcal{F}, \P)$ be a probability space, $(E, \mathcal{E})$ be a measurable space and $T$ be an arbitrary set. A \textbf{stochastic process} with values in a measurable space $E$, indexed by an arbitrary set $T$, is a family of random variables $X = (X_t)_{t \in T}$, where each $X_t$ is $E$-valued.
 
 For given $\omega \in \Omega$ a \textbf{trajectory} of process $X$ is a function $t \mapsto X_t(\omega)$, with domain $T$ and codomain $E$.
\end{mydef}

\begin{remark}
 Stochastic process may be seen as a function $X: \Omega \rightarrow \mathbb{E}^T$. Then a trajectory is value of such function, i.e. for given $\omega,\ X(\omega)$ is a trajectory. In the other words, a stochastic process is a random function and a trajectory is its concrete realization.
\end{remark}

\begin{remark}
 In our applications space $E$ will be equal $\R$ or $\R^n$. 
\end{remark}

\begin{mydef}
 A \textbf{Brownian motion} (or a \textbf{Wiener process}) is a stochastic process $(W_t)_{t \geq 0}$ defined by following conditions:
 \begin{itemize}
  \item $W_0 = 0$ a.s.,
  \item for any $t,\ W_t \sim \mathcal{N}(0,t)$,
  \item increments of $W$ are independent (i.e. for any $t_0 \leq t_1 \leq \ldots \leq t_n$ random variable $W_{t_0}, W_{t_1} - W_{t_0},\ \ldots, W_{t_n} - W_{t_{n-1}}$ are independent,
  \item increments of $W$ are stationary (i.e. for every $0 \leq s < t,\ W_t-W_s$ is equal in distribution to $W_{t-s})$,
  \item trajectories of $W$ are continous a.s.
 \end{itemize}
\end{mydef}
\noindent In this paper $W$ will always denote Brownian motion.

\begin{mydef}
 \textbf{Filtration} $(\mathcal{F}_t)_{t=0}^T$ on probability space $(\Omega, \mathcal{F}, {P})$ is an increasing family of $\sigma$-algebras contained in $\mathcal{F}$, i.e. for all $s<t,\ \mathcal{F}_s \subseteq \mathcal{F}_t \subseteq \mathcal{F}$.
\end{mydef}
\noindent Sometimes $\mathcal{F}_t$ is interpreted as a set of all events observable up to time $t$.

\begin{mydef}
 Process $X=(X_t)_{t=0}^T$ is called $\mathcal{F}_t$-\textbf{adoptable} if and only if for all $t~\in~[0,T],\ X_t$ is $\mathcal{F}_t$-measurable.
\end{mydef}
\noindent Minimal filtration to which $X$ is adoptable if of course filtration generated by $X$, defined as $\mathcal{F}_t^X = \sigma(X_s:\ s \leq t)$.

\begin{mydef}
 A \textbf{stopping time} with respect to filtration $(\mathcal{F}_t)_{t=0}^T$ is a random variable $\tau:\ \Omega \rightarrow [0,T]\cup\{\infty\}$, such that $\{\tau \leq t\} \in \mathcal{F}_t$ for all $t \in [0,T]$.
\end{mydef}
If $X$ is a process corresponding to some risky game, then a stopping time may be seen as a strategy which tells us whether we should withdraw at time $t$, basing only on the information accessible at time $t$.
\begin{example}
 A typical example of a stopping time is first $t$, when $X_t$ reaches a fixed barrier, i.e.
 \[\tau = \inf\{t\in[0,T]: X_t \geq b\}\]
\end{example}
\noindent Stopping times play important role in financial mathematics. Often we are interested in finding an optimal strategy for exercising an option. Such strategy is a stopping time.

\begin{mydef}
 We call a stochastic process $M=(M_t)_{t=0}^T$ a \textbf{martingale} with respect to the filtration the $(\mathcal{F}_t)_{t=0}^T$ if and only if it satisfies following conditions:
 \begin{itemize}
  \item for all $t \in [0,T],\ M_t$ is $\mathcal{F}_t$-measurable,
  \item for all $t \in [0,T],\ \E|M_t| < \infty$,
  \item for all $0 \leq s < t \leq T,\ \E[M_t|\mathcal{F}_s] = M_s$  a.s.
 \end{itemize}
\end{mydef}

\begin{example}
 Brownian motion $W$ is a martingale. Indeed, we have
 \begin{equation*}
  \E[W_t|\mathcal{F}_s] = \E[W_t-W_s|\mathcal{F}_s] + \E[W_s|\mathcal{F}_s] = \E[W_t-W_s] + W_s = W_s.
 \end{equation*}
 for all $t > s$.
\end{example}
\begin{example}
 \label{ex:angleWt}
 Process $(W_t^2-t)_t$ is a martingale. As previously, for any $t > s$
 \begin{equation*}
  \begin{split}
       & \E[W_t^2-t|\mathcal{F}_s] = \E[(W_t-W_s)^2 + 2W_tW_s - W_s^2|\mathcal{F}_s] -t =\\ 
    =\ & \E[(W_t-W_s)^2|\mathcal{F}_s] + \E[2W_tW_s|\mathcal{F}_s] - \E[W_s^2|\mathcal{F}_s] -t = \\
    =\ & \E[(W_t-W_s)^2] + 2W_s\E[W_t|\mathcal{F}_s] - W_s^2 -t = \\
    =\ & \E[(W_t-W_s)^2] + 2W_s^2 - W_s^2 -t = W_s^2 - s.
  \end{split}
 \end{equation*}
\end{example}

\begin{mydef}
 A stochastic process $M=(M_t)_{t=0}^T$ is called a \textbf{supermartingale} with respect to the filtration the $(\mathcal{F}_t)_{t=0}^T$ if and only if it satisfies following conditions:
 \begin{itemize}
  \item for all $t \in [0,T],\ M_t$ is $\mathcal{F}_t$-measurable,
  \item for all $t \in [0,T],\ \E|M_t| < \infty$,
  \item for all $0 \leq s < t \leq T,\  M_s \geq \E[M_t|\mathcal{F}_s]$  a.s.
 \end{itemize}
 $M$ is called \textbf{submartingale} if it is satisfies the above conditions, but with an inequality $ M_s \leq \E[M_t|\mathcal{F}_s]$.
\end{mydef}
\begin{example}
 For $0 \leq s < t \leq T$ we have
 \[ \E[W_t^2|\mathcal{F}_s] > \E[W_t^2|\mathcal{F}_s] - t + s = \E[W_t^2 - t|\mathcal{F}_s] + s = W_s^2, \]
 hence $W_t^2$ is a submartingale.
\end{example}


The breakthrough allowing financial mathematics to devolop was discovery of It\^{o} integral, named after Japanese mathematician Kiyoshi It\^{o}. We will not discuss constructon of such integral, what is done for example in \cite{latala}.
Instead we will provide some intuition about its meaning. It\^{o} integral of $X=(X)_{t=0}^T$ with respect to Wiener process $W=(W)_{t=0}^T$ is a stochastic process
\[ \left( \int_0^{t} X_s dW_s \right)_{t = 0}^T, \]
where
\begin{equation}
 \label{eq:ito_integral}
  \int_0^{t} X_s dW_s = \lim_{n \rightarrow \infty} \sum\limits_{i=0}^n X_{t_{i-1}} (W_{t_i} - W_{t_{i-1}}).
\end{equation}
As we can see the above definition is similar to the Stieltjes integral definition, which is defined for $g$ with locally bounded variation, and continous $f$, as
\[  \int_0^{t} f(s) dg(s) = \lim_{n \rightarrow \infty} \sum\limits_{i=0}^n f(t_{i-1}) (g(t_i) - g(t_{i-1})). \]
However, on almost all trajectories $W$ has locally unbounded variation. In order to give sense to equation (\ref{eq:ito_integral}), the limit has to be taken in $L_2$.

\begin{remark} Note that
\begin{itemize}
 \item to integrate $\int\limits_0^t X_s ds$ we need only ``standard'' Riemann theory. The integrand is random, hence $\int\limits_0^t X_s ds$ is a function $\omega \mapsto \int\limits_0^t X_s(\omega) ds$ and the last term is a Riemann integral.
 \item $\int\limits_0^t X_s dW_s$ denotes stochastic integral, thus its calculation requires It\^{o} theory.
\end{itemize}
\end{remark}


\begin{mydef}
\label{def:SDE}
 Let $\mu, \sigma \in C^1,\ \xi$ be $\mathcal{F}_s$-measurable random variable. We say that process $X=(X_t)_{t=0}^T$ solves a \textbf{stochastic differential equation (SDE)}
 \begin{equation*}
 \begin{split}
   dX_t &= \mu(X_t)dt + \sigma(X_t) dW_t,\\
   X_0 &= \xi  
 \end{split}  
 \end{equation*}
 if and only if
 \[X_t = \xi + \int\limits_0^t \mu(X_s)ds + \int\limits_0^t\sigma(X_s) dW_s\]
for all $t \in [0,T)$.
\end{mydef}
\begin{remark}
 Sometimes indices are omitted and SDE is written in the form
\end{remark}
\[ dX = \mu(X)dt + \sigma(X) dW. \]

Next definition presents one of the most important type of processes, used to model asset movements in markets.
\begin{mydef}
 A stochastic process $S$ given by SDE
 \begin{equation}
  dS_t = \mu S_t dt + \sigma S_t dW_t, 
  \label{eq:gbm}
 \end{equation}
where $\mu,\sigma \in \R$ is called a \textbf{geometic Brownian motion}.
\end{mydef}

Now we can formulate a version of It\^{o}'s lemma, which is widely used in financial mathematics.
\begin{thm}[It\^{o}'s lemma]
 \label{thm:ito}
  Let $S$ be a geometic Brownian motion as in (\ref{eq:gbm}), $F:\ \R^2 \rightarrow \R,\ F \in C^2$. Then 
  \begin{equation*}
   F(S_t, t) = F(S_0, 0) + \int\limits_0^t \frac{\partial F}{\partial S}(S_r,r)dS_r + \int\limits_0^t \frac{\partial F}{\partial t}(S_r,r)dr + \frac{1}{2}\sigma^2 S_t^2 \int\limits_0^t \frac{\partial^2 F}{\partial S^2}(S_r,r)dr
  \end{equation*}
  or equivalently in SDE form
  \begin{equation}
   \label{eq:ito}
   dF(S_t, t) = \frac{\partial F}{\partial S}(S_t,t)dS_t + \frac{\partial F}{\partial t}(S_t,t)dt + \frac{1}{2}\sigma^2 S_t^2 \frac{\partial^2 F}{\partial S^2}(S_t,t)dt   .
  \end{equation}  
\end{thm}

\noindent In the books on the stochastic processes It\^{o}'s lemma is proven in much greater generality. However, for our purposes, as in many other literature on financial mathematics, formulated theorem will be sufficient.
Equation (\ref{eq:ito}) is also called an It\^{o}'s formula.

It\^{o}'s lemma is a very powerfull tool, indispensable in Black-Scholes theory. We will show how it can be used to solve equation (\ref{eq:gbm}).
\begin{prop}
\label{prop:solution_dynamics}
 Let $S$ be a geometric Brownian motion, as in (\ref{eq:gbm}).
 Solution of its SDE is given by
 \begin{equation}
  \label{eq:gmb_sol}
  S_t = S_0 \exp\left\{ (\mu - \frac{1}{2}\sigma^2)t + \sigma W_t \right\}.
 \end{equation}
\end{prop}
\begin{proof}
We will apply Theorem \ref{thm:ito} (It\^{o}'s formula) with $F(S,t) = \ln(S)$. We have
 \begin{equation*}
  \begin{split}
   dF &= \frac{\partial F}{\partial S}dS + \frac{\partial F}{\partial t}dt + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2}dt \\
   &= \frac{\partial F}{\partial S}(\mu S dt + \sigma S dW) + \frac{\partial F}{\partial t}dt + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2}dt \\    
   &= \frac{1}{S}(\mu S dt + \sigma S dW) + 0dt - \frac{1}{2}\sigma^2 S^2 \frac{1}{S^2}dt \\   
   &= (\mu - \frac{1}{2}\sigma^2) dt + \sigma dW
  \end{split}.
 \end{equation*}
 From Definition \ref{def:SDE}
 \begin{equation*}
  \begin{split}
  F(S_t,t) &= F_0 + \int\limits_0^t (\mu - \frac{1}{2}\sigma^2) ds + \int\limits_0^t \sigma dW_s\\
  &= F_0 + (\mu - \frac{1}{2}\sigma^2)t + \int\limits_0^t \sigma W_t. 
  \end{split}.
 \end{equation*}
 By substituting $S_0 = e^{F_0}$, we get
 \[ S = S_0 \exp\left\{ (\mu - \frac{1}{2}\sigma^2)t + \sigma W_t \right\}. \] 
\end{proof}

So far, we have discussed only one dimensional stochastic processes. However, often we have to take into account several assets at once, thus we need mathematical tools to describe multidimensional cases.
\begin{mydef}
 Process $W$ is called \textbf{$d$-dimensional standard Wiener process} if it is a vector process (its values are in $\mathbb{R}^d$) of the form
 \[ W = \left[ \begin{array}{c}
         W^{(1)}\\
         W^{(2)}\\
         \vdots\\
         W^{(d)}
        \end{array} \right],\]
where all components are independent Wiener processes.
\end{mydef}
Movements of asset prices usually can not be regarded as independent. We need notation to describe dependency between processes.
\begin{mydef}
 We say that Wiener processes $W$ and $V$ are correlated and have correlation $\varrho$, what we denote by
 \[ \Corr(W, V) = \varrho, \]
 if and only if
 \[ \Corr(W_1, V_1) = \varrho. \]
\end{mydef}
\begin{remark}
 It is easy to notice that $\Corr(W_1, V_1) = \varrho$ if and only if for all $t > 0$, $\Corr(W_t, V_t) = \varrho$.
\end{remark}
\begin{mydef}
 The process $W$ is called \textbf{$d$-dimensional correlated Wiener process} with correlation matrix $\Sigma = (\varrho_{ij})_{i,j=1}^d$, if and only if $W = [W^{(1)},W^{(2)},\ldots,W^{(d)}]'$, where for each $i,j$, $\Corr(W^{(i)}, W^{(j)}) = \varrho_{ij}$.   
\end{mydef}

We end this section with the Girsanov theorem, whose significance in the financial mathematics arises from the fact, that it allows us to move from the real measure $\P$ to an equivalent martingale measure $\Pm$. In the literature exist many versions of this theorem. The one presented here comes from \cite{bjork}, there reader may also finde the proof.
\begin{thm}[\bfseries Girsanov theorem]
 \label{thm:girsanov}
 Let $\bar{W}$ be a $d$-dimensional standard Wiener process on probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t)_{t=0}^T, \P)$ and let $\varphi$ be any $d$-dimensional adapted column vector process.
 Choose a fixed $T$ and define the process $L$ on $[0,T]$ by
 \[ L_t = \exp\left\{ \int\limits_0^t \varphi_s \cdot d\bar{W}_s - \frac{1}{2}\int\limits_0^t ||\varphi_s||^2ds. \right\} \]
 Assume that 
 \[ \E^P[L_T] = 1, \]
 and define the new probability measure $\mathbb{Q}$ on $\mathcal{F}_T$ by
 \[ \frac{d\mathbb{Q}}{d\P} = L_T,\ \ \hbox{ on } \mathcal{F}_T. \]
 Then $W$ given by
 \[W_t = \bar{W}_t - \int\limits_0^t \varphi_s ds\]
 is a standard Wiener process under $\mathbb{Q}$.
\end{thm}
\begin{remark}
 Symbol $\cdot$ in definition of $L$ is the inner product of two vectors. 
\end{remark}

\section{Elements of Monte Carlo theory}
Monte Carlo methods are a class of algorithms designed for estimation of unknown values by simulation.
They do not refer to any particular algorithm, they are rather a general ``recipe'' for procedures, which obtain results by simulation.

\subsection{Crude Monte Carlo}
Suppose we want to estimate an unknown value $I$, which can be written as expected value of some random variable, i.e.
\begin{equation}
 \label{eq:EY}
 I = \E Y. 
\end{equation}
The idea of Monte Carlo technique is to replicate $Y$ many times, and as an estimation of $I$ take an average. So
\[ I \approx \frac{1}{n} \sum\limits_{i=1}^n Y_i, \]
where $n$ is a big natural number and $Y_i$ are independent, with the same distribution as~$Y$.

This procedure is justified by the strong law of large numbers. Let 
\begin{equation}
 \label{eq:CMC}
 \CMC[n] = \frac{1}{n}\sum\limits_{i=1}^n Y_i.
\end{equation}
Of course $\E\CMC[n] = \E Y = I$, so $\CMC[n]$ is unbiased. Moreover, from the law of large numbers $\CMC[n] \conv I$ a.s., what explains why Monte Carlo method works. 

Value $\CMC[n]$ is called \textbf{crude Monte Carlo} estimator. Simple calculation gives its variance
\begin{equation}
 \label{eq:VarCMC}
 \Var(\CMC[n]) = \frac{1}{n}\Var(Y).
\end{equation}
In this paragraph we will simply write $\hat{Y}_n$ instead of $\CMC[n]$.

Here appears a natural question, how big should be the number $n$ to obatain the satisfying accuracy of the estimator?
To find an answer we have to specify the question a little more: for chosen numbers $b$ and $\alpha$, how big should be $n$, so we could tell, that an error of the estimation, with probability $1-\alpha$, is not greater than $b$?

Let $\sigma = \sqrt{\Var{Y}}$, $z_{1-\alpha/2} = \Phi^{-1}(1-\alpha/2)$, where $\Phi$ is cumulative distribution function of normal distribution.
Strong convergence of $\hat{Y}_n$ implies also weak convergence, what means that
\[ \P(|\hat{Y}_n - I| > b) \conv 0 \hbox{\ \ a.s.,} \]
for any $b > 0$. 
Hence we write
\begin{align*}
 \P(-b \leq \hat{Y}_n - I \leq b) &= 1 - \alpha\\
 \P(-b \leq \frac{\sum\limits_{i=1}^n Y_i - nI}{n}  \leq b) &= 1 - \alpha\\
 \P(-\frac{b\sqrt{n}}{\sigma} \leq \frac{\sum\limits_{i=1}^n Y_i - nI}{\sqrt{n}\sigma}  \leq \frac{b\sqrt{n}}{\sigma}) &= 1 - \alpha
\end{align*}
From Central Limit Theorem we have
\[ \limn \P(-z_{1-\alpha/2} \leq \frac{\sum\limits_{i=1}^n Y_i - nI}{\sqrt{n}\sigma}  \leq z_{1-\alpha/2}) = 1 - \alpha, \]
hence for large $n$ we have
\[z_{1-\alpha/2} \approx \frac{b\sqrt{n}}{\sigma}.\]
In a typical situation we do not know variation of $Y$ (we don't even know the expected value, yet we are using Monte Carlo method to find it!), so above formula has rather theoretical meaning.
However, there is a version of CLT which uses unbiased estimator
\[ \hat{\sigma} = \frac{1}{n-1}\sum\limits_{i=1}^n (Y_i - \hat{Y}_n)^2 \]
instead of $\sigma$, what allows to replace $\sigma$ by $\hat{\sigma}$ in above approximation. We have proven following 
\begin{thm}
 Dependency between number of simulations $n$, error $b$ and confidence level $\alpha$ is given by following formulas
 \begin{equation}
   \label{eq:error}
   b = \frac{\hat{\sigma} z_{1-\alpha/2}}{\sqrt{n}}
 \end{equation}
 \begin{equation}
   \label{eq:sim}
   n = \frac{\hat{\sigma}^2 z_{1-\alpha/2}^2}{b^2}.
 \end{equation}
\end{thm}
\noindent Equation (\ref{eq:error}) tells us how big is an error of estimation when we performed $n$ simulation. Equation (\ref{eq:sim}) inverses situation, it allows us to plan the number of simulations necessary to obtain requested accuracy.

Unfortunatly equation (\ref{eq:error}) tells us that convergence of the Monte Carlo method is slow. To improve accuracy by one more digit, one have to perform 100 times more simulations. The only way to decrease the number of necessary simulations is to choose $Y$ with smallest possible variance. In next sections two methods of variance reduction are discussed.

The confidence level $\alpha$, which appears in (\ref{eq:error}) in quantile function, is not essential when comparing two estimators. Hence we introduce 
\begin{mydef}
 Value
 \begin{equation}
  \label{eq:stderr}
  \frac{\hat{\sigma}}{\sqrt{n}}
 \end{equation}
is called \textbf{standard error} (abbreviated \textbf{s.e.}).
\end{mydef}
Suppose that in some fixed time we can take $n$ samples from distribution of $Y$, and $m$ samples from distribution of $Z$, where $EY = EZ = I$. In order to settle which estimator is better, $\hat{Y}_n$ or $\hat{Z}_m$, it is sufficient to compare their standard errors, that is $\dfrac{\hat{\sigma}_Y}{\sqrt{n}}$ and $\dfrac{\hat{\sigma}_Z}{\sqrt{m}}$.

\subsection{Antithetic variates}
Let's consider again $I$ and $Y$ as in (\ref{eq:EY}). Equation (\ref{eq:sim}) shows that the number of simulations required to obtain given accuracy is proportional to variance of $Y$. It explains the necessity of choosing $Y$ wisely. If we can find $Y'$ which has smaller variance than $Y$, then we can significantly decrease the number of needed simulations.
We will describe two techniques of variance reduction: this paragraph introduces antithetic variates method, and the following presents control variates method.

In \textbf{antithetic variates method} every sample is a pair of values, each from the same distribution as $Y$. Every of $n$ sample pairs is independent from each other, however random variables in a pair should be correlated. In the other words we consider pairs $(Y_{2i-1}, Y_{2i})$, $i=1,2,...,n$,
where each $(Y_{2i-1}, Y_{2i})$ is independent from $(Y_{2j-1}, Y_{2j})$, if $i \neq j$, and for some $\varrho$, $\Corr(Y_{2i-1}, Y_{2i}) = \varrho$. Let
\begin{equation*}
 \tilde{Y}_i = \frac{Y_{2i-1} + Y_{2i}}{2},\ \ \ i = 1,2,...,n.
\end{equation*}
It is clear that $(\tilde{Y}_i)_{i=1}^n$ are i.i.d., and their variance satisifies
\begin{equation*}
 \begin{split}
 \Var(\tilde{Y}_i) &= \dfrac{1}{4} \Var( Y_{2i-1} + Y_{2i} ) = \dfrac{1}{4} (\Var(Y_{2i-1}) + \Var(Y_{2i}) + 2\Cov(Y_{2i-1}, Y_{2i})) \\
 %&= \dfrac{1}{4} (\Var(Y_{2i-1}) + \Var(Y_{2i}) + 2\Corr(Y_{2i-1}, Y_{2i})\sqrt{\Var(Y_{2i-1})\Var(Y_{2i})})
 &= \dfrac{1}{4} (2\Var(Y) + 2\Var(Y)\varrho) \\
 &= \dfrac{\Var(Y)}{2} (1 + \varrho).
 \end{split}
\end{equation*}
We define \textbf{antithetic variates estimator} as
\begin{equation*}
 \AV[n] = \frac{1}{n}\sum\limits_{i=1}^n \tilde{Y}_i.
\end{equation*}
We calculate its variance
\begin{equation}
 \label{eq:VarAV}
 \begin{split}
 \Var(\AV[n]) &= \frac{1}{n^2} \Var(\sum\limits_{i=1}^n \tilde{Y}_i) \\
   &= \frac{1}{n} \Var(\tilde{Y}_i) = \dfrac{\Var(Y)}{2n} (1 + \varrho).
 \end{split}
\end{equation}
From (\ref{eq:VarCMC}) we see that variance of the crude Monte Carlo estimator, which performs the same number of draws, equals $\frac{1}{2n}\Var(Y)$. Hence, if correlation of random variables in a pair is negative, then we reduce variance. In consequence the number of simulations necessary to keep an error smaller than $b$, at the confidence level $\alpha$ is also smaller.

\subsection{Control variates}
The \textbf{control variates method} also involves drawing pairs of values, however in opposite to antithetic variates method, elements in pair do not come from the same distribution and expected value of the second distribution must be known. More precisely, we consider pairs $(Y_i, X_i)$, $i=1,2,...,n$, where each $(Y_i, X_i)$ is independent from $(Y_j, X_j)$,
if $i \neq j$, $\E X$ is known and $\Cov(Y_i, X_i) > 0$. Let $\hat{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$. \textbf{Control variates estimator} is defined as
\begin{equation}
 \label{eq:CV}
 \CV[n] = \CMC[n] + c(\hat{X}_n - \E X)
\end{equation}
for some $c$. In order to reduce variance $c$ must be chosen properly. We have
\begin{equation*}
 \begin{split}
 \Var( \CV[n] ) &= \Var( \CMC[n] + c\hat{X}_n ) = \frac{1}{n^2} \Var \left( \sum\limits_{i=1}^n( Y_i + c X_i) \right) \\
                &= \frac{1}{n}\Var(Y + c X) = \frac{1}{n}( \Var(Y) + 2c\Cov(Y,X) + c^2 \Var(X)).
 \end{split}
\end{equation*}
The last expression is a simple quadratic equation with respect to $c$, hence it is easy to determine for which argument it reaches its minimum value:
\[ c = -\frac{\Cov(Y,X)}{\Var(X)}. \]
Let $\varrho = \Corr(Y,X)$. By substituting $c$ to the last equation we get
\begin{equation}
 \begin{split}
 \Var( \CV[n] ) &=  \frac{1}{n} \left( \Var(Y) - 2\frac{\Cov(Y,X)^2}{\Var(X)} + \frac{\Cov(Y,X)^2}{\Var(X)^2} \Var(X) \right) \\
 &= \frac{1}{n} \left( \Var(Y) - \frac{\Cov(Y,X)^2}{\Var(X)}  \right) \\
 &= \frac{\Var(Y)}{n} \left( 1 - \varrho^2  \right) \label{eq:VarCV}
 \end{split}
\end{equation}
Crude Monte Carlo estimator, which takes the same number of random variables (i.e. 2 times the number of pairs in control variates method) has the variance equal to $\frac{\Var(Y)}{2n}$. Thus if $1 - \varrho^2 < \frac{1}{2}$ we reduce the variance.

In practice, however, we do not know values $\Var(X)$ (we only assumed we know expectation of $X$) and $\Cov(Y,X)$. Hence in the simulations we have to use 
\begin{equation}
 \label{eq:CVc}
 c = -\frac{\sigma_{XY}^2}{\sigma_{X}^2},
\end{equation}
where
\begin{equation*}
 \begin{split}
  \sigma_{XY}^2 &= \frac{1}{n-1} \sum\limits_{i=1}^{n} (X_i - \hat{X}_n)(Y_i - \CMC[n]),\\
  \sigma_{X}^2 &= \frac{1}{n-1} \sum\limits_{i=1}^{n} (X_i - \hat{X}_n)^2.
 \end{split}
\end{equation*}

\begin{example}
To compare presented Monte Carlo methods let us calculate value of $I = \int_0^1 e^x dx$ by simulation. Of course exact value equals $e - 1 \approx 1.71828183$. Let $g(x) = e^x$ and $U \sim \mathcal{U}(0,1)$. Then 
\[ I = \E[g(U)], \]
 hence we can use derived theory with $Y = g(U)$. We consider following estimators:
 \begin{equation*}
  \begin{split}
   \CMC[2n] &= \frac{1}{2n} \sum\limits_{i=1}^{2n} g(U_i), \\
   \AV[n] &= \frac{1}{n} \sum\limits_{i=1}^{n} \frac{g(U_i) + g(1-U_i)}{2}, \\ 
   \CV[n] &= \frac{1}{n} \sum\limits_{i=1}^{n} \left( g(U_i) + c(U_i - \frac{1}{2}) \right),
  \end{split}
 \end{equation*}
where $c$ is as in (\ref{eq:CVc}) with $Y = g(U)$ and $X = U$. Note that we are taking twice as much simulations in crude Monte Carlo method, since it does not use pairs of random variables. The results of comparision of all presented methods are gathered in Table \ref{tab:MCcompare} and Figures \ref{fig:boxMC}, \ref{fig:convergenceMC}.

\begin{table}
\centering
 \caption{Results of calculating $\int_0^1 e^x dx$ by simulation.}
 \label{tab:MCcompare}
\begin{tabular} {||c | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMC[2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AV[n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CV[n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
100    & 1.69825 & 0.03504 & 1.71717 & 0.00648 & 1.71962 & 0.00638 \\ \hline 
1000   & 1.72458 & 0.01094 & 1.72171 & 0.00205 & 1.72032 & 0.00203 \\ \hline 
10000  & 1.72116 & 0.00349 & 1.71805 & 0.00062 & 1.71918 & 0.00063 \\ \hline 
100000 & 1.71665 & 0.00110 & 1.71802 & 0.00020 & 1.71844 & 0.00020 \\ \hline 
1000000& 1.71796 & 0.00035 & 1.71831 & 0.00006 & 1.71829 & 0.00006 \\ \hline 
\end{tabular}  
\end{table}

\begin{figure}
\centering
 \includegraphics[scale=0.4]{images/Preliminaries/boxMonteCarlo.pdf}
\caption{For each method 10000 simulations were run 100 times. Hence each method gave 100 estimations of $\int_0^1 e^x dx$. Small points indicate obtained values. As usually in box plots, the lower and upper edges of the boxes are first and third quartiles.  }
\label{fig:boxMC}
\end{figure}

\begin{figure}
\centering
 \includegraphics[scale=0.4]{images/Preliminaries/convergenceMC.pdf}
\caption{Comparision of speed of convergence. }
\label{fig:convergenceMC}
\end{figure}

We see that in this case antithetic and control variates methods gave approximatly equal results, while crude Monte Carlo is far behind them. When performing one million simulations (in case of CMC two millions) standard error turned out 50 times smaller in AV and CV than in CMC. It means that results from the first two methods are more than one digit more accurate.

Box plot from figure \ref{fig:boxMC} shows that variance of the crude Monte Carlo estimator is greater than in two other methods. In practice it means, that if we run simulations with AV estimator or CV estimator, then every time we would obtain more or less equal result. For CMC discrepancy between the results would be much bigger.
Figure \ref{fig:convergenceMC} explains that fact -- speed of convergence of CMC is definitely lower than two other methods.

In order to realize why AV and CV methods result with so similar accuracy, look at (\ref{eq:VarAV}) and (\ref{eq:VarCV}). In AV method variance is reduced by a coefficient
\[ \frac{1 + \Corr(e^U, e^{1-U})}{2} \approx \frac{1 - 0.968}{2} = 0.0162, \]
while in CV method variance is reduced by a coefficient
\[ 1 - \Corr(e^U, U)^2 \approx 1 - 0.992^2 = 0.0163. \]
Such similarity of the results is pure coincidence.

At the end note that this is very tendentious example, which shows that variance reduction may be very usefull. Actually, in many applications it may be difficult to find pairs of highly correlated random variables necessary to use AV or CV methods.
\end{example}


\subsection{Simulation}
Now, when we know how Monte Carlo methods work, we need to describe how to get random values.
\paragraph{Independent standard normal random variables.} Most computational enviroments and programming languages have built-in generator of values from uniform distribution. We will show how to obtain (pseudo)random variables with ubiquitous normal distribution.

The most popular way is to use \textbf{Box-Muller algorithm}, which uses two independent variates with uniform distribution on $(0,1)$, and ``produces'' two independent variates with standard normal distribution.
\begin{algorithm}[!ht]
 \begin{algorithmic}[1]
  \Function{BoxMuller}{}
    \State Generate independent random variables $U_1, U_2 \sim \mathcal{U}(0,1)$,
    \State $N_1 \gets \sqrt{-2\log(U_1)} \cos(2\pi U_2)$,
    \State $N_2 \gets \sqrt{-2\log(U_1)} \sin(2\pi U_2)$,
    \State \Return ($N_1$, $N_2$).
  \EndFunction
 \end{algorithmic}
 \caption{Box-Muller method.}
 \label{alg:box-muller}
\end{algorithm}

This method returns values of two independent random variables coming from standard normal distribution. When we need more than two samples, then of course we repeat that algorithm as many time as necessary.

In \cite{london} we can find a remark that necessity of calculating sine and cosine may slow the above algorithm down. Another algorithm, \textbf{polar rejection}, is proposed.
\begin{algorithm}[!ht]
 \begin{algorithmic}[1]
  \Function{PolarRejection}{}
    \State Generate independent random variables $U_1, U_2 \sim \mathcal{U}(0,1)$,
    \State $V_1 \gets 2U_1-1$,
    \State $V_2 \gets 2U_2-1$,
    \State $W \gets V_1^2 + V_2^2$,
    \State if $W > 1$ return to step 2.,
    \State $N_1 \gets \sqrt{\frac{-2\log(W)}{W}} V_1$,
    \State $N_2 \gets \sqrt{\frac{-2\log(W)}{W}} V_2$,
    \State \Return ($N_1$, $N_2$).
  \EndFunction
 \end{algorithmic}
 \caption{Polar rejection method.}
 \label{alg:polarRejection}
\end{algorithm}

However, conducted experiment does not show any significat diffrence in efficiency of both presented methods. Code for the test is presented on Listing \ref{lst:rnorm}.
\lstset{  basicstyle=\scriptsize }
\lstinputlisting[language=Java, caption=Java program for comparision of normal random values generators, label=lst:rnorm]{listings/rnormTest.java}
For both algorithms program takes ten millions pairs of values and prints following \hbox{output}\footnote{Test was performed on a notebook with processor Intel® Core™2 Duo CPU P8400 @ 2.26GHz x 2 }: \bigskip \\
\texttt{Box-Muller: 3.321 s.\\
Polar rejection: 3.292 s.} \bigskip\\
what brings us to conclusion that the efficiency of both algorithms is comparable and not worth bothering.

\paragraph{Independet nonstandard normal random variables.} Sampling from an arbitrary normal distribution $\mathcal{N}(\mu, \sigma^2)$ is now straightforward. From the elementary probability theory comes following method.
\begin{enumerate}
 \item Genarate $N \sim \mathcal{N}(0,1)$ using one of previously shown methods.
 \item Return $\mu + \sigma N$.
\end{enumerate}

\paragraph{Correlated normal random values.} Above methods allow us to generate independent random variables. In the real world, however, we notice dependencies between observed phenomenons. For example movements of the prices of the market assets are usually correlated. When the market is in a boom cycle, then all the prices are increasing; inversly, if the recession comes, all of the prices are falling.
In order to model such values we must be able to generate correlated random variables.

\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.4]{images/Preliminaries/normalCorrelated.pdf}
\caption{Graphical illustration of dependency between normal correlated random variables. In the upper left corner $\varrho = -0.8$, upper right: $\varrho = -0.4$, lower left: $\varrho = 0$ (independent variables), lower right: $\varrho = 0.4$.}
\end{figure}

Let's begin with two standard normal random variables with correlation $\varrho$. We want to obtain $Z_1, Z_2 \sim \mathcal{N}(0,1)$ such that $\Corr(Z_1, Z_2) = \varrho$.  For now we only can generate independent $Z_1$ and $Z_2$, i.e. $\Corr(Z_1, Z_2) = 0$. On the other hand $\Cov(Z_1, Z_1) = 1$. Here rises the idea that there exists $Z_3$, such that $\Corr(Z_1, Z_3) = \varrho$, of the form $Z_3 = a Z_1 + b Z_2$.
It should come from standard normal distribution, thus
\[ 1 = \Var(Z_3) = \Var( a Z_1) +  \Var(b Z_2) = a^2 + b^2 \]
Moreover
\[ \varrho = \Corr(Z_1, Z_3) = \Cov(Z_1, Z_3) = a\Cov(Z_1, Z_1) + b\Cov(Z_1, Z_2) = a \]
Hence
\[ a = \varrho,\ \ \ \ b = \sqrt{1 - \varrho^2}. \]
We have proven following
\begin{prop}
 If $Z_1$ and $Z_2$ are independent random variables with the same distribution $\mathcal{N}(0,1)$, then for any $\varrho \in [-1,1]$ random variable
 \[ Z_3 = \varrho Z_1 + \sqrt{1 - \varrho^2} Z_2 \]
 has distribution $\mathcal{N}(0,1)$ and $\Corr(Z_1, Z_3) = \varrho$.
\end{prop}
The derivation of above fact was intuitive, but we need a more general version.


\begin{thm}
 If $N_1$ and $N_2$ are independent random variables with the same distribution $\mathcal{N}(0,1)$, then for any
 $\Sigma = \left( \begin{array}{cc}
                      \sigma_1^2 & \sigma_{12}^2 \\
                      \sigma_{12}^2 & \sigma_2^2
                   \end{array} \right)$
 random vector $ Z = \mu + LN$, where
  $L = \left( \begin{array}{cc}
                      \sigma_1 & 0 \\
                      \frac{\sigma_{12}^2}{\sigma_1} & \sqrt{\sigma_2^2 - \frac{\sigma_{12}^4}{\sigma_1^2}}
                   \end{array} \right)$,
 has distribution $\mathcal{N}(\mu,\sigma)$. Moreover $\Sigma = LL^T$.
\end{thm}
\begin{proof}
Let's focus on the case $\mu_1 = \mu_2 = 0$, since the mean may be added at the end. We have $N \sim \mathcal{N}(\bf{0}, \mathbb{I})$. By making an assigment $Z_1 = \sigma_1 N_1$, $Z_1$ has desired variance. As previously, we look for $Z_2$ of the form $Z_2 = a N_1 + b N_2$. We want the variance of $Z_2$ to equal $\sigma_2^2$, so
\[ \sigma_2^2 = \Var(Z_2) = \Var( a N_1) +  \Var(b N_2) = a^2 + b^2 \]
Moreover
\[ \sigma_{12}^2 = \Cov(Z_1, Z_2) = \sigma_1 a\Cov(N_1, N_1) + \sigma_1 b\Cov(N_1, N_2) = a\sigma_1 \]
Hence
\[ a = \frac{\sigma_{12}^2}{\sigma_1},\ \ \ \ b = \sqrt{\sigma_2^2 - \frac{\sigma_{12}^4}{\sigma_1^2}}. \] 
Equation $\Sigma = LL^T$ may be proven by simple matrix multiplication.
\end{proof}

It turns out that above theorem can be generalized for higher dimensions. That explains following algorithm for generating values from multivariate normal distribution with given mean vector $\mu$ and positive-definite covariation matrix $\Sigma$. 
\begin{enumerate}
 \item Use Cholesky decomposition to obtain matrix $L$ such that $\Sigma = LL^T$,
 \item Using previously shown method generate vector $N$ of independent random variables with standard normal distribution.
 \item Return $\mu + LN$.
\end{enumerate}


\chapter{Basics of option pricing}
The main field of interest of the financial mathematics is pricing so-called contingent claims, which are assets whose payoff depends on the stock prices. In case of the European options there exists a straightforward forumula, derived by Black and Scholes in 1973, which gives price of the option. Antother way of pricing is using Monte Carlo simulations.
Although the simulations are time-consuming and for that reason less effective than Black-Scholes formula, they are widely used because of the possibility to adjust them to diffrent contingent claims. 

\section{Elements of arbitrage theory}

\subsection{Notation}
Throughout this thesis we assume we are given a probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t)_{t=0}^T, \P)$. Since it is observed by investors, $\P$ is sometimes called a \textbf{real measure}, in opposite to artificial \textbf{risk-neutral measure}, which will be later on. Elements of $\Omega$ are called \textbf{market scenarios}.
Furthermore $\sigma$-algebra $\mathcal{F}_t$ may be seen as set of all events observable up to time $t$.

We consider a market with $d+1$ assets, where each asset $S^{(i)} = (S^{(i)}_t)_{t=0}^T$ is modelled as a $\R_+$-valued stochastic process adapted to $(\mathcal{F}_t)_{t=0}^T$. The $0$\textsuperscript{th} asset is the money stored in a locally riskless bank account and is given by 
\[S^{(0)}_t = \exp\left\{ \int\limits_0^t r(t)dt \right\},\]
where $r(t)$ is a short term riskless interest rate at time $t$. In general $r(t)$ may also be a stochastic process, however often we will assume $r(t) \equiv r$ and then $S^{(0)}$ may also be regarded as a bond, paying $e^{rT}$ at time $T$. By $S$ we will denote a $d$-dimensional vector of prices of the risky assets, i.e.
\begin{equation*}
 S_t = (S^{(1)}_t, S^{(2)}_t, \ldots, S^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}
We also introduce notation $\Sa$ for a $(d+1)$-dimensional vector of prices of all assets, that is
\begin{equation*}
 \Sa_t = (S^{(0)}_t, S_t) = (S^{(0)}_t, S^{(1)}_t, \ldots, S^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}

For convenience we also consider discounted time processes
\[ X^{(i)}_t = \frac{S^{(i)}_t}{S^{(0)}_t}. \]
It allows us to compare asset prices quoted at diffrent times. In similar manner as previously we will use notation $X, \Xa$ for vectors of the discounted prices,
\begin{equation*}
 X_t = (X^{(1)}_t, X^{(2)}_t, \ldots, X^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}
\begin{equation*}
 \Xa_t = (X^{(0)}_t, X^{(1)}_t, \ldots, X^{(d)}_t), \ \ \ 0 \leq t \leq T.
\end{equation*}

Next definition gives us a notation to describe the content of \textbf{portfolio}.
\begin{mydef}
A \textbf{dynamic trading strategy} is any $\mathcal{F}_t$-adapted,  $\R^{d+1}$-valued process $\xia = (\xia_t)_{t=0}^T = (\xi^{(0)}_t, \xi_t)_{t=0}^T = (\xi^{(0)}_t, \xi^{(1)}_t, \ldots, \xi^{(d)}_t)_{t=0}^T$.
\end{mydef}
Each $\xi^{(i)}_t$ has an interpretation of the quantity of shares of the $i$\textsuperscript{th} asset held in portfolio at time $t$ (it may be negative, then it corresponds to the short sale). Thus, the notion of the portfolio and the dynamic trading strategy may be equated. The value of the portfolio at time $t$ equals
\[\xia_t \cdot \Sa_t = \sum\limits_{i=0}^d \xi^{(i)}_t S^{(i)}_t,\]
where $\cdot$ is the inner product of two vectors.

Assume that investor's portfolio is worth 101\$ today and a year ago it was worth 100\$. Did the investor really make a profit? If riskless interest rate equals 5\%, then investor would gain more if he put all his capital into bank account. This example shows the necessity of discounting to compare portfolios whose values are quoted at diffrent times.
\begin{mydef}
 The \textbf{discounted value process} $V^{\xi} = (V^{\xi}_t)_{t=0}^T$ associated with a trading strategy $\xia$ is given by 
 \begin{equation*}
  V^{\xi}_t = \xia_t \cdot \Xa_t.
 \end{equation*}
\end{mydef}

\subsection{Arbitrage opportunities}
The value $V^{\xi}_0$ is the initial investment into the portfolio. Following definition introduces portfolios which do not receive cash flows from the ``outside world'' after initialization. They are rearranged in such a way that purchases of new assets must be covered by selling some other assets, so value of the portfolio before and after rearranging stays the same.
\begin{mydef}
 A dynamic trading strategy is called \textbf{self-financing} if and only if for every $0 \leq t \leq T$
 \[ \sum\limits_{i=0}^d d\xi^{(i)}_t (S^{(i)}_t + dS^{(i)}_t) = 0. \]
\end{mydef}
This definition, although being very simple, looks completely incomprehensible at first sight. To convey some intuition let's think that $dt$ is a very small, even infinitesimal, time period. Vector $\xia_t$ describes content of the portfolio at the beginning of the period. After time $dt$ change of the stock prices equals $dS_t$. The portfolio needs a rearrangment -- $d\xia_t$ means changes of quantities of the held assets.
Thus $d\xia_t \cdot (\Sa_t + d\Sa_t)$ is the total cost of the rearrangment. From the definition it equals 0, what explains the name \textit{self-financing}.

From now on we will consider only those market models that are efficient in the sense that they are arbitrage-free.
\begin{mydef}
 An \textbf{arbitrage opportunity} is a self-financing portfolio $\xia$, such that
 \begin{align*}
  V^{\xi}_0 &= 0\\
  \P(V^{\xi}_T \geq 0) &= 1\\
  \P(V^{\xi}_T > 0 ) &> 0
 \end{align*}
 The market is \textbf{arbitrage-free} if it does not allow for arbitrage opportunities.
\end{mydef}
What does arbitrage opportunity mean in practice? Assume an investor entering the market without any capital. He builds his portfolio by short sale of some assets and purchase of other assets for received money. Arbitrage opportunity is a situation when the investor at time $T$ can cover his short positions by sale of assets held long, and with positive probability he has some remaining cash.
In the other words, he can make money without exposure to any downside risk. 

Now we are moving to an important concept of martingule measure.
\begin{mydef}
 A probability measure $\Pm$ is a \textbf{martingale measure} if and only if the discounted price process $X$ is a $\Pm$-martingale, i.e. for all  $0 \leq s \leq t \leq T$
 \begin{equation}
  \label{eq:X-martingale}
  \Em[X_t] < \infty \hbox{\ \ and\ \ } \Em[X_t | \mathcal{F}_s] = X_s
 \end{equation}
\end{mydef}

\begin{remark}
 Condition (\ref{eq:X-martingale}) is written for a vector process $X$, hence for every $1 \leq i \leq d$
  \begin{equation*}
  \Em[X^{(i)}_t] < \infty \hbox{\ \ and\ \ } \Em[X^{(i)}_t | \mathcal{F}_s] = X^{(i)}_s
 \end{equation*}
\end{remark}

Let us recall that two measures $\P$ and $\Pm$ defined on $\sigma$-algebra $\mathcal{F}$ are equivalent if and only if $\forall A \in \mathcal{F}.\ \P(A)=0 \Leftrightarrow \Pm(A)=0$. Next theorem, known as \textbf{first fundamental theorem of asset pricing}, shows importance of martingale measures.
\begin{thm}[\bfseries First FTAP]
 \label{thm:fftap}
 The following to statements are \emph{essentialy} equivalent:
 \begin{enumerate}
  \item The market model is arbitrage free.
  \item There exists martingale measure $\Pm$ equivalent to $\P$.
 \end{enumerate}
\end{thm}
Unfortunatly, due to an appearence of a word ``essentialy'', this is rather a ``meta-theorem''. It can be given a sharp, mathematical sense -- see for example Theorems 10.9 and 10.10 in \cite{bjork}. In the discrete case, however, theorem holds without the word ``essentialy'', as it is proven in \cite{follmer} (Theorem 5.17). This case is sufficient for us, since in Monte Carlo methods price trajectories are simulated only in a finite number of points.

\section{European contingent claims}
\label{sec:ECC}
We start this section with definition of a mentioned contingent claim.
\begin{mydef}
 \label{def:cc_eu}
 \textbf{European contingent claim} is a non-negative random variable $C$ on $(\Omega, \mathcal{F}_T, \P)$. \textbf{Derivative} of underlying assets $S^{(0)}, S^{(1)}, \ldots, S^{(d)}$ is a contingent claim which is measurable with respect to $\sigma$-algebra generated by price processes.
\end{mydef}
European contingent claims may be seen as assets yielding a random payoff at \textbf{exercise date} $T$ (also called \textbf{maturity}). Of course the seller of such contingent claim can not take a random amount of money from the buyer. What should be then the price at time $0$? The answer to this question is in general definitely nontrivial. However, for some simple derivatives, e.g. European options, there exists a straightforward formula for the price.

\begin{mydef}
 An \textbf{European call option} on the asset $S^{(i)}$ with exercise date $T$ and \textbf{strike price} $E$ gives it's owner the right, but not the obligation, to \underline{buy} that asset at time $T$ for a fixed price $E$.
 
 An \textbf{European put option} on the asset $S^{(i)}$ with exercise date $T$ and \textbf{strike price} $E$ gives it's owner the right, but not the obligation, to \underline{sell} that asset at time $T$ for a fixed price $E$.
\end{mydef}
From the definition
\begin{equation}
 \label{eq:ecall}
 C\textsuperscript{call} = (S^{(i)}_T - E)_+
\end{equation}
\begin{equation}
 \label{eq:eput}
 C\textsuperscript{put} = (E - S^{(i)}_T )_+
\end{equation}
where $(x)_+ = \max(0,x)$.

Options defined above are also called \textbf{vanilla options}, while derivatives with additional features are called \textbf{exotic options}. \textbf{Barrier options} may serve as an example. Their payoff depends not only on the stock price at the maturity, but also on the historical prices. Barrier options are divided into \textit{knock-in} options, which may be ``turned on'', and \textit{knock-out} options, which may be ``turned off'' in case of reaching some \textbf{barrier}. Let us write down two example definitions.
\begin{mydef}
The payoff of the \textbf{up-and-in call} option on asset $S^{(i)}$ with exercise date $T$, strike price $E$ and barrier $\bar{B}$, equals
\[ C^{\hbox{\scriptsize call}}_{\hbox{\scriptsize u\&i}} = 
\begin{cases}
 (S^{(i)}_T - E)_+    & \hbox{if } \sup\limits_{0 \leq t \leq T} S^{(i)}_t \geq \bar{B}\\
 0                    & \hbox{otherwise.}
\end{cases}
\]
\end{mydef}
\noindent The payoff of the knock-out option is zeroed when barrier is hit.
\begin{mydef}
The payoff of the \textbf{down-and-out put} option on asset $S^{(i)}$ with exercise date $T$, strike price $E$ and barrier $\underline{B}$, equals
\[ C^{\hbox{\scriptsize put}}_{\hbox{\scriptsize d\&o}} = 
\begin{cases}
 (E - S^{(i)}_T)_+    & \hbox{if } \inf\limits_{0 \leq t \leq T} S^{(i)}_t \leq \underline{B}\\
 0                    & \hbox{otherwise.}
\end{cases}
\]
\end{mydef}
We have eight types of barrier options, as every one is call or put, up or down, in or out. They are all defined in similar manner. The best way to get a grip on the barrier options is possibly through a graphical example. Figure \ref{fig:barrier} discusses payoffs from an up-and-out call option in three diffrent scenarios. 
\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.3]{images/BasicsOfOptionPricing/barrier.pdf}
\caption{Consider up-and-out call option with strike 110, barrier 140, expiring at time 1. In the red scenario option is in-the-money at the maturity, however in the past the barrier was crossed, thus payoff is 0. In the blue scenario stock price ends about the level of 115, barrier wasn't reached, hence payoff equals 5. In case of green scenario payoff is 0, as it would be for vanilla option, because we ended out-of-the-money. }
\label{fig:barrier}
\end{figure}

Another modification of the vanilla options are the \textbf{Asian options}. Their payoff depends on an average price of the asset during options lifetime.
\begin{mydef}
 Payoffs of Asian call and put options on asset $S^{(i)}$ with exercise date $T$ and strike price $E$, are given by
\begin{align*}
 C^{\text{call}}_{\text{asian}} &= (\bar{S}^{(i)}_T - E)_+, \\
 C^{\text{put}}_{\text{asian}} &= (E - \bar{S}^{(i)}_T)_+, \\
\end{align*}
\end{mydef}
\noindent where
\[ \bar{S}^{(i)}_T = \frac{1}{K} \sum\limits_{j=0}^K S^{(i)}_{j\cdot T/K}, \]
for some $K$. 

So far we presented only options on one asset. Multiasset options are also in usage, for example \textbf{basket options} are options on value $\eta \cdot S$. Vector $\eta$ describes quantity of shares of the assets contained in a basket. The basket call option gives us right to buy whole set of assets for the specified price, and the basket put allows us to sell it.
\begin{mydef}
 Payoffs of basket call and put options on basket $\eta$ with exercise date $T$ and strike price $E$, are given by
\begin{align*}
 C^{\text{call}}_{\eta} &= (\eta \cdot S_T - E)_+, \\
 C^{\text{put}}_{\eta} &= (E - \eta \cdot S_T)_+, \\
\end{align*}
\end{mydef}

\paragraph{Why do we need derivatives in the first place?}
The well known anecdote claims that the first man who used derivatives was Tales of Miletus. His extraordinary skills allowed him to predict that the olive harvest next year will be large. During the winter, when nobody needed olive presses, he reserved them for summer. During the season demand for olive presses increased and Tales rented them for a good price. After all, it turned out that he earned much more then paid for the reservation. From this story appears the first reason to use options: they give opportunity to make money on accurate predictions.

Second, and probably more important reason of option usage, is possibility to hedge against unconvienient scenarios. Consider a producer making his articles from some raw material. The cost of his production depends on the price of this material. If it goes too high, then the factory may become unprofitable. By buying the options, the producer may ensure that the cost of the production will not exceed above known level. If the price of the raw material stays low, then the options expire worthless, but the producer stays content, because the production is not endangered. If asset price peaks, he can exercise the options. Either way he wins.


\paragraph{What is the purpose of exotic options?}
Altering the rules of ``typical'' payoffs may be caused by many reasons. The seller of a call option puts himself into a risk, induced by the fact, that his maximum loss is unbounded. Thus, he may be interested in entering only contracts with up-and-out barrier, which prevents too large payoffs. The buyer of the call option may want to hedge himself against high prices.
He may purchase cheaper version of the option, with down-and-out  barrier -- maybe if the asset price is low, he does not need any extra hedge. Asian options may be a good choice for risk-averse investors, because they are less sensitive to changes in the underlying price, especially in the time close to the maturity.

Described stories show that derivatives idea comes up in a natural way. In both stories there was an exchange of money for some goods. In the real live, however, situation is not always that clear. Sometimes, even if the investor exercise his option on some commodity, there is no real transaction performed, only the diffrence between prices is paid off.
It may seem that the derivatives are artificial tools, created by people living only in the theoretical, mathematical models. Some exotic options may be really complicated and at the first glance no one can tell what was the motivation of entering such contract. However, it is worth to remember, that many of the derivative contracts are designed by investors, economist or producers, and they correspond to their real needs. Mathematical models lend a hand in pricing such contracts.


\section{Black-Scholes model}
\label{sec:blackScholes}
In this section we recall famous Black-Scholes model, leading to a straightforward formula for the price of the European options. At first we discuss a case when $d=1$, i.e. the model has only one risky asset and a bond. For convenience we will write $S$ instead of $S^{(1)}$, and $B$ instead of $S^{(0)}$. We will use this convention every time when considering a market with one risky asset.

The assumptions are following:
\begin{enumerate}
  \item[BS1.] \textbf{The market does not admit arbitrage opportunities.}

 \item[BS2.] \textbf{The stock price of the underlying follows a geometric brownian motion.} Moreover drift $\mu$ and volatility $\sigma$ are constant in time. Thus, SDE of the option price is described by equation
\begin{equation}
 \label{eq:BS_dynamics}
 dS_t = \mu S_t dt + \sigma S_t dW_t. 
\end{equation}
 
  \item[BS3.] \textbf{There exists constant risk-free interest rate $r$.} In the other words, dynamics of $B$ is given by 
\[ dB_t = rB_t dt. \]
Investors may both, borrow and lend, any amount of money at rate $r$.

  \item[BS4.] \textbf{It is possible to buy and sell any amount of stock.} It means that investors can even trade fractional numbers of stock, and sell short unbounded quantity of shares.

  \item[BS5.] \textbf{All transactions do not incur any additional costs.}

  \item[BS6.] \textbf{The underlying does not pay a dividend.}
  
  \item[BS7.] We have to make one additional assumption on the options value. Many authors forget to mention it, altough it is required for It\^{o}'s lemma. Let $F$ be the process of the price of the option\footnotemark.
  \textbf{For some smooth function $\varphi$ the price process has the form:}
    \begin{equation}
    \label{eq:PriceProcessForm}
    F_t = \varphi(S_t, t).
    \end{equation}
This assumption looks entirely natural, but it can not be concluded from what we discussed so far. It must be taken as an axiom.
\end{enumerate}
\footnotetext{$F_t$ is the value of the option quoted at time $t$ (not discounted to time 0). The discounted price process is in this thesis denoted by letter $V$. }

Instead of (\ref{eq:PriceProcessForm}) we will write $F_t = F(S_t, t)$. Then $F$ has an ambigous meaning -- left $F$ denotes the price process and the right one is some function. However, as in many other literature, we will identify them, since it does not lead to misunderstanding.

Suppose we are constructing a portfolio consisting of a short position in one option and a long position in $\Delta$ shares. Let $\Pi$ be the value process of the portfolio. Equation of portfolio is given by
\begin{equation}
 \label{eq:portfolio}
  \Pi = \Delta S - F 
\end{equation}
We analyze how much the portfolio will change in a short period of time. We have
\[ d\Pi = \Delta dS - dF  \]
Note that we do not have to differentiate $\Delta$, because it is constant in an infinitesimal increment of time. To handle $dV$ we will use It\^{o}s lemma. Thus
\[ d\Pi = \Delta dS - \frac{\partial F}{\partial S}dS - \frac{\partial F}{\partial t}dt - \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2}dt  \]
The risk in an increment of the portfolio is carriered by changes of the stock price. By choosing
\begin{equation}
 \label{eq:delta}
 \Delta = \frac{\partial F}{\partial S}
\end{equation}
we get rid off the uncertainity. Now we have
\begin{equation}
  \label{eq:portfolio_inc}
 d\Pi = -(\frac{\partial F}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2})dt.
\end{equation}
The increment of $\Pi$ does not depend on any risky asset, hence no-arbitrage assumption induces
\[ d\Pi = r\Pi dt. \]
After substituting (\ref{eq:portfolio}), (\ref{eq:delta}) and (\ref{eq:portfolio_inc}) into above equation, we obtain
\[ -(\frac{\partial F}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2})dt = r(\frac{\partial F}{\partial S} S - F)dt, \]
which after simple calculation gives
\begin{equation}
 \label{eq:BSeq}
 \frac{\partial F}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 F}{\partial S^2} + r\frac{\partial F}{\partial S} S - rF = 0.
\end{equation}
Formula (\ref{eq:BSeq}) is known as \textbf{Black-Scholes equation}. Note that so far we did not say anything about the final condition of (\ref{eq:BSeq}), i.e. about the payoff off the option, thus this is a general equation. For European options it has straightforward solution, known as \textbf{Black-Scholes formula}.
\begin{prop}
\label{prop:BSFormula}
Prices of the European call and put options with time to expiration $T$, strike price $E$ and the underlying dynamics given by (\ref{eq:BS_dynamics}) are given by the following equations:
\begin{equation*}
  \begin{split}
    F_t\textsuperscript{call} &= S_t \Phi\bigl( d_1(t) \bigr) - e^{-r(T-t)} E \Phi\bigl(d_2(t) \bigr),\\
    F_t\textsuperscript{put} &= -S_t \Phi\bigl(-d_1(t) \bigr) + e^{-r(T-t)} E \Phi\bigl(-d_2(t) \bigr), 
  \end{split}
\end{equation*}
where
\begin{align*}
d_1(t) &= \frac{\ln\left(\frac{S_t}{E}\right)+\left(r+\frac{\sigma^{2}}{2}\right)(T-t)}{\sigma\sqrt{T-t}}\\
d_2(t) &= \frac{\ln\left(\frac{S_t}{E}\right)+\left(r-\frac{\sigma^{2}}{2}\right)(T-t)}{\sigma\sqrt{T-t}} = d_{1}(t)-\sigma\sqrt{T-t},\\
\Phi & \hbox{ is the distibution function of the standard normal distribution. } 
\end{align*}
\end{prop}
We prove this proposition at the end of the section \ref{sec:risk-neutral}, using the risk-neutral measure.

\paragraph{Multiasset model.}
All above assumptions move instantly to the market model with many assets, maybe with little edition:
\begin{enumerate}
 \item[BS2.] \textbf{Stock prices of all risky assets follow a geometric brownian motion.} Each risky asset $S^{(i)}$ has constant drift $\mu_i$ and volatility $\sigma_i$. In symbolic form:
\begin{equation}
 \label{eq:BS_multi_dynamics}
 dS^{(i)}_t = \mu S^{(i)}_t dt + \sigma S^{(i)}_t dW^{(i)}_t\ \ \ \ (i=1,2,\ldots,d). 
\end{equation}
  \item[BS3.]  The dynamics of $S^{(0)}$ is given by 
\[ dS^{(0)}_t = rS^{(0)}_t dt. \]
\end{enumerate}
  
The movements of the asset prices are not independent.
\begin{mydef}
 We say that the correlation between two risky assets $S^{(i)}$ and $S^{(j)}$ equals $\varrho_{ij}$ if and only if $\Corr(W^{(i)}, W^{(j)}) = \varrho_{ij}$.
\end{mydef}
In the other words by the correlation of two assets we understand the correlation between corresponding Wiener processes, appearing in their dynamics. A matrix of the correlation between all risky processes will be denoted by $\Sigma$,
\begin{equation*}
 \Sigma = \left( \begin{array}{cccc}
           \varrho_{11} & \varrho_{12} & \cdots & \varrho_{1d} \\
           \varrho_{21} & \varrho_{22} & \cdots & \varrho_{2d} \\
           \vdots & \vdots & \ddots & \vdots \\
           \varrho_{d1} & \varrho_{d2} & \cdots & \varrho_{dd} \\
          \end{array} \right)
\end{equation*}

\textbf{The assumptions described in this section will hold true to the rest of the thesis.}

\section{Model calibration}
By looking at the previous section we can specify a set of values by which the model is parameterised:
\begin{itemize}
 \item drifts $\mu_1, \mu_2, \ldots, \mu_d$,
 \item volatilities $\sigma_1, \sigma_2, \ldots, \sigma_d$,
 \item correlation $\Sigma$,
 \item riskless interest rate $r$.
\end{itemize}
While calibrating a model it is conveniet to assume that today is time $0$. We are interested in modeling asset prices in the future, up to time $T$. It is natural to use negative $t$ to denote times in the past. For example $S^{(i)}_{-0.5}$ means the price of the $i$\textsuperscript{th} asset half of a year ago. Hence for $t > 0,\ S_t$ is random vector, which we are about to model, and for $t \leq 0,\ S_t$ is a vector with historical prices, which may be obtained from stock archives.

Since asset prices follow (\ref{eq:BS_multi_dynamics}) and its solution is given by (\ref{eq:gmb_sol}), thus for all $i$
\[  S^{(i)}_{t_{n+1}} = S^{(i)}_{t_n} \exp\left\{ (\mu_i - \frac{1}{2}\sigma_i^2)\Delta t + \sigma_i \sqrt{\Delta t} Z_i \right\}, \]
where $\Delta t = t_{n+1} - t_n$, $Z$ is a random vector with corralation matrix $\Sigma = \bigl( \varrho_{ij} \bigr)_{i,j=1}^d$, and for each $Z_i$, $Z_i \sim \mathcal{N}(0,1)$. Let
\[  L^{(i)}_{n+1} = \ln\left( \frac{S^{(i)}_{t_{n+1}}}{S^{(i)}_{t_n}} \right). \]
It is clear that $ L^{(i)}_{n+1} \sim \mathcal{N}\left(  (\mu_i - \frac{1}{2}\sigma_i^2)\Delta t,\ \sigma_i^2 \Delta t \right)$

The key to the calibration is an assumption that in the past, price processes followed (\ref{eq:BS_multi_dynamics}) as well. Let $\overline{T}$ denote how old is the oldest price observation, and $N$ be such that $N \cdot \Delta t = \overline{T}$. Furthermore let $t_k = -(N-k)\Delta t\ (k=0,1,\ldots,N)$. Values $t_k$ are times in which we take historical prices, from $t_0 = -\overline{T}$, to $t_N = 0$, which is today. Let us focus on the $i$\textsuperscript{th} asset. We have $N+1$ historical prices:
\[  \bigl( S^{(i)}_{t_0}, S^{(i)}_{t_1}, \ldots,S^{(i)}_{t_N} \bigr), \]
from which we obtain a vector
\[ \bigl( L^{(i)}_{1}, L^{(i)}_{2}, \ldots, L^{(i)}_{N} \bigr) \]
with $N$ samples from distribution $\mathcal{N}\left(  (\mu_i - \frac{1}{2}\sigma_i^2)\Delta t,\ \sigma_i^2 \Delta t \right)$.

In practice, usually $\Delta t = 1/252$, because there are about 252 working days in a year. However, it is debatable how long should be $\overline{T}$. Values taken most often vary from ... to ...
{\Large \color{red} TODO TODO TODO TODO }

Finally, we present how to obtain values of model parameters.
\paragraph{Drifts and volatilities.}
Let $L^{(i)} \sim \mathcal{N}\left(  (\mu_i - \frac{1}{2}\sigma_i^2)\Delta t,\ \sigma_i^2 \Delta t \right)$. It means that
\begin{equation*}
 \begin{split}
  \E\left( L^{(i)} \right) &= (\mu_i - \frac{1}{2}\sigma_i^2)\Delta t, \\
  \Var\left( L^{(i)} \right) &= \sigma_i^2 \Delta t.
 \end{split}
\end{equation*}
Hence
\begin{equation*}
 \begin{split}
  \mu_i  &= \frac{ 2\E\left( L^{(i)} \right) + \Var\left( L^{(i)} \right) }{2\Delta t}, \\
  \sigma_i^2 &= \frac{\Var\left( L^{(i)} \right)}{\Delta t}.
 \end{split}
\end{equation*}
Now we can use the sample vector to estimate expectaion and variance. Let
\begin{equation*}
 \begin{split}
  \alpha_i &= \frac{1}{N}\sum\limits_{k=1}^{N} L^{(i)}_k\\
  \beta_i &= \frac{1}{N-1}\sum\limits_{k=1}^{N}(L^{(i)}_k - \alpha_i)^2
 \end{split}
\end{equation*}
Values $\alpha_i$ and $\beta_i$ are unbiased estimators of expectation and variance respectively. Thus we assign
\begin{equation*}
 \begin{split}
  \mu_i  &= \frac{ 2\alpha_i + \beta_i }{2\Delta t}, \\
  \sigma_i^2 &= \frac{\beta_i}{\Delta t}.
 \end{split}
\end{equation*}
\begin{remark}
 Calculating drifts is in many applications redundant. Note that there is no drift term in Black-Scholes formula nor equation. As it is shown in section \ref{sec:risk-neutral} also the dynamics in the martingale measure does not depend on the drift.
\end{remark}


\paragraph{Correlation.} At first recall that $\Corr(aX + b, cY + d) = \Corr(X,Y)$. Thus finding a correlation between $Z_i$ and $Z_j$ is equivalent to finding corralation between $L^{(i)}$ and $L^{(j)}$. We can do it using Pearson's estimator:

\[ \varrho_{i,j} = \frac{1}{N-1} \frac{\sum\limits_{k=1}^N(L^{(i)}_k - \alpha_i)(L^{(j)}_k - \alpha_j)}{\sqrt{\beta_i \beta_j}} \]

\paragraph{Riskless interest rate.}
In order to calculate the interest rate it is necessary to choose a bond whose maturity is close to the expiry of valuated option. The interest rate implied by that bond reflects well the real interest rate in the concerned time.

It is clear that
\[ C = Ne^{-rT}, \]
where $C$ is price of the bond, $N$ is its nominal value, $r$ is the interest rate implied by the bond, and $T$ is the maturity time. By simple transformation
\begin{equation*}
r = \dfrac{\ln(\frac{N}{C})}{T}.
\end{equation*}

\section{Risk-neutral pricing}
\label{sec:risk-neutral}
Black-Scholes formula allows us to price only European vanilla options. In this section we present a general method of pricing European contingent claims. 
\begin{mydef}
 The discounted value of the contingent claim $C$ is given by
 \begin{equation*}
  H = \frac{C}{S^{(0)}_T}.
 \end{equation*}
 Random variable $H$ is called a \textbf{discounted claim}.
\end{mydef}

Values $C$ and $H$ correspond to the payoff of an instrument. We need notation to talk about its price also before maturity.
\begin{notation}
 The (discounted) \textbf{price process} is denoted by $V_t$. 
\end{notation}
\begin{remark}
 In section \textit{Black-Scholes model} value $V_t$ denoted price of the option at time $t$ (no discounting). From now on $V_t$ is price of the contingent claim at time $t$ discounted to time~$0$.
\end{remark}

Next theorem is the key to defining prices of contingent claims. But first we define a class of claims for which pricing is pretty straightforward. 
\begin{mydef}
 A contingent claim is called \textbf{attainable} if there exists a self-financing trading strategy $\xia$ whose portfolio coincides with $C$ at maturity, i.e.
 \[ C = \xia \cdot \Sa_T. \]
 The trading strategy $\xia$ is then called the \textbf{replicating strategy} for $C$.
\end{mydef}

\begin{thm}
 For every attainable discounted claim $H$ and for every equivalent martingale measure $\Pm$
 \[ \Em [H] < \infty. \]
 Moreover, for every replicating strategy $\xia$ its value process satisfies
 \begin{equation}
  V^\xi_t = \Em[H | \mathcal{F}_t] \hbox{ P-a.s., } 0 \leq t \leq T .
 \end{equation}
\end{thm}
Proof of this theorem reader may find in \cite{follmer}.

Since there is no $\xia$ in term $\Em[H | \mathcal{F}_t]$, so value $V^\xi_t$ does not depend on choice of $\xia$. Note also that
\begin{equation*}
 \Em[H | \mathcal{F}_t]  = \Em[\xia \cdot \Xa_T | \mathcal{F}_t]  = \xia \cdot \Xa_t
\end{equation*}
Thus, value $\Em[H | \mathcal{F}_t]$ does not depend on choice of $\Pm$. 
Since attainable discounted claim $H$ and its replicating strategy $\xia$ have the same payoff at time $T$, thus no-arbitrage assumption induces
\[ V_t = V^\xi_t,\ \ 0 \leq t \leq T. \]
Thus in particular it implies
\begin{coro}
\label{coro:price_mth}
Let $H$ be a discounted contingent claim and $V$ be its price process. Then
\begin{equation}
 \label{eq:price_mtg}
 V_0 = \Em[H].
\end{equation}
\end{coro}
\noindent This equation tells us that \textbf{value of the option is an expectation of its payoff} (under the risk-neutral measure).

The above theorem suggests how price processes should look in general.
\begin{mydef}
 The (discounted) price process of the discounted claim $H$ is given by
 \begin{equation*}
  V_t = \Em[H | \mathcal{F}_t].
 \end{equation*}
 Such $V$ is a $\Pm$-martingale.
\end{mydef}
For general claims process $V$ depends on the choice of an equivalent martingale measure. However, it may be proven that the market model consisting of the discounted assets $(X^{(0)}, X^{(1)},\ldots,X^{(d)}, V)$ is arbitrage-free, regardless of the choice of $\Pm$. In that sense every possible price process $V$ is equally good.

\subsection*{Change of the measure}
We have discussed how equivalent martingale measures can be used for option pricing, but so far we did not tell how to find them. It is difficult to find in literature suitable theorem, which would exactly match our needs, thus we have to prove some facts ourselves.

\begin{lemma}
\label{lemma:measure_change}
 Suppose that $S$ is a $d$-dimensional stochastic process, where each $S^{(i)}$ follows the geometric Brownian motion, that is
 \begin{equation}
  \label{eq:dynamics_real}
  dS^{(i)} = \mu_i S^{(i)} dt + \sigma_i S^{(i)} d\bar{W}^{(i)},\ \ \ (i=1,2,\ldots,d)
 \end{equation}
 where each $\bar{W}^{(i)}$ is a Brownian motion under measure $\P$ and $\Corr(\bar{W}^{(i)}, \bar{W}^{(j)}) = \rho_{ij}$. For every vector $(\nu_1, \nu_2, \ldots, \nu_d)$ there exists equivalent probability measure $\mathbb{Q}$, such that the equation (\ref{eq:dynamics_real}) may be rewritten in the form
  \begin{equation}
  dS^{(i)} = \nu_i S^{(i)} dt + \sigma_i S^{(i)} dW^{(i)},\ \ \ (i=1,2,\ldots,d)
 \end{equation}
 where each $W^{(i)}$ is a Brownian motion under equivalent measure $Q$ and\\ $\Corr^Q(W^{(i)}, W^{(j)}) = \rho_{ij}$.
\end{lemma}

\begin{proof}
 Let $\Sigma = (\rho_{ij})_{i,j=1}^d$ be a covariance matrix (which in this case is the same as correlation matrix). Cholesky's algorithm allows us to decompose $\Sigma$ to the form
 \[ \Sigma = LL^T, \]
 where $L$ is lower traingular matrix. Hence, $\bar{W}$ may be written in the form
 \[ \bar{W} = L \bar{V}, \]
 where $\bar{V}$ is a standard $d$-dimensional Wiener process under measure $\P$. Let us apply Theorem \ref{thm:girsanov} (Girsanov theorem) with $\varphi = (\theta_1, \theta_2, \ldots, \theta_d)'$, where all $\theta_i$ are constant. It implies that
 \[ V_t = \bar{V}_t - t\theta \]
 is $d$-dimensional standard Wiener process under measure $\mathbb{Q}$, which is defined as
 \[\frac{d\mathbb{Q}}{d\P} = \exp\left\{ \sum\limits_{i=1}^d \theta_i \bar{W}^{(i)}_T - \frac{T}{2} ||\theta||^2 \right\}.\] Thus
 \begin{equation*}
  \begin{split}
   dS^{(i)} &= \mu_i S^{(i)} dt + \sigma_i S^{(i)} d\bar{W}^{(i)} \\
            &= \mu_i S^{(i)} dt + \sigma_i S^{(i)} d\left(\sum\limits_{k=1}^i l_{ik} \bar{V}^{(k)}\right) \\
            &= \mu_i S^{(i)} dt + \sigma_i S^{(i)} d\left(\sum\limits_{k=1}^i \bigl[ l_{ik}\theta_k t + l_{ik} V^{(k)} \bigr] \right) \\    
            &= \left[ \mu_i + \sigma_i \sum\limits_{k=1}^i l_{ik}\theta_k \right] S^{(i)}dt + d\sum\limits_{k=1}^i l_{ik} V^{(k)} \\      
  \end{split}
 \end{equation*}
 By substituting
 \begin{align*}
  \theta_1 &:= \frac{\nu_1 - \mu_1}{\sigma_1 l_{11}}\\
  \theta_i &:= \frac{\nu_i - \mu_i - \sigma_i \sum\limits_{k=1}^{i-1} l_{ik}\theta_k}{\sigma_il_{ii}}\ \ \ (i=2,3,\ldots,d)\\
         W &:= LV
 \end{align*}
 we get the thesis.
\end{proof}

Above lemma allows us to describe vector of price processes in terms of some equivalent measures, however we need a very particular measure -- the martingale measure.

\begin{prop}
\label{prop:rn-dynamics}
 In real measure $\P$ the risky assets follow a geometric Brownian motion, as in equation (\ref{eq:dynamics_real}). Under equivalent martingale measure $\Pm$ the dynamics has the form
 \begin{equation}
  \label{eq:dynamics_neutral}
  dS^{(i)} = r S^{(i)} dt + \sigma_i S^{(i)} dW^{(i)}.
 \end{equation}
\end{prop}
\begin{proof}
 Lemma \ref{lemma:measure_change} states that there exist equivalent measure $\Pm$ under which price processes are described by equation (\ref{eq:dynamics_neutral}). We will show that it is martingale measure.
 From (\ref{eq:gmb_sol})
 \[ X_t = e^{-rt} S_t = S_0 e^{ -\frac{1}{2}\sigma^2 t + \sigma W_t }. \]
 Let $0 \leq s \leq t \leq T$. We have
 \begin{equation*}
  \begin{split}
   \Em[X_t | \mathcal{F}_s] &= \Em[ S_0 e^{ -\frac{1}{2}\sigma^2 t + \sigma W_t } | \mathcal{F}_s] \\
       &= S_0 e^{-\frac{1}{2}\sigma^2 t} \Em[ e^{  \sigma W_s} e^{ \sigma (W_t - W_s) } | \mathcal{F}_s] \\
       &= S_0 e^{-\frac{1}{2}\sigma^2 t + \sigma W_s} \Em[ e^{ \sigma (W_t - W_s) }] \\
       &= S_0 e^{-\frac{1}{2}\sigma^2 t + \sigma W_s}  e^{ \frac{1}{2}\sigma^2(t-s) } \\
       &= S_0 e^{-\frac{1}{2}\sigma^2 s + \sigma W_s} = X_s.
  \end{split}
 \end{equation*}
Hence $\Pm$ is an equivalent martingale measure.
\end{proof}

Propositions \ref{prop:rn-dynamics} and \ref{prop:solution_dynamics} have crucial meaning in our applications. They allow us to generate trajectories of the asset prices under the risk-neutral measure, which is essential in the Monte Carlo pricing. We show one more application of the risk-neutral pricing -- it can be used to derive Black-Scholes formula.
\begin{proof}[(Proof of Proposition \ref{prop:BSFormula})]
 From Proposition \ref{prop:solution_dynamics}
 \[ S_T = S_t \exp\bigl\{ (r - \frac{1}{2} \sigma^2)(T-t) + \sigma W_{T-t} \bigr\} = S_t e^Z, \]
 where $Z \sim \mathcal{N}\left((r - \frac{1}{2} \sigma^2)(T-t), (T-t)\sigma^2 \right)$ in the measure $\Pm$. Let $f_Z$ be the density of $Z$ and $S_t = s$.
 \begin{equation*}
  \begin{split}
    F_t\textsuperscript{call} &= e^{-r(T-t)} \Em\left[(S_T-E)_+ | \mathcal{F}_t \right] = e^{-r(T-t)} \Em\left[(S_T-E)_+ |S_t\right] \\
    &= e^{-r(T-t)} \Em\left[(s e^Z-E)_+ \right] = e^{-r(T-t)} \Em\left[(s e^Z-E) \mathbbm{1}\left({\textstyle Z \geq \ln\left(\frac{E}{s}\right)} \right) \right] \\
    &= e^{-r(T-t)} \int\limits_{\ln(E/s)}^\infty (se^z - E)f_Z(z) dz \\
    &= s\int\limits_{\ln(E/s)}^\infty e^{-r(T-t)}e^z f_Z(z) dz - e^{-r(T-t)} E\int\limits_{\ln(E/s)}^\infty f_Z(z) dz = (\bigstar)
  \end{split}
 \end{equation*}
 Simple calculation gives
 \[ \int\limits_{\ln(E/s)}^\infty e^{-r(T-t)}e^z f_Z(z) dz = \Phi\bigl( d_1(t) \bigr),  \ \ \ 
    \int\limits_{\ln(E/s)}^\infty f_Z(z) dz = \Phi\bigl( d_2(t) \bigr),  \ \ \ \]
 hence 
 \[ (\bigstar) = S_t \Phi\bigl( d_1(t) \bigr)  - e^{-r(T-t)} E \Phi\bigl( d_2(t) \bigr) . \]
 Derivation of the formula for put's price is analogous.
\end{proof}




\chapter[{Pricing European options using Monte Carlo method}]{Pricing European options using \\Monte Carlo method}
The Black-Scholes theory gives us compact formula for pricing european vanilla options. Such options gained popularity and are traded in many world markets. However, over the counter (ab. OTC) investors may trade much more complicated instrumets, whose value can not be derived analitically. Thus, other methods must be used.
The most popular are finite diffrence, binomial trees and Monte Carlo. In this thesis only the last one is presented.

\section{Vanilla options}
\label{sec:pricing_vanilla}

In order to use the Monte Carlo method in option pricing, we need to involve the theory presented in the section \ref{sec:risk-neutral}. First we will focus on the case, when the only instruments traded in the market are $B = S^{(0)}$ -- a riskless bank account, and a risky asset $S = S^{(1)}$.

From Corollary \ref{coro:price_mth} we have
\begin{equation}
 \label{eq:price_for_MC}
 V_0 = \Em[H].% = \Em[\frac{C}{S^{(0)}_T}] = e^{-rT} \Em[C].
\end{equation}
By comparision with (\ref{eq:EY}), we see that equation (\ref{eq:price_for_MC}) is exactly what we need for simulations. To calculate options price we have to replicate its payoff many times and take an average. Note, however, that expectaion is taken under the risk-neutral measure. Hence, also the asset price must be generated under the risk-neutral measure. Corollary \ref{prop:rn-dynamics} describes its dynamics:
\[ dS = rSdt + \sigma S dW. \]
Lemma \ref{prop:solution_dynamics} gives the solution to above SDE:
\begin{equation}
 \label{eq:vanilla_St}
 S_t = S_0 \exp\left\{ (r - \frac{1}{2}\sigma^2)t + \sigma W_t \right\}.
\end{equation}
In case of vanilla options only the value at the end of the trajectory is important, i.e. at maturity time $T$. Thus, we need
\begin{equation}
\label{eq:vanilla_ST}
 S_T = S_0 \exp\left\{ (r - \frac{1}{2}\sigma^2)T + \sigma W_T \right\},
\end{equation}
where, from properties of the Wiener process, $W_T \sim \mathcal{N}(0,T)$. Value of $S_T$ depends on $W_T$, hence it is justified to write $S_T = S_T(W_T)$.

Let $H = g(S_T)$ and $E$ be the strike price. For instance, if $H$ is a call option $g(x) = (x - E)_+$, and if $H$ is a put $g(x) = (E - x)_+$, but in fact $H$ might be any claim whose payoff depends only on $S_T$. Equation (\ref{eq:vanilla_ST}) tells us how to generate the asset price; by applying function $g$ we generate the payoff.
Since $S_T$ is also a function of some $Z \sim \mathcal{N}(0,T)$, thus actually $H = g(S_T(Z)) =: f(Z)$, for $f = g \circ S_T$. By $Z_i, i = 1,2,...$, we will denote replications of $Z$.
The crude Monte Carlo estimator has the form:
\begin{equation}
 \label{eq:vanilla_CMC}
 \CMCa[H, 2n] = \frac{1}{2n}\sum\limits_{i=1}^{2n} f(Z_i).
\end{equation}
We will also use antithetic variates, where an antithetic variable to $f(Z_i)$ will be  $f(-Z_i)$. 
\begin{equation}
 \label{eq:vanilla_AV}
 \AVa[H, n] = \frac{1}{n}\sum\limits_{i=1}^{n} \frac{f(Z_i) + f(-Z_i)}{2}.
\end{equation}
To use the control variates method, recall that $S_0 = \Em[S_T]$. It implies that we can take $S_T$ as a control variate, hence
\begin{equation}
 \label{eq:vanilla_CV}
 \CVa[H, n] = \frac{1}{n}\sum\limits_{i=1}^{n} \left( f(Z_i) + c (S_T(Z_i) - S_0) \right),
\end{equation}
where $c$ is a value calculated as in equation (\ref{eq:CVc}).

To get a grip on using above estimators in practice, we present how exactly looks pricing call options using the control variates method. It is shown in Algorithm \ref{alg:priceCallCV}. Argument of the algorithm is \texttt{n} -- number of simulations. 
\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{PriceCallCV}{$n$, $S_0$, $\sigma$, $r$, $T$, $E$ }
    \State  $S,H,Y \gets $ arrays with indices from 1 to $n$.
    \For{$i = 1$ {\bf to} $n$} 
      \State $Z \gets$ generate standard normal
      \State $S[i] \gets S_0 \cdot \exp\{ (r - \frac{1}{2}\sigma^2 ) \cdot T + \sigma \cdot Z \}$
      \State $H[i] \gets \max(S - E, 0) \cdot \exp\{-rT\}$
    \EndFor
    \State $c \gets -\Cov(H,S)/\Var(S)$
    \For{$i = 1$ {\bf to} $n$} 
      \State $Y[i] \gets  H[i] + c\cdot \bigl(S[i] - S_0\cdot \exp\{rT\} \bigr)$
    \EndFor    
    \State $price \gets mean(Y)$
    \State $var \gets var(Z)$
    \State $se \gets \sqrt{var / n}$
    \State \Return $(price, var, se)$
  \EndFunction
 \end{algorithmic}
 \caption{Valuation of a call option using CV method.}
 \label{alg:priceCallCV}
\end{algorithm}
Values calculated in lines 12-14 are price of the option, variance and standard error of the estimation.

Implementation of an option pricer based on estimators (\ref{eq:vanilla_CMC})-(\ref{eq:vanilla_CV}) allows us to compare these methods. In sections \ref{sec:pricing_vanilla} and \ref{sec:pricing_complicated} we will always assume following parameters:
\begin{equation}
\label{eq:marketParams}
\begin{split}
 S &= 100 \\
 \sigma &= 0.20 \\
 r &= 0.05 \\
 T &= 1 \hbox{\ \ \ (options expire after one year)}
\end{split}
\end{equation}
First consider a call option with strike 90. The Black-Scholes value of the option is 16.70. Results of the Monte Carlo pricing are shown in Table \ref{tab:vanilla1} and Figure \ref{fig:vanilla1}.

\begin{table}
\centering
 \caption{Results of pricing call@90. Black-Scholes price is 16.70.}
 \label{tab:vanilla1}
\begin{tabular} {||r | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 17.09 & 0.393 & 16.67 & 0.185 & 16.74 & 0.127 \\ \hline 
10000  & 16.98 & 0.123 & 16.66 & 0.061 & 16.67 & 0.041 \\ \hline 
100000 & 16.71 & 0.039 & 16.67 & 0.019 & 16.70 & 0.013 \\ \hline 
\end{tabular}  
\end{table}
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxCall90.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergenceCall90.pdf}
\caption{Accuracy of pricing call@90. Box plot on the left was created by running estimation 100 times for each method, each estimation used 10000 replicated pairs. Chart on the right shows speed of convargence, i.e. how the estimation changes as the number of performed replications increases. The horizontal line is the options value calculated form Black-Scholes formula. }
\label{fig:vanilla1}
\end{figure}

It is clear, that in this case CV method proved itself the best. It is caused by the fact, that in many simulations option expires in the money. In consequence the payoff is highly correlated with the asset price at the end of the path. Let us consider now a call with higher strike, 130, whose Black-Scholes price equals 1.64. Look at the Table \ref{tab:vanilla2} and Figure \ref{fig:vanilla2}. 

\begin{table}
\centering
 \caption{Results of pricing call@130. Black-Scholes price is 1.64.}
 \label{tab:vanilla2}
\begin{tabular} {||r | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 1.67 & 0.135 & 1.56 & 0.126 & 1.67 & 0.147 \\ \hline 
10000  & 1.61 & 0.043 & 1.60 & 0.041 & 1.60 & 0.046 \\ \hline 
100000 & 1.63 & 0.014 & 1.64 & 0.013 & 1.64 & 0.015 \\ \hline 
\end{tabular}  
\end{table}
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxCall130.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergenceCall130.pdf}
\caption{Accuracy of pricing call@130. Plots were created in the similar manner as on the Figure \ref{fig:vanilla1}.}
\label{fig:vanilla2}
\end{figure}
This time the asset price usually ended above the options strike, what means that in most simulations payoff was 0. Thus, correlation between payoff and assets final price is low, and in consequence CV did not bring a significant improvement.
\begin{remark}
 Box plot from Figure \ref{fig:vanilla2} shows that CMC estimator has smaller dispersion than AV and CV. That is because we compare $\CMCa[H, 2n]$ (index is $2n$) with $\AVa[H, n]$ and $\CVa[H, n]$. We do so, because then the number of used random variables is the same in each estimator.
 However, generating an antithetic variate or a control variate is often instantaneous. Hence calculating $\CMCa[H, 2n]$ may be much slower. If in time $t$ we can compute  $\CMCa[H, a]$, $\AVa[H, b]$ and $\CVa[H, c]$, then $\CMCa[H, a]$ will always\footnote{Of course we assume that antithetic variate is really antithetic, i.e. it is negatively correlated with the base variate, and control variate is not independent from the base variate.} have greater variance than $\AVa[H, b]$ and $\CVa[H, c]$.
\end{remark}

\section{Path-depenent instruments}
\label{sec:pricing_complicated}

To price vanilla options it was sufficient to generate the asset price only at the maturity. However, there are contingent claims whose payoff depends on the entire history, for example barrier options or Asian options. Of course, we can not generate the entire trajectory, since it has continuum points. Thus, values of the asset must be generated in a finite number $K$ of points. By taking $K$ large enough, a continous model is approximated sufficiently.

It follows from equation (\ref{eq:vanilla_St}) that
\begin{equation}
 \label{eq:priceChange}
 S_{t + {\Delta} t} = S_t \exp\left\{ (r - \frac{1}{2}\sigma^2)\Delta t + \sigma \sqrt{\Delta t} Z \right\},
\end{equation}
where $Z$ is standard normal. Above formula allows us to generate prices of the asset in specified points step by step.

Figure \ref{fig:trajectories} shows a thousand of trajectories simulated accordingly to equation (\ref{eq:priceChange}). Note that the mean of the asset price at the final time is slightly above $S_0 = 100$. It corresponds to the fact that $\Em [S_T] = e^{rT}S_0$, which for parameters of the simulations equals $100\cdot e^{0.05} \approx 105.13$.

\begin{figure}[ht]
\centering
 \includegraphics[scale=0.4]{images/PricingEuropean/trajectories50.pdf}
\caption{A thousand of simulated trajectories of the asset price, under paratemeters ${T=1},\ {\sigma=0.2}$, ${r=0.5},\ {S_0=100}$. Each path was generated in $K=50$ points. The darker is the area the greater is the concentration of trajectories.}
\label{fig:trajectories}
\end{figure}

In theory, value of the discounted claim now has the form $H = g(S)$, for some $g$, i.e. $H$ is a function of the whole process $S$. As mentioned before, in order to make $H$ computable, we are forced to treat $H$ as a function of $S$ in limited number of points, that is $H = g\bigl(S_0, S_{\Delta t}, ..., S_T\bigr),\ T = K\cdot\Delta t$.
Path replications will be denoted by $S_i\ (i=1,2,...$), i.e. value $S_{i,t}$ means what was the asset price at time $t$, on $i$-th simulated path. The CMC estimator is analogous to (\ref{eq:vanilla_CMC})
\begin{equation*}
 \CMCa[H, n] = \frac{1}{n}\sum\limits_{i=1}^n g\bigl(S_{i,0}, S_{i,\Delta t}, ..., S_{i,T}\bigr)
\end{equation*}
For example for Asian call option
\begin{equation*}
 \CMCa[H, n] = \frac{1}{n}\sum\limits_{i=1}^n \left( \frac{1}{K} \sum\limits_{j=1}^K S_{i,j \Delta t} - E \right)_+
\end{equation*}
and for a put option with down-and-out barrier $B$
\begin{equation*}
 \CMCa[H, n] = \frac{1}{n}\sum\limits_{i=1}^n \left( (E - S_{i,T})_+ \cdot \prod\limits_{j=0}^K \mathbbm{1}\bigl(S_{i,j \Delta t} \geq B\bigr) \right).
\end{equation*}
Adjusting above estimators to use control variates does not bring any difficulties. The asset price at the end of the path may still be the control variate, however, better suited is the payoff from the analogous vanilla option (at least for barrier and Asian options). For instance for Asian put option
\begin{equation*}
 \CVa[H, n] = \CMCa[H, n] + \frac{c}{n} \sum\limits_{i=1}^n \Bigl( (E - S_{i,T})_+ - \Em (E - S_T)_+ \Bigr),
\end{equation*}
where $c$ is calculated as in (\ref{eq:CVc}) and value $\Em (E - S_T)_+$ is known from Black-Scholes formula.

In previous section while using AV method, we generated negatively correlated variables representing the asset price at the expiry of the option. Since now payoff depends on the whole process, thus we have to generate the antithetic trajectories. Algorithm \ref{alg:single-tr} describes how to do it. Figure \ref{fig:trajectoriesAnti} gives an idea how antithetic paths look like.
We omit exact formulas for $\AVa[H, n]$, because they are becoming lengthy and overly complicated. Analysing an example application of AV method should be sufficient to understand how it works in general. To this end, we present procedure of pricing Asian call options (Algorithm \ref{fig:trajectoriesAnti}).

\begin{figure}
\centering
 \includegraphics[scale=0.8]{images/PricingEuropean/trajectoriesAnti.pdf}
\caption{Pair of antithetic trajectories generated by an implementation of Algorithm \ref{alg:single-tr}.}
\label{fig:trajectoriesAnti}
\end{figure}
\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{Trajectory}{$S_0$, $\sigma$, $r$, $T$, $K$}
  \State pos, neg $\gets$ arrays with indices from $0$ to $K$
  \State pos[0] $\gets$ neg[0] $\gets S_0$
  \State $dt \gets T/K$
  \For{$i=1$ {\bf to} $K$}
    \State $Z \gets$ generate standard normal
    \State pos[$i$] $\gets$ pos[$i-1$] $\cdot \exp\left\{ (r - \frac{1}{2}\sigma^2) dt + \sigma \sqrt{dt} Z \right\}$
    \State neg[$i$] $\gets$ neg[$i-1$] $\cdot \exp\left\{ (r - \frac{1}{2}\sigma^2) dt - \sigma \sqrt{dt} Z \right\}$
  \EndFor
  \State \Return (pos, neg)
  \EndFunction
 \end{algorithmic}
 \caption{Generating antithetic trajectories.}
 \label{alg:single-tr}
\end{algorithm}
 
\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{PriceAsianCallAV}{$n$, $S_0$, $\sigma$, $r$, $T$, $E$, $K$}
    \State  $sum \gets sum\_sq \gets 0$
    \For{$i=1$ {\bf to} $n$}
      \State (pos,neg) $\gets$ \Call{Trajectory}{$S_0$, $\sigma$, $r$, $T$, $K$}
      \State $H_{pos} \gets \max($mean(pos)$- E, 0) \cdot \exp\{-rT\}$
      \State $H_{neg} \gets \max($mean(neg)$- E, 0) \cdot \exp\{-rT\}$
      \State $H \gets \frac{1}{2} \cdot (H_{pos} + H_{neg})$
      \State $sum \gets sum + H$
      \State $ sum\_sq \gets sum\_sq + H^2$
    \EndFor
    \State $var \gets (sum\_sq - sum \cdot sum/n) / (n-1)$
    \State $se \gets \sqrt{var / n}$
    \State $price \gets sum / n$
    \State \Return $(price, var, se)$
  \EndFunction
 \end{algorithmic}
 \caption{Pricing Asian call options}
 \label{alg:priceAsianAV}
\end{algorithm}

In a similar manner we can value any path-dependent options. For instance we present results of pricing some barrier options. In this section we still set market parameters as in (\ref{eq:marketParams}), moreover we take
\[ K = 50, \]
it may be regarded as checking once a week if barrier was hit.

Suppose $S$ is an exchange rate between some currencies. Consider an exporter whose production becomes unprofitable when exchange rate becomes too low. He would like to be hedged for pesimistic scenarios, thus he is interested in purchasing put options with strike 100, whose price from the Black-Scholes formula is 5.57.
In order to save some capital he prefers cheaper barrier options rather than vanilla options. He may think the following: ``If the exchange rate at some point will be very high, then it is very likely that my option will expire worthless. It means that I will not need an option when the rate is high.''. Thus he may decide to buy put options with strike 100 and with up-and-out barrier 115.
Monte Carlo methods allow us to price such an instrument, and the results are gathered in Table \ref{tab:barrier1} and Figure \ref{fig:barrier1}. On the other hand, the exporter may think: ``I can stand if the rate is not too bad. However, if the situation gets really ugly, I would like to sell part of my production for good money.''. Hence, he may be interested in put options with strike 100 and with down-and-in barrier 70.
Table \ref{tab:barrier2} and Figure \ref{fig:barrier2} present results of pricing such instrument with Monte Carlo methods.

\begin{table}
\centering
 \caption{Results of pricing put@100 with up-and-out barrier 115. Black-Scholes price of the option without barrier equals 5.57.}
 \label{tab:barrier1}
\begin{tabular} {||r | c | c | c | c |c | c ||}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 5.10 & 0.189 & 5.13 & 0.150 & 5.20 & 0.072 \\ \hline 
10000  & 5.14 & 0.060 & 5.15 & 0.049 & 5.15 & 0.023 \\ \hline 
100000 & 5.20 & 0.019 & 5.17 & 0.015 & 5.18 & 0.007 \\ \hline 
\end{tabular}  
\end{table}
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxPut100UaO115.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergencePut100UaO115.pdf}
\caption{Accuracy of pricing put@100 with up-and-in barrier 115. Plots were created in the similar manner as on the Figure \ref{fig:vanilla1}.}
\label{fig:barrier1}
\end{figure}

\begin{table}
\centering
 \caption{Results of pricing put@100 with down-and-in barrier 70. Black-Scholes price of the option without barrier equals 5.57.}
 \label{tab:barrier2}
\begin{tabular} {|r |c |c |c |c |c |c |}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 1.33 & 0.138 & 1.38 & 0.135 & 1.37 & 0.152 \\ \hline 
10000  & 1.29 & 0.043 & 1.31 & 0.043 & 1.31 & 0.049 \\ \hline 
100000 & 1.38 & 0.014 & 1.36 & 0.014 & 1.36 & 0.016 \\ \hline 
\end{tabular}
\end{table}  
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxPut100DaI70.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergencePut100DaI70.pdf}
\caption{Accuracy of pricing put@100 with down-and-in barrier 70. Plots were created in the similar manner as on the Figure \ref{fig:vanilla1}.}
\label{fig:barrier2}
\end{figure}

As previously, CV seems to be the best method when payoffs from vanilla option and barrier options are highly correlated. It is the case when pricing put@100 with up-and-out barrier 115. Option expires in the money when asset prices are low, while reaching the barrier happens when prices are high.
Hence in most cases if option ended in the money, then the barrier was not hit, and if the barrier was hit, then option would expire worthless anyway. Thus payoff of barrier and vanilla options are highly correleated.

In the case of put@100 with down-and-in barrier 70, barrier is set very low; hitting it happens seldom, thus often option expires worthless even if analogous vanilla option ends in the money. In consequence correlation between payoffs of the barrier and the vanilla option becomes low, and in this case AV method gives slightly better accuracy. 

At the end of this section, it is worth to mention, that there exist analitical formulas for prices of European barrier options, see \cite{wilmott}, chapter 23.

\begin{figure}[!h]
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/chart3dCallUaO.png}
\caption{Value of an European option call option with up-and-out barrier as a function of strike and barrier values.}
\label{fig:barrier3d}
\end{figure}

\section{Multiasset instruments}
\label{sec:multi-asset}
Valuation of derivatives whose payoff depends on many assets does not differ much from one dimensional case. We only have to remember to include correlation between the assets. Let
\[ \Sigma = \left( \varrho_{ij} \right)_{i,j=1}^d \]
be the matrix describing correlation between risky assets (recall that by that we understand the correlation between Wiener processes appearing in assets dynymics). Equation (\ref{eq:priceChange}) holds for every asset, i.e.
\begin{equation}
 \label{eq:priceChangeMulti}
  S^{(i)}_{t + {\Delta} t} = S^{(i)}_t \exp\left\{ (r - \frac{1}{2}\sigma_i^2)\Delta t + \sigma_i \sqrt{\Delta t} Z_i \right\}\ \ (i = 1,2,\ldots,d),
\end{equation}
where each $Z_i$ is standard normal. However, we have to take into account correlation between variables $Z_i$. To be precise $Z \sim \mathcal{N}(0, \Sigma)$.

Equation (\ref{eq:priceChangeMulti}) is the key to genarating multiasset scenarios. Its usage is shown in Algorithm \ref{alg:multi-tr}, which creates two antithetic scenarios of market evolution. Figure \ref{fig:corrPaths} illustrates trajectories of prices of correlated assets.

\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{MultiTrajectory}{$S_0$, $\sigma$, $r$, $\Sigma$, $T$, $K$}
  
  \Comment{{\color{comment} $S_0$ and $\sigma$ are now arrays, for example $\sigma[3]$ is the volatility of the third asset}}
  \State $S \gets$ two dimensional array \Comment{{\color{comment} S[i,k] is the price of i-th asset at k-th time point}}
  \State $S^\star \gets$ two dimensional array \Comment{{\color{comment} antithetic scenario}}
  \State $L \gets$ Cholesky decomposition of $\Sigma$ \Comment{{\color{comment} $\Sigma = LL'$}}
  \For{$i=1$ {\bf to} $d$}
    \State $S[i,0] \gets S_0[i]$
    \State $S^\star[i,0] \gets S_0[i]$
  \EndFor
  \State $dt \gets T/K$
  \For{$k=1$ {\bf to} $K$}
    \State $Z \gets$ array of $d$ independent standard normal variates
    \State $Z \gets LZ$ \Comment{{\color{comment} now $Z$ is a sample from $\mathcal{N}(0, \Sigma)$ distribution}}
    \For{$i=1$ {\bf to} $d$}
      \State $S[i, k] \gets S[i, k-1] \cdot \exp\left\{ (r - \frac{1}{2}\sigma[i]^2) dt + \sigma[i] \sqrt{dt} Z[i] \right\}$
      \State $S^\star[i, k] \gets S^\star[i, k-1] \cdot \exp\left\{ (r - \frac{1}{2}\sigma[i]^2) dt - \sigma[i] \sqrt{dt} Z[i] \right\}$
    \EndFor
  \EndFor
  \State \Return $(S, S^\star)$
  \EndFunction
 \end{algorithmic}
 \caption{Generating multiasset trajectories.}
 \label{alg:multi-tr}
\end{algorithm}

\begin{figure}
\centering
 \includegraphics[scale=0.75]{images/PricingEuropean/correlatedPaths.pdf}
\caption{Price trajectories of correlated assets.Correlation between red and green equals 0.8, between red and blue -0.8, and between green and blue also -0.8.}
\label{fig:corrPaths}
\end{figure}

\begin{remark}
 If the payoff depends only on the assets values at the end of the path, then there is no need to generate whole trajectories. It is sufficient to generate asset prices only at the expiry, using equations
 \[ S^{(i)}_T = S^{(i)}_0 \exp\left\{ (r - \frac{1}{2}\sigma_i^2)T + \sigma_i \sqrt{T} Z_i \right\} \ \ (i = 1,2,\ldots,d),\]
  where  $Z \sim \mathcal{N}(0, \Sigma)$. We do not have to write a new algorithm to do that, we can use function 
   \Call{MultiTrajectory}{}
 with $K=1$.

\end{remark}

While having a method for scenario generation, valuation of the multiasset options is pretty straightforward. For example we write a procedure for pricing basket put options using AV method. The basket is described by an array $\eta$, where $\eta[i]$ means how many units of asset $i$-th asset are contained in a basket.

\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{PriceBasketPutAV}{$n$, $S_0$, $\sigma$, $r$, $\Sigma$, $T$, $\eta$, $E$}
  \State  $sum \gets sum\_sq \gets 0$
  \For{$j=1$ {\bf to} $n$}
    \State $(S, S^\star) \gets$ \Call{MultiTrajectory}{$S_0$, $\sigma$, $r$, $\Sigma$, $T$, $1$}
    \State $H \gets \frac{1}{2}\exp\{-rT\} ($ \Call{BasketPutPayoff}{$S$, $\eta$, $E$, $1$} +\\ 
    \hspace{132pt} \Call{BasketPutPayoff}{$S^\star$, $\eta$, $E$, $1$} $)$
  \EndFor
  \State $var \gets (sum\_sq - sum \cdot sum/n) / (n-1)$
  \State $se \gets \sqrt{var / n}$
  \State $price \gets sum / n$
  \State \Return $(price, var, se)$
  \EndFunction
  \\
  \Function{BasketPutPayoff}{$S$, $\eta$, $E$, $K$}
    \State sum $\gets 0$
    \For{$i=1$ {\bf to} $d$}
      \State sum $\gets$ sum + $\eta[i]\cdot S[i, K]$
    \EndFor
    \State \Return $\max(E - sum, 0)$
  \EndFunction
 \end{algorithmic}
 \caption{Pricing basket put option.}
 \label{alg:priceBasketPutAV}
\end{algorithm}


In Algorithm \ref{alg:priceBasketPutAV} we called function \Call{MultiTrajectory}{} with $K=1$, because payoff of the basket option does not depend on the history. However, modifications of options and their payoffs are only bounded by investors imagination (and by some integrability assumptions, but it is hard bo believe that investors can invent a claim which would not be sufficiently integrable).
It should be clear how to modify Algorithm \ref{alg:priceBasketPutAV} to price options with any arbitrary payoff, even path-dependent. This is the main adventage of Monte Carlo methods in option pricing -- flexibility, which can not be provided by finite diffrence or binomial trees.

We used described technique to price basket vanilla call option. We took following parameters:
\begin{equation}
\label{eq:EuBasketParams}
 \begin{split}
  d &= 3,\ S_0 = (10, 50, 100)\\
  r &= 0.05,\ \sigma = (0.4, 0.2, 0.3),\\ 
  \Sigma &= \left( \begin{array}{rrr}
            1 & 0.8 & -0.8\\
            0.8 & 1 & -0.8\\
            -0.8 & -0.8 & 1
           \end{array} \right)\\
  E &= 90,\ \eta = (10, -2, 1),\ T=1
 \end{split}
\end{equation}
Such contract gives its owner right to change at expiration date 2 shares of the second asset and amount of money $E$ for 10 shares of the first asset and one of the third. The results are gathered in Table \ref{tab:EuBasket} and Figure \ref{fig:EuBasket}. In CV method value of the basket at the expiry was used as the control variate. From section \ref{sec:risk-neutral} we know its expectation: $\Em[\eta \cdot S_T] = \eta \cdot S_0$. 
CV method gave the most accurate prices.

\begin{table}
\centering
 \caption{Results of pricing basket option described in equations (\ref{eq:EuBasketParams}). }
 \label{tab:EuBasket}
\begin{tabular} {|r |c |c |c |c |c |c |}  
 \hline 
  & \multicolumn{2}{|c|}{ CMC } & \multicolumn{2}{|c|}{ AV } & \multicolumn{2}{|c|}{ CV } \\
  n & \multicolumn{1}{c}{ $\CMCa[H, 2n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\AVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } & \multicolumn{1}{c}{ $\CVa[H, n]$ } & \multicolumn{1}{c|}{ s.e. } \\ \hline \hline 
1000   & 18.91 & 0.507 & 19.90 & 0.444 & 19.85 & 0.241 \\ \hline 
10000  & 19.66 & 0.165 & 19.84 & 0.143 & 19.73 & 0.077 \\ \hline 
100000 & 19.65 & 0.052 & 19.68 & 0.045 & 19.70 & 0.024 \\ \hline 
\end{tabular}
\end{table}  
\begin{figure}
\centering
 \includegraphics[scale=0.5]{images/PricingEuropean/boxBasket.pdf}
 \includegraphics[scale=0.5]{images/PricingEuropean/convergenceBasket.pdf}
\caption{Accuracy of pricing basket option described in equations (\ref{eq:EuBasketParams}).}
\label{fig:EuBasket}
\end{figure}

\chapter[{Pricing American options using Least Squares Monte Carlo}]{Pricing American options using \\Least Squares Monte Carlo}
\label{chapter:pricingAmerican}
Part \Roman{chapter} describes American-style derivatives. The diffrence between them and discussed previously European-style contracts is that American feature allows the owner of the derivative to exercise it at \emph{any time} up to the expiration date. This additional attribute makes the instrument much harder to analyze and more advanced theory is necessary to value and hedge.
Due to the practical nature of this thesis we will not get deep into details. Nevertheless, we will provide mathematical tools necessary for pricing American contingent claims, advising the reader to find proofs in more specialist literature. 

It turns out that Monte Carlo method from previous part can not be carried over directly to price American contracts. However, Least Squares Monte Carlo method uses a clever trick, so the simulations still can be involved. 

\section{American contingent claims}
Definition of the American contingent claim is analogous to its European counterpart, with one diffrence that it is not a random variable, but a \emph{process}.
\begin{mydef}
 \label{def:cc_am}
 An \textbf{American contingent claim} is a non-negative adapted process $C = (C_t)_{t=0}^T$ on the filtered probability space $(\Omega, (\mathcal{F}_t)_{t=0}^T, \P)$.
By a \textbf{derivative} of the underlying assets $\Sa$ since now we will understand such American contingent claim $C$ which is adapted also to the filtration generated by $\Sa$ (which in general may be smaller than $\mathcal{F}$).
\end{mydef}
Value $C_t$ has the meaning of the payoff obtained from the claim if it is exercised at time $t$. The definitions from section \ref{sec:ECC} carry over directly to their American counterparts, for example American call and put options on $i$\textsuperscript{th} asset are defined as derivatives with the payoffs
\begin{equation*}
 \begin{split}
  C^{\text{call}}_t &= (S^{(i)}_t - E)_+, \\
  C^{\text{put}}_t &= (E - S^{(i)}_t)_+,
 \end{split}
\end{equation*}
where $E$ is the strike price.
\begin{remark}
 In fact European contracts are just a particular case of the American contracts. An European claim $\tilde{C}$ may be regarded as an American claim $C = (C_t)_{t=0}^T$ with payoff
 \[ C_t = \begin{cases}
         \tilde{C},\ \ \ \ t = T \\
         0,\ \ \ \ \ t < T.
        \end{cases}
        \]
\end{remark}

As usually, it is conveniet to quote payoff values in terms of time 0.
\begin{mydef}
 The discounted value of the American contingent claim $C$ is a process $H = (H_t)_{t=0}^T$ given by
 \begin{equation*}
  H_t = \frac{C_t}{S^{(0)}_t}.
 \end{equation*}
 The process $H$ is called an \textbf{American discounted claim}.
\end{mydef}

The exercise time is entirely up to the buyer. He will decide when to get his payoff dynamically, watching the market evolution. However, at the very beginning he may plan under which conditions the option will be exercised.
\begin{mydef}
 An \textbf{exercise strategy} for an American contingent claim $C$ is a stopping time $\tau$ taking values in $[0,T]$. The payoff resulting from following the strategy $\tau$ is defined for any $\omega \in \Omega$ as
 \[ C_{\tau}(\omega) = C_{\tau(\omega)}(\omega).\]
 The set of exercise strategies is denoted by $\mathcal{T}$. 
\end{mydef}
An exercise strategy may be seen as an oracle telling at any time $t$ whether or not the option should be exercised now, basing only on the informations available up to time $t$. Note that the definition of an exercise strategy is limited to these stopping times which do not take value $\infty$. That is so, because the option will be exercised always, however, if the owner postpones the exercise to the expiration date, then the payoff may equal 0.

Of course the option buyer looks for the best exercise strategy. Thus, we need to write precisely what we mean by that.
\begin{mydef}
 An exercise strategy $\hat{\tau}$ is called optimal (with respect to $\Pm$) if and only if
\begin{equation}
\label{eq:AM_optStrategy}
\Em[H_{\hat{\tau}}] = \sup\limits_{\tau \in T} \Em[H_{\tau}]. 
\end{equation}
\end{mydef}

\begin{remark}
 The optimal exercise strategy does not always exist. However, for each $\epsilon > 0$ there exist such stopping time $\tau_\epsilon$ that
 \[ \Em[H_{\tau_\epsilon}] \geq \sup\limits_{\tau \in T} \Em[H_{\tau}] - \epsilon.\]
 Moreover, if the optimal exercise strategy exists it is not necessarly unique.
\end{remark}
As we can see the owner of the claim may choose such strategy that its expected value is arbitrarily close to the $\sup\limits_{\tau \in T} \Em[H_{\tau}]$. It suggests how the option price should be defined.
\begin{mydef}
 Price of the discounted American contingent claim $H$ is given by
\begin{equation}
\label{eq:AM_optPrice}
V_0 = \sup\limits_{\tau \in T} \Em[H_{\tau}]. 
\end{equation}
\end{mydef}
We also need to analyze how the option price changes over time.
\begin{mydef}
 \label{def:valueProcess}
 Let  $\mathcal{T}_t = \{ \tau \in \mathcal{T}:\ \tau \geq t \}$. The discounted \textbf{price process} (or \textbf{value process}) of the  discounted American contingent claim $H$ is given by
\begin{equation}
\label{eq:AM_valueProcess}
V_t = \esssup\limits_{\tau \in  \mathcal{T}_t} \Em[H_{\tau} | \mathcal{F}_t]. 
\end{equation}
 If there exists the stopping time realizing this essential supremum, then we call it optimal in $\mathcal{T}_t$ and denote it by $\hat{\tau}_t$.
\end{mydef}

\begin{remark}
 The reader may ask how do we know that in the definitions above the martingale measure should be used. It may be even confusing that we \emph{define} what is the value of the option instead of \emph{proving} that some formula gives the value. Remember that the goal of the theory is to answer what should be the price of the option. The proposed definition is good in the sense that the extended market model $(S^{(0)}, S^{(1)}, \ldots, S^{(d)}, V)$ is still arbitrage free -- proof for discrete time is in \cite{follmer}.
\end{remark}


\begin{prop}
 At any time $t$ value of the American contingent claim is not less then value of its European counterpart.
\end{prop}
\begin{proof}
 Following the exercise strategy $\tau_t \equiv T$ will always result in the same payoff from the American contract as from the European. The price of the American claim must be greater or equal, because the supremum is taken over all stopping times in $\mathcal{T}_t$.
\end{proof}

\begin{prop}
 Assume that the interest rate $r$ is nonnegative. The exercise strategy $\tau \equiv T$ is optimal for an American call option on non-dividend-paying stock.
\end{prop}
\begin{proof}
 For the brevity let $S$ be the price process of the underlying asset (not the vector process of all the risky assets). From the previous Corollary we have
 \[V_t \geq \Em[e^{-r(T-t)}(S_T - E)_+ | \mathcal{F}_t].\] Moreover,
 \[\Em[(S_T - E)_+ | \mathcal{F}_t] \geq \Em[S_T - E | \mathcal{F}_t],\]
 because the left hand side expectation zeroes negative values of $S_T - E$. Hence,
 \[ V_t \geq e^{-r(T-t)}\Em[S_T - E | \mathcal{F}_t] = S_t - e^{-r(T-t)}E > S_t - E.\]
 The obtained inequality tells us that value of the option is always higher than the immediate exercise, thus it is more profitable to sell the option rather than exercise it.
\end{proof}
The above proposition simply says that \textbf{it is never worth to exercise the American call option before the expiration date} (if the stock does not pay any dividend and interest rate is nonnegative). A similar proof shows that for negative interest rate $r$ American put options should be exercised only at the maturity, however, this a very rare situation.

Unfortunately the above definition of the value process is not constructive. It does not tell us how to find the optimal exercise strategy nor how to compute options value. We need to involve a little more theory. Following two definitions are formulated for general measure $\Q$. 

\begin{mydef}
 Let $X$ and $Y$ be two processes on the same probability space\\ $(\Omega, (\mathcal{F}_t)_{t=0}^T, \Q)$. We say that $X$ \textbf{dominates} $Y$ if $ X_t \geq Y_t$ $\Q$-a.s. for all $t \geq 0$.
\end{mydef}
 
\begin{mydef}
 Let $Y$ be the process such that for all $0 \leq t \leq T$, $\E^{\Q}[Y_t] < \infty$. Its \textbf{Snell envelope} $U^{\Q}$ is defined as the smallest supermartingale dominating $Y$. In the other words $U^{\Q}$ is a supermartingale dominating $Y$ and if $\tilde{U}$ is another supermartingale dominating $Y$, then $U_t \leq \tilde{U}_t$, $\Q$-a.s. for all $t \geq 0$.
\end{mydef}
It is proven that Snell envelope exists for a vast class of processes. Its usefulness in the option pricing follows from the next theorem.
\begin{thm}
 \label{thm:snell}
 If $\sup\limits_{\tau \in T} \Em|H_{\tau}| < \infty$, then the value process $V$ is the Snell envelope of the claim $H$ with respect to the measure $\Pm$. Moreover, if there exists an optimal stopping time (not necessarily unique), then the smallest one is given by
 \begin{equation}
  \label{eq:optStop}
  \hat{\tau}_t = \inf\{ s \geq t:\ V_s = H_s \}.
 \end{equation}
\end{thm}
{\LARGE \color{red} TODO: referencja do dowodu}
Theorem \ref{thm:snell} not only states that Snell envelope $U^{\Pm}$ of the claim $H$ coincides with its value $V$. It also gives us a recipe for the optimal stopping: \textbf{exercise the option when its value equals the payoff possible to obtain immediately}.

Presented theory may look incomprehensible at the first glance. In order to get some intuition let us explain the above concepts in discrete time. Let us divide the time to expiration on the $K$ intervals separated by points $0 = t_0 < t_1 < \ldots < t_K = T$. In order to reduce the number of indices we will use following notation in discrete time:
\begin{align*}
 V_k &:= V_{t_k} \\
 H_k &:= H_{t_k} \\
 \mathcal{F}_k &:= \mathcal{F}_{t_k}
\end{align*}
Also the stopping times $\tau$ will now take values in $\{0, 1, \ldots, K\}$ (and $\tau_k$ will denote such stopping time, that $\tau_k \geq k$ a.s.).
Since $k$ is usually associated with natural numbers and $t$ with real numbers, we hope that when reader see $V_k$ he will remember that it is the value at $k$\textsuperscript{th} time point (i.e. at time $t_k$), not at time $k$.

It turns out that in discrete time equation (\ref{eq:AM_valueProcess}) can be written in more friendly form.
\begin{prop}
\label{prop:AM_valueProcessDisc}
 In the discrete time the value process of the American contingent claim is given by recursion
 \begin{equation}
  \label{eq:AM_valueProcessDisc}
  V_{k} = \begin{cases}
             H_T &\text{if } k = K,\\
             \max\Bigl(H_{k}, \Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr] \Bigl)\ \ \ \ &\text{otherwise.}
            \end{cases}
 \end{equation}
 Moreover, it is optimal to stop at $k$\textsuperscript{th} time point if and only if $V_{k} = H_{k}$. 
\end{prop}
\begin{proof}
Let us think about the value of the claim at $k$\textsuperscript{th} time point. From the definition, $V_{k}$ is the expected value resulting from following optimal strategy $\hat{\tau}_{k}$. However, at this point only one of these is possible: it is optimal to stop or not. If it is not optimal, then $\hat{\tau}_{k} = \hat{\tau}_{k+1}$ must hold. At $(k+1)$\textsuperscript{th} time point claim's value resulting from following $\hat{\tau}_{k+1}$ equals $V_{k+1}$, however, at $k$\textsuperscript{th} time point it equals (from the definition) 
\[ V_{k} = \Em[H_{\hat{\tau}_{k}} | \mathcal{F}_{k}] = \Em[H_{\hat{\tau}_{k+1}} | \mathcal{F}_{k}] = \Em\bigl[[H_{\hat{\tau}_{k+1}} | \mathcal{F}_{k+1}] \bigl|\bigr. \mathcal{F}_{k} \bigr] = \Em[V_{k+1} | \mathcal{F}_{k}].\]
On the other hand, if it is optimal to stop at time then the price equals immediate payoff, that is $V_{k} = H_{k}$. Hence, at time $k$ we have to compare $H_{k}$ and $\Em[V_{k+1} | \mathcal{F}_{k}]$, and we stop if and only if the former is greater.
\end{proof}
Proposition 6.11 in \cite{follmer} states that process defined via (\ref{eq:AM_valueProcessDisc}) is the Snell envelope of $H$ (in the discrete sense).

Obvious conclusion from the Proposition \ref{prop:AM_valueProcessDisc} gives us a useful formula for the optimal stopping.
\begin{coro}
 \label{coro:AM_optStopDisc}
 The optimal exercise strategies at time 0, and at $k$\textsuperscript{th} time point are given by:
 \begin{equation}
  \label{eq:AM_optStopDisc}
  \begin{split}
   \hat{\tau} &= t_n,\ \ \ \text{where } n = \min\{m \geq 0:\ V_m = H_m \}.\\
   \hat{\tau}_{k} &= t_n,\ \ \ \text{where } n = \min\{m \geq k:\ V_m = H_m \}.\\
  \end{split}
 \end{equation}
\end{coro}
\begin{remark}
 Since finding the optimal exercise strategy in discrete time involves taking minimum, not infinum, hence it always exist. However, it is not necessarily unique.
\end{remark}

\begin{example}
 Figure \ref{fig:binTree} illustrates terms discussed above. It shows a binomial tree (readers not familiar with binomial trees may be interested in reading about CRR model) used to price an American put option. The red color indicates nodes where $V_{k} = H_{k}$, i.e. the immediate payoff exceeds the expected payoffs in the future. Hence, Corollary \ref{coro:AM_optStopDisc} states that following procedure is an optimal exercise strategy: exercise the option when you step in the red node.
 
 It is also remarkable that decision whether the option should be exercised depends not only on the price of the underlying, but also on time. Note that we should exercise the option for asset price 91 in the time step one before last, but not in the previous time steps.
\end{example}

\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.4]{images/LSM/binomialTree.png}
\caption{The binomial tree used to price American put@100. In nodes marked red it is optimal to exercise the option. Blue indicates those nodes where exercise should be postponed. }
\label{fig:binTree}
\end{figure}

\section{Least Squares Monte Carlo}
After wading through the theory we want to use it in practice. We showed on the example of the European options that Monte Carlo methods are very flexible and can be used to price exotic options with very sophisticated payoffs (at least when they are European-styled). Therefore we would like to adjust them for pricing American claims. 

\subsection{Difficulties with pricing American options}

Let us think how pricing American options using Monte Carlo method would look like. Of course, as for European options we need to simulate some paths and for each path we have to determine what payoff we would obtain. Since the option may be exercised at any time, it is not sufficient to check the payoff at the expiration date. We have to follow the path and at each time step compare the immediate payoff with the expectation of the future payoff.

Consider an American put option. Let us say that we are already at time $k$, and we need to compute $V_{k}$. From (\ref{eq:AM_valueProcessDisc}) we know that it is the greater of values $H_{k}$ and $\Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr]$. Value $H_{k}$ is obtained instantaneously, but how can we get $\Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr]$? Note that it is the price of a similar option, with a little shorter time to expiration. We can compute it by calling the procedure again, with the beginning asset price $S_{k}$. Algorithm \ref{alg:naiveProcedure} presents a little modified version of this approach.

\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{PriceAmericanPut}{$n$, $k$, $K$, $S_0$, $\sigma$, $r$, $T$, $E$ }
    \If{$k=K$}
      \State \Return $e^{-rT} \max(0, E - S_0)$
    \EndIf
    \State $dt \gets T/K$
    \State $t \gets k\cdot dt$
    \State $S \gets$ simulate $n$ asset prices in the next step 
    \State $H \gets$ $n$-element array
    \For{$i = 1$ {\bf to} $n$} 
       \State $H[i] \gets$ \Call{PriceAmericanPut}{$n$, $k+1$, $K$, $S[i]$, $\sigma$, $r$, $T$, $E$ }
    \EndFor 
    \State $av \gets$ average$(H[i])$
    \State \Return max($e^{-rt} \max(0, E - S_0),\ av$)
  \EndFunction 
 \end{algorithmic}
 \caption{Pricing American options by ``Monte Carlo on Monte Carlo''. This is how pricing \emph{cannot} be done.}
 \label{alg:naiveProcedure}
\end{algorithm}

Unfortunately, this is a very ineffective procedure. Computing $\Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr]$ involves generating new paths starting at time point $k$. We perform ``Monte Carlo on Monte Carlo''. Since we have to do it at every time step, complexity of such algorithm becomes exponential. These difficulties are illustrated on Figure \ref{fig:MC_difficulties}.

\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.5]{images/LSM/LSMidea1.pdf}
\caption{The illustration of the difficulties occuring with attempts to involve Monte Carlo method in pricing American claims. }
\label{fig:MC_difficulties}
\end{figure}

As we can see Monte Carlo methods used to price European options cannot be carried over directly to price American options.

\subsection{LSM idea}
We will present one of methods allowing to circumvent the difficulties described above. It is called \textbf{Least Squares Monte Carlo}, or \textbf{Longstaff-Schwartz method}, after its discoverers Francis Longstaff and Eduardo Schwartz, abbreviated \textbf{LSM}.

Consider again the problem of pricing American options with the Monte Carlo method. At the beginning we simulate thousands of trajectories. At every time point on every path we need to obtain an expectation of the future payoff. Assume that we follow one path and we are already at time $t_k$. In order to obtain option's value at this point, we have to compute $\Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr]$. Previously we came up with an idea to generate new trajectories starting from that point.
Note that we have exactly the same problem on every path. Look at the Figure \ref{fig:LSMidea}. There are several points marked at line $x = t_k$, they are asset prices on simulated trajectories, at time $t_k$. While using previous method we had to release thousands of ``subpaths'' from each point, but we cannot afford this. However, these points are not lying far from each other. The main idea of the LSM is that instead of generating new ``subpaths'' starting at time $t_k$, we can use the remainders of the ``original'' paths.

\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.5]{images/LSM/LSMidea2.pdf}
\caption{The illustration of the idea allowing to bypass the difficulties with Monte Carlo described in previous section.}
\label{fig:LSMidea}
\end{figure}

As in Part on pricing European options, $S_{i,k}$ will denote the price of the underlying at time $t_k$, on $i$\textsuperscript{th} simulated path (similarly for $V_{i,k}$ and $H_{i,k}$). Moreover, let $D_{i,k}$ be the payoff (discounted to time 0) obtained on $i$\textsuperscript{th} path conditional on not exercising the option up to time $t_k$ (inclusively).
\begin{remark}
  Some values appearing in the discussion have an ambiguous meaning. The reader must aware of both interpretations.
 \begin{itemize}
  \item It is clear that $S_{k}$ is a random variable, but $S_{i,k}$ may be seen in two ways. After simulations $S_{i,k}$ is a real value, a concrete realization of $S_{k}$. However, prior to the simulations $S_{i,k}$ is also a random variable with the same distribution as $S_k$. The same applies to  $V_k$, $H_k$, $D_k$, etc.
  \item Let $Y$ be any random variable measurable with respect to $\mathcal{F}_k$. From the perspective of time 0, $Y$ is unknown and depends on the market evolution up to time $t_k$. However, from the perspective of time $t_k$ we already know the history up to time $t_k$, hence $Y$ is already a concrete real value.
 \end{itemize}
\end{remark}

If we a priori knew what is the optimal exercise strategy, then $D_{k} = (H_{\hat{\tau}_{k+1}} | \mathcal{F}_{k})$ would hold. Furthermore,
\begin{equation}
 \label{eq:LSM_futurePayoff}
 \Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr] = \Em\bigl[ \Em[H_{\hat{\tau}_{k+1}} | \mathcal{F}_{k+1}] \bpipe \mathcal{F}_{k} \bigr] = \Em\bigl[ H_{\hat{\tau}_{k+1}} | \mathcal{F}_k \bigr] = \Em[ D_{k} ]. 
\end{equation}
In the LSM equation (\ref{eq:LSM_futurePayoff}) is still used, although we use a strategy which only approximates the optimal stopping. Such strategy is built dynamically. At time point $K$ values $V_{i,K}$ and $D_{i,K-1}$ are obtained instantaneously, we have
\[ D_{i,K-1} := H_{i,K},\ \ \ \ V_{i,K} := H_{i,K}.\]
At time $t_{K-1}$ situation is not that clear. For each path we have to estimate value $\Em\bigl[ V_{i,K} | \mathcal{F}_{K-1} \bigr]$, which we believe is close to $\Em[D_{i,K-1}]$. If we knew that value we could assign to $V_{i,K-1}$ maximum of $H_{i,K-1}$ and $\Em\bigl[ V_{i,K} | \mathcal{F}_{K-1} \bigr]$. If the former value is greater, then we decide to exercise the option at time $t_{k-1}$, and $D_{i,K-2} := H_{i,K-1}$. Otherwise we postpone the exercise, hence $D_{i,K-2} := D_{i,K-1}$. In general, for $0 < k < K$ we do
\begin{align*}
 V_{i,k} &:= \max(H_{i,k}, \Em[D_{i,k}]) \\
 D_{i,k-1} &:= \begin{cases}
                 D_{i,k},\ \ \ \ \text{if } H_{i,k} < \Em[D_{i,k}], \\
                 H_{i,k},\ \ \ \ \text{otherwise.}
               \end{cases}
\end{align*}
\begin{remark}
 Someone might argue that in above assignments instead of $\Em[D_{i,k}]$ we should take $D_{i,k}$, because after simulations this value is already known and an option should be exercised if and only if $D_{i,k} < H_{i,k}$. However, we have to take the point of view of the investor who at time $t_k$ does not know the future and must rely on the expectations. 
\end{remark}

So far we did not explain how to calculate $\Em[D_{i,k}]$. Here the main idea of the LSM comes in. We cannot create thousands of ``subpaths'' starting from $S_{i,k}$ to obtain thousands of realizations of $D_{i,k}$ and assign to $\Em[D_{i,k}]$ their average, but we \emph{already have} single realizations of $D_{1,k}, D_{2,k},\ldots, D_{n,k}$. In the other words, we have mapping
\begin{equation}
 \label{eq:AM_mapping}
  S_{i,k} \mapsto D_{i,k}.
\end{equation}
Similarly as in assumption BS7. from section \ref{sec:blackScholes} we assume that
\begin{equation*}
 \Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr] = F(S_{k}),
\end{equation*}
for some continuous function $F$. Stone-Weierstra\ss{} theorem states that $F$ can be approximated as closely as desired by a polynomial of a sufficiently large degree $m$. Hence
\begin{equation*}
 \Em[D_{k}] \approx \Em\bigl[ V_{k+1} | \mathcal{F}_{k} \bigr] \approx P(S_{k}) = a_m S_{k}^m + \ldots + a_1 S_{k} + a_0.
\end{equation*}
The method of least squares can be used to find coefficients $a_m, a_{m-1},\ldots,a_0$ fitting the mapping (\ref{eq:AM_mapping}) the best.

\subsection{Regression}
It turned out that regression is an important step in LSM. We explained that the estimated future payoff may be represented by a polynomial function of $S_k$ whose coefficients may be obtained from least squares method. We will briefly describe the general method of finding the polynomial of degree $m$, best fitting given set of points $(x_i, y_i)$, $i=1,2,...n$.
\[ \begin{cases}
    a_0 + a_1 x_1 + \ldots + a_m x_1^m &= y_1 \\
    a_0 + a_1 x_2 + \ldots + a_m x_1^m &= y_2 \\
    \vdots & \\
    a_0 + a_1 x_n + \ldots + a_m x_n^m &= y_n
   \end{cases}
\]
We are minimizing functional
\[ \psi(a_0,a_1,\ldots,a_m) = \sum\limits_{i=1}^n \left( y_i - \sum\limits_{j=0}^m a_jx_i^j \right)^2. \]
From basic analysis we know that $\psi$ may have minimum only in those points where partial derivative with respect to each variable equals 0, hence we are looking for such $a_0,a_1,\ldots,a_m$, that for any $k \in \{0,1\ldots,m\}$
\[ 0 = \frac{\partial \psi}{\partial a_k} = 2  \sum\limits_{i=1}^n \bigl( y_i - \sum\limits_{j=0}^m a_jx_i^j \bigr) \bigl( -x_i^k \bigr). \]
Simple calculation gives
\begin{equation}
 \label{eq:regression1}
 \sum\limits_{j=0}^m \left( a_j \sum\limits_{i=1}^n  x_i^{j+k} \right) = \sum\limits_{i=1}^n y_i x_i^k. 
\end{equation}
For any $k \in \{0,1\ldots,m\}$ and $l \in \{0,1\ldots,2m\}$ let
\[ s_{l} := \sum\limits_{i=1}^n  x_i^l \text{\ \ \ and \ \ } t_k := \sum\limits_{i=1}^n y_i x_i^k .\]
From (\ref{eq:regression1}) we obtain a system of linear equations
\begin{equation}
 \label{eq:regression2}
 \begin{cases}
  s_0 a_0 + s_1 a_1 + \ldots + s_m a_m &= t_0 \\
  s_1 a_0 + s_2 a_1 + \ldots + s_{m+1} a_m &= t_1 \\
    \vdots & \\
  s_m a_0 + s_{m+1} a_1 + \ldots + s_{2m} a_m &= t_m
  \end{cases}
\end{equation}
This system has $m+1$ variables and $m+1$ equations. It can be solved with the Gauss elimination method.
\begin{prop}
 The algorithm of approximating set of points $\{ (x_i,y_i) \}_{i=1}^n$ by a polynomial of degree $m$, which was described above, has the computational complexity \mbox{$\mathcal{O}(nm + m^3)$}.
\end{prop}
\begin{proof}
 For fixed $k$ computing $s_k$ or $t_k$ involves summation of $n$ values, and there is $\mathcal{O}(m)$ of $k$'s, hence the first part of the algorithm  has complexity $\mathcal{O}(nm)$. After that we have to solve the system of linear equations what can be done using the Gauss elimination method in time $\mathcal{O}(m^3)$.
\end{proof}


\subsection{Step by step example}
Description of the LSM may look a little bit scary, however, in fact the idea is very simple. We will explain it once again, this time on an example.

Suppose we are pricing an American put@100. We take parameters
\begin{equation*}
\begin{split}
 S_0 = 98,&\ \sigma=0.35,\ r = 6.06\%,\\
 E = 100,&\ T = 1,\ K = 3. 
\end{split}
\end{equation*}
Under those parameters $t_0 = 0,\ t_1 = \frac{1}{3},\ t_2 = \frac{2}{3},\ t_3 = 1,\ e^{-\frac{1}{3}r} = 0.98$.
\bigskip

\noindent \textbf{1. The algorithm starts by simulating $n$ trajectories of the asset price.} The asset dynamics under the risk-neutral measure must be used. For our example we take $n=10$. The simulated paths are shown in Table \ref{tab:LSM_paths}. Table \ref{tab:LSM_cashflows_t3} presents what would be the payoff from the option if the owner did not exercise it before the expiration date. It corresponds to the values $D_{i,K-1} = D_{i,2}$ described previously ($D_{i,k}$ are discounted to time 0, but in tables we omit discounting for readability, instead we provide time of the payoff, hence everybody may calculate discounted value on his own).
\begin{table}[!ht]
 \parbox{.45\linewidth} {
   \centering
   \caption{Paths simulated under the risk-neutral measure.}
   \label{tab:LSM_paths}
   \begin{tabular} {||c |c |c |c |c ||}  
    \hline 
    i\textbackslash k & 0   &  1  &  2  &  3  \\ \hline \hline
    1 & 98 & 108 & 102 & 112 \\ \hline 
    2 & 98 & 98 & 95 & 105 \\ \hline 
    3 & 98 & 102 & 97 & 93 \\ \hline 
    4 & 98 & 105 & 98 & 106 \\ \hline 
    5 & 98 & 92 & 102 & 98 \\ \hline 
    6 & 98 & 107 & 103 & 111 \\ \hline 
    7 & 98 & 108 & 113 & 118 \\ \hline 
    8 & 98 & 96 & 99 & 109 \\ \hline 
    9 & 98 & 107 & 98 & 96 \\ \hline 
    10 & 98 & 97 & 103 & 97 \\ \hline 
   \end{tabular} 
 }
 \qquad 
 \parbox{.45\linewidth} {
  \centering
  \caption{Cash flows obtained conditional on not exercising the option before the maturity.}
  \label{tab:LSM_cashflows_t3}
  \begin{tabular}{|| c | c | c ||}
    \hline 
    i  & time  &  payoff \\ \hline \hline
    1  & 1     &      0 \\ \hline
    2  & 1     &      0 \\ \hline
    3  & 1     &      7 \\ \hline
    4  & 1     &      0 \\ \hline
    5  & 1     &      2 \\ \hline
    6  & 1     &      0 \\ \hline
    7  & 1     &      0 \\ \hline
    8  & 1     &      0 \\ \hline
    9  & 1     &      4 \\ \hline
    10  & 1     &      3 \\ \hline
  \end{tabular}
}
\end{table}

\FloatBarrier
\noindent \textbf{2. At time $t_2 = \frac{2}{3}$ the owner must decide whether or not to exercise the option.} Of course he has choice only in that paths where option is in the money. From Table \ref{tab:LSM_paths} we see that in our case at time $t_2$ option is in the money at paths number 2,3,4,8,9. To estimate future payoffs we will use payoffs obtained on these paths conditional on not exercising the option up to time $t_2$ (these values are gathered in Table \ref{tab:LSM_cashflows_t3}).

\begin{table}[!ht]
\parbox{.45\linewidth} {
  \centering
  \caption{Estimating future payoffs at time point 2.}
  \label{tab:LSM_regression_t2}
  \begin{tabular} {||c |c |c || c | c ||}  
  \hline 
    i & X   &  Y  & now   &  future\\ \hline \hline
    2 & 95 & $0\cdot 0.98$ & 5 & 0.33 \\ \hline
    3 & 97 & $7\cdot 0.98$ & 3 & 4.90  \\ \hline
    4 & 98 & $0\cdot 0.98$ & 2 & 3.27 \\ \hline
    8 & 99 & $0\cdot 0.98$ & 1 & -0.98 \\ \hline
    9 & 98 & $4\cdot 0.98$ & 2 & 3.27 \\ \hline
  \end{tabular}
}
\qquad
\parbox{.45\linewidth} {
  \centering
  \caption{Cash flows obtained conditional on not exercising the option before time point 2.}
  \label{tab:LSM_cashflows_t2}
  \begin{tabular}{||c|c|c||}
  \hline 
  i  & time  &  payoff \\ \hline \hline
  1  & 1     &      0 \\ \hline
  2  & 2/3   &      5 \\ \hline
  3  & 1     &      7 \\ \hline
  4  & 1     &      0 \\ \hline
  5  & 1     &      2 \\ \hline
  6  & 1     &      0 \\ \hline
  7  & 1     &      0 \\ \hline
  8  & 2/3   &      1 \\ \hline
  9  & 1     &      4 \\ \hline
  10  & 1     &      3 \\ \hline
  \end{tabular}
}
\end{table}
Look at Table \ref{tab:LSM_regression_t2}. Column X presents the asset price at time $t_2$ (only paths for which option is in the money at that time are taken into consideration). Column Y contains payoffs on that paths conditional on not exercising the option at or prior to time $t_2$, discounted to time $t_2$. The regression with a quadratic function leads to the following formula for the future estimated payoff:
\begin{equation}
 \label{eq:LSM_example1}
 Y = -1.31\cdot X^2 + 253.17\cdot X - 12257.87 
\end{equation}
Values in column ``now'' are the payoffs obtained from the immediate exercise and those in column ``future'' present the estimation of the future payoff calculated by using (\ref{eq:LSM_example1}). We decide to exercise the option on those paths where expectation of the future payoff is lower than immediate exercise. In our case these paths are 2 and 8. The update to the optimal stopping is shown on Table \ref{tab:LSM_cashflows_t2}.

\begin{remark}
 Here an inefficiency of the LSM may be seen: expected future payoff may be negative, what is of course impossible in the real life. Moreover, for asset price 95 expected future payoff is lower than for asset price 97 and 98, what also does not reflect the reality. The reason of that problem is a small number of paths for regression. In practice we use thousands on paths, hence the approximating polynomial gives better estimations.
\end{remark}

\noindent \textbf{3. At time $t_1 = \frac{1}{3}$ we proceed as in time $t_2$.}
Table \ref{tab:LSM_regression_t1} shows the data for regression. It is worth to mention that at time $t_1$ we still use realized cashflows, not for example option's prices calculated at previous step -- such approach would lead to an upward bias.
\begin{table}[!ht]
\parbox{.45\linewidth} {
  \centering
  \caption{Estimating future payoffs at time point 1.}
  \label{tab:LSM_regression_t1}
  \begin{tabular} {||c |c |c || c | c ||}  
  \hline 
    i & X   &  Y  & now   &  future\\ \hline \hline
    2 & 98 & $5\cdot 0.98$ & 2 & 5.0 \\ \hline
    5 & 92 & $2\cdot 0.98^2$ & 8 & 1.9  \\ \hline
    8 & 96 & $1\cdot 0.98$ & 4 & 1.1 \\ \hline
  10 & 97 & $3\cdot 0.98^2$ & 3 & 2.7 \\ \hline
  \end{tabular}
}
\qquad
\parbox{.45\linewidth} {
  \centering
  \caption{Cash flows obtained conditional on not exercising the option before time point 1.}
  \label{tab:LSM_cashflows_t1}
  \begin{tabular}{|| c | c | c ||}
  \hline 
  i  & time  &  payoff \\ \hline \hline
  1  & 1     &      0 \\ \hline
  2  & 2/3   &      5 \\ \hline
  3  & 1     &      7 \\ \hline
  4  & 1     &      0 \\ \hline
  5  & 1/3   &      8 \\ \hline
  6  & 1     &      0 \\ \hline
  7  & 1     &      0 \\ \hline
  8  & 1/3   &      4 \\ \hline
  9  & 1     &      4 \\ \hline
  10  & 1/3   &      3 \\ \hline
  \end{tabular}
}
\end{table}

This time quadratic function representing estimated future payoff has the form
\[ Y = 0.36\cdot X^2 - 67.32\cdot X + 3173.71. \]
We see that option should be exercised at paths 5,8,10, and we update properly the table of realized cashflows (Table \ref{tab:LSM_cashflows_t1}).

\noindent \textbf{4. At time 0 we have to perform final calculations to find options value.} Here we proceed different than at times $t_1$, $t_2$, because there is no data for regression. However, Table \ref{tab:LSM_cashflows_t1} already tells us what would be the future payoffs if the option was not exercised immediately. In order to obtain estimated future payoff at time 0, we take the average of the realized payoffs discounted to time 0. If the average is greater than immediate payoff, then this is the value of the option. Otherwise option should be exercised at time 0 and its value equals the immediate payoff.

In our example the average of realized cashflows equals 2.99. It is greater than value of immediate exercise, hence \textbf{the price of the option is 2.99}.

\FloatBarrier
\subsection{LSM algorithm}
\begin{algorithm}
 \begin{algorithmic}[1]
  \Function{LSM-Put}{$N$, $K$, $M$, $S_0$, $\sigma$, $r$, $T$, $E$ }
    \State $S \gets$ matrix $N \times (K+1)$ \Comment{{\color{comment} $S[i,k]$ will be asset price at $i$\textsuperscript{th} path at time $t_k$.}}
    \State $CF \gets$ matrix $N \times 2$ \Comment{{\color{comment} $CF[i,1]$ is the time of the realized cash flow at $i$\textsuperscript{th} path and $CF[i,2]$ is its value.}}
    \For{$i = 1$ {\bf to} $N$} \Comment{{\color{comment} Generating trajectories like in Algorithm \ref{alg:single-tr}}}
      \State $S[i,] \gets$ \Call{Trajectory}{$S_0$, $\sigma$, $r$, $T$, $K$ } \Comment{{\color{comment} but only positive path is taken.}}
      \State $CF[i,1] \gets$ vector of $N$ $T$'s \Comment{{\color{comment} Realized cash flows conditional on }}
      \State $CF[i,2] \gets$ $\max(0, E - S[i,K])$ \Comment{{\color{comment} not exercising before expiration. }}
    \EndFor
    \For{$k = K-1$ {\bf to} $1$} 
      \State $nrs \gets $ indices $i$ such that $E - S[i,k] > 0$
      \State $X \gets S[nrs, k]$
      \State $Y \gets \exp\bigl(-r\cdot(CF[nrs, 1]-t_k) \bigr)\cdot CF[nrs, 2]$
      \State $P \gets $ polynomial of degree $M$ resulting from regression $Y = P(X)$
      \For{$i = 1$ {\bf to} $N$}
	\State $now \gets \max(0, E - S[i,k])$
	\If{$now > 0$ and $now > P(S[i,k])$}
	  \State $CF[i,1] \gets t_k$ \Comment{{\color{comment} Immediate exercise gives higher payoff}}
	  \State $CF[i,2] \gets now$ \Comment{{\color{comment} than expected payoff in the future.}}
	\EndIf
      \EndFor
    \EndFor
    \State $sum \gets 0$
    \For{$i = 1$ {\bf to} $N$} 
      \State $sum \gets sum + \exp\bigl(-r\cdot(CF[i, 1]-t_k) \bigr)\cdot CF[i, 2]$
    \EndFor
    \State \Return $\max(E - S_0,\ sum/n)$
    \EndFunction 
 \end{algorithmic}
 \caption{Valuation of American put options using LSM.}
 \label{alg:LSM}
\end{algorithm}

\begin{prop}
 The computational complexity of the LSM equals $\mathcal{O}(KNM + KM^3)$, where $N$ is the number of simulated paths, $M$ is the degree of approximating polynomial, $K$ is the number of time steps.
\end{prop}

\section{Mathematical background of LSM}

\chapter{Application architecture}
An inherent component of the thesis is an application for pricing miscellaneous financial instruments. The application was written in Java and is taking advantage of the best object oriented paradigm practices and design patterns. This part describes architecture of the created financial library which is application's back end. The library is to some extent an implementation of algorithms presented in previous parts, however, they are generalized and adjusted to the object oriented language.

\section{Scenarios and trajectories}
The basis of Monte Carlo pricing is trajectory generation. Hence, we begin with a presentation of classes performing this task. Corresponding class diagram is presented in Figure \ref{fig:arch:traj}.

\begin{sidewaysfigure}
\centering
 \includegraphics[scale=0.75]{images/Architecture/trajectories.png}
\caption{Diagram presenting classes designated for scenario generation.}
\label{fig:arch:traj}
\end{sidewaysfigure}

Class \texttt{TimeSupport} is a simple auxiliary class allowing to switch between discrete and continous time. Let $T$ be the final time on a trajectory and $K$ be the natural number such that the trajectory is generated in points $0 = t_0 < t_1 < \ldots < t_K$, where $t_k = k \cdot \Delta T$ and $\Delta T = T / K$. Method \texttt{nrToTime} from class \texttt{TimeSupport} for given $k$ returns $t_k$. Method \texttt{timeToNr} is somewhat an opposite and for given $t$ returns natural number $k$ such that $t_k \leq t < t_{k+1}$. 

\texttt{Trajectory} is an interface for classes representing realization of price movements of one asset. Method \texttt{price} returns price of that asset at k\textsuperscript{th} time point. Interface provides also several auxiliary functions like \texttt{average} which returns average price of the option in time between given time points, or \texttt{cumMax} which returns asset's maximum price until given time point. These methods are useful for determining payoffs from instruments like asian, barrier or lookback options. Class \texttt{ConcreteTrajectory} is an implementation of the \texttt{Trajectory} interface.

\texttt{Scenario} is an interface for classes representing realization of whole market scenario. A scenario may be considered as a set of trajectories of all assets. Method \texttt{getNumberOfAssets} answers how many assets are in the model. We can obtain trajectory of chosen asset by call to \texttt{getTrajectory}, which takes as an argument asset's name. \texttt{TimeSupport} object obtained by a call to \texttt{getTimeSupport} represents set of points in which trajectory was generated. Anthitetic variates method makes a use from \texttt{getAnthi} which returns anthitetic scenario. \texttt{Scenario} is implemented by class \texttt{MultiTrScenario}.

When we have classes for holding scenarios and trajectories we can finally develop their generators. They must implement \texttt{Generator} interface, which provides a method \texttt{generate} returning an array of Scenarios. Class \texttt{MultiTrGenerator}, which is an implementation of \texttt{Generator}, follows Algorithm \ref{alg:multi-tr} from section \ref{sec:multi-asset}.

\section{Instrument hierarchy}
Classes representing financial instruments are arranged in a hierarchy based on the so-called decorator pattern. Idea of such construction arises from the fact that instruments like barrier options are just modifications of vanilla options. Moreover, we can add several modifications to one instrument. Decorator pattern allows us to take into account diffrent sets of modifications without a need to create a seperate class for each set. Figure \ref{fig:arch:instr} shows the instrument hierarchy.
\begin{sidewaysfigure}
\centering
 \includegraphics[scale=0.75]{images/Architecture/instr.png}
\caption{Class diagram presenting hierarchy of financial instruments.}
\label{fig:arch:instr}
\end{sidewaysfigure}


\texttt{Instr} is an abstract class representing a general financial instrument. It stores field \texttt{T} which holds time to the expiration. Classes deriving from \texttt{Instr} must implement methods \texttt{exAvail} and \texttt{payoff}. The first method, for specified Scenario and time point, answers if the exercise is possible. For example an European option may be exercised if and only if given time point is the last one on the trajectory. On the other hand, exercise of knock-out option is possible if and only if barrier was not hit in given Scenario. Method \texttt{payoff} returns a real number which means what would be the payoff obtained in given scenario if the instrument was exercised at given time point.

\texttt{Bond} and \texttt{Option} are concrete instruments. As the name indicates \texttt{Bond} represents instruments paying \texttt{nominal} after time \texttt{T}. Implementation of the methods for class \texttt{Instr} looks as follows: 
\lstset{language=Java, basicstyle=\small}
\begin{lstlisting}
    protected boolean exAvail(Scenario s, int k) {        
        return s.getTS().getK() == k;
    }
    protected double payoff(Scenario s, int k) {
        return nominal;
    }
\end{lstlisting}

	
Class \texttt{Option} is designed for American options. It stores information about the strike price, its type (call or put) and name of the underlying asset. American vanilla option may be exercised at any time, hence \texttt{exAvail} has the form:
\begin{lstlisting}
    protected boolean exAvail(Scenario s, int k) {
        return true;
    }
\end{lstlisting}
Implementation of \texttt{payoff} is also not complicated:
\begin{lstlisting}
    protected double payoff(Scenario s, int k) {
        Trajectory tr = s.getTr(underlying);
        double spot = tr.price(k);
        if (type == CALL) return max(0, spot - strike);
        else return max(0, strike - spot);
    }
\end{lstlisting}

\texttt{Modificator} class is the place where decorator pattern comes in. \texttt{Modificator} is just a wrapper for another instrument, but deriving classes can modify its \texttt{payoff} and \texttt{exAvail}. Let us discuss it on several examples. \texttt{EuExercise} and \texttt{Barrier} do not change the payoff, thus corresponding function has the form
\begin{lstlisting}
    protected double payoff(Scenario s, int k) {
        return wrapped.payoff(s, k);
    }
\end{lstlisting}
but \texttt{exAvail} is modified. In class \texttt{EuExercise} we modify the instrument in such a way, that it may be exercised only in final time point, hence
\begin{lstlisting}
    protected boolean exAvail(Scenario s, int k) {
        return s.getTS().getK() == k;
    }
\end{lstlisting}
Class \texttt{Barrier} checks if the barrier was hit. And then, depending on whether the option is knock-out or knock-in, it allows for option's exercise or not. 
\begin{lstlisting}
    public boolean exAvail(Scenario s, int k) {
        Trajectory tr = s.getTr(underlying);
        boolean hit;
        if (bp.isFromUp())
            hit = tr.cumMax(k) >= bp.level;
        else
            hit = tr.cumMin(k) <= bp.level;
        return (bp.isKnockIn() ? hit : !hit);
    }
\end{lstlisting}
Class \texttt{Binary} does not change method \texttt{exAvail}, but payoff function is modified:
\begin{lstlisting}
    protected double payoff(Scenario s, int k) {
        return wrapped.payoff(s, k) > 0 ? 1 : 0;
    }
\end{lstlisting}
	
This design may look overly complicated. Let us explain what is its advantage. Suppose that at some point we will have a need to price not only typical barrier options, but also options with double barrier, for example knock-out corridor options, which has zero payoff if the stock price goes beyond some specified range during option's lifetime. Our design lets us to instantiate an object representing such instrument without necessity to write any additional classes! We just write\footnote{Constructors' arguments which are irrelevant for the example were omitted.}:
\begin{lstlisting}
    Instr corridor = new Barrier(new Barrier(new Option()));
\end{lstlisting}
That's it! What if we would like to price European binary option with double barrier? Do we need some additional code? Of course not, we simply type
\begin{lstlisting}
    Instr veryExotic = new European(new Barrier(new Barrier(
                                    new Binary(new Option()))));
\end{lstlisting}
If we had to create special classes for such instruments as the one mentioned above, then soon we would have dozens of instrument classes and the code would become unmaintainable.
	
\section{Pricing methods}
\begin{sidewaysfigure}
\centering
 \includegraphics[scale=0.59]{images/Architecture/method.png}
\caption{Class diagram presenting hierarchy of classes used for option pricing.}
\label{fig:arch:method}
\end{sidewaysfigure}

\chapter{Results illustrations}
 
\section{Vanilla options}

\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.5]{images/Results/vanillaEuAndAmPut.pdf}
\caption{Chcem sprawdzic jak obrazek wyglada w pracy}
\label{fig:results:dupa1}
\end{figure}

\section{Barrier options}
\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.5]{images/Results/barrierCall3D.pdf}
\caption{Chcem sprawdzic jak obrazek wyglada w pracy}
\label{fig:results:dupa2}
\end{figure}

\section{Binary options}
\begin{figure}[!ht]
\centering
 \includegraphics[scale=0.5]{images/Results/binaryEuPut.pdf}
 \includegraphics[scale=0.5]{images/Results/binaryEuPut.pdf}
\caption{Chcem sprawdzic jak obrazek wyglada w pracy}
\label{fig:results:dupa3}
\end{figure}

\chapter*{Concluding remarks}
 

\begin{thebibliography}{99}
\addcontentsline{toc}{section}{\bfseries References}

\bibitem{bjork}
T. Bj\"{o}rk, \emph{Arbitrage Theory in Continuous Time}, Oxford University Press,  New York, 3rd edition, 2009

\bibitem{follmer}
H. F\"{o}llmer, A. Schied, \emph{Stochastic finance. An introduction in discrete time}, Walter de Gruyter, Berlin, 2nd edition, 2004

\bibitem{latala}
R. Latała, \emph{Wstęp do Analizy Stochastycznej}, Warszawa, 2011

\bibitem{london}
J. London, \emph{Modeling derivatives in C++}, John Wiley \& Sons, Hoboken, 2005

\bibitem{l-sch}
F. Longstaff, E. Schwartz, \emph{Valuing American Options by Simulation: A Simple Least Squares Approach}, The Review of Financial Studies, Vol.14, No.1, pp.113-147, 2001

\bibitem{wilmott}
P. Wilmott, \emph{On quantitative finance}, John Wiley \& Sons, Chichester, 2nd edition, 2006

\end{thebibliography}


\end{document}
